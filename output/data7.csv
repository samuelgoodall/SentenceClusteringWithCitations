Foldername,sentenceID,sentence,citations,citation_titles,citation_authors,PaperID,ParagraphID,Bibliography used
usable_dataset/2104.10558,urn:uuid:60199125-574b-32c3-b1a0-7901a8a4964a,"Planning algorithms are central to robot navigation <cit.>, and planning under uncertainty is especially critical in uncontrolled environments like public roads.",['lavalle2006planning'],['Planning algorithms'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:c222f901-b370-363a-9f90-394b74759ec1,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:ca8a32c6-1382-3129-8260-285876788d50,Various choices exist for designing autonomous vehicle planning algorithms that consider other vehicles (see <cit.> for a thorough survey).,['schwarting2018planning'],['Planning and decision-making for autonomous vehicles'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:c222f901-b370-363a-9f90-394b74759ec1,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:b4ade074-3ebf-3de3-9e53-1dc713054f2a, Gray  <cit.>                         Passive ,['hardy2013contingency'],['{Contingency Planning Over Probabilistic Obstacle Predictions for Autonomous Road Vehicles}'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:0f9e6925-b936-389b-942d-8eed10ff166a,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:efbf3bb9-e757-3ec3-8e30-c3bb39fb2607,   <cit.>                         Active  ,['bandyopadhyay2013intention'],['Intention-aware motion planning'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:ef333523-ec92-32ad-8e62-ab2d6997bb11,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:cf41c548-973f-3418-a76e-9e276f89f500,    Gray  <cit.>                         None ,['xu2014motion'],['Motion planning under uncertainty for on-road autonomous driving'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:91e31e52-bb3f-3a7c-9033-30220b91d242,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:79c1e977-6242-3f8c-835c-a580dc6b90e8,   <cit.>                          Passive ,['zhan2016non'],['A non-conservatively defensive strategy for urban autonomous driving'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:de24cb71-6007-39dd-8bfe-8e2ffcdff77c,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:9460ee77-bfdd-370a-ace7-b543411c4e22,    Gray  <cit.>                          None    ,['sadigh2016planning'],['Planning for Autonomous Cars that Leverage Effects on Human Actions'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:6a978729-4caf-3417-a4f0-aa5db6d4457c,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:e1bdbd55-aa32-3e96-b4a4-86bcbe637a68,   <cit.>                         Active ,['galceran2017multipolicy'],['Multipolicy decision-making for autonomous driving via changepoint-based behavior prediction: Theory and experiment'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:3adc5e8d-3821-31ce-aa40-eba157d7c94c,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:86f95691-13a1-3b77-917a-6035ce442acd,  Gray  <cit.>                          None    ,['schmerling2018multimodal'],['Multimodal probabilistic model-based planning for human-robot interaction'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:098dd308-05c5-340c-8c78-bfe3f6e44900,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:1c066f57-05b4-358f-b32d-b2f45dc5e4e9,   <cit.>                         None ,['rhinehart2020deep'],"['Deep Imitative Models for Flexible Inference, Planning, and Control']",[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:86c6b371-6dbe-32d2-8cbd-62b2904ca92a,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:1271e00c-6732-3344-ac11-cdfffa2b2be2,    Gray  <cit.>         a                 None ,['zhou2018joint'],['Joint multi-policy behavior estimation and receding-horizon trajectory planning for automated urban driving'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:0ad9cbcb-4307-3b50-b5c0-37eb7180d39a,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:571fd5b5-6787-309d-b13c-2d0e6125b3b6,  <cit.>                          Active ,['fisac2019hierarchical'],['{Hierarchical Game-Theoretic Planning for Autonomous Vehicles}'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:3585c0d6-1873-3162-9f71-60763d512ade,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:55287bd1-f29b-3c83-97c6-4aaa0e671a07,    Gray  <cit.>                          None  ,['zeng2019end'],['End-to-end interpretable neural motion planner'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:3138e02b-07b1-3330-a8e0-89d7994ac63a,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:1fbd0514-58de-30b9-b9c2-21e9a54d0aec,   <cit.>                          None ,['tang2019mfp'],['Multiple futures prediction'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:3e430fdb-cd5c-3831-ae85-f7aa62bfadf9,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:28fae2dc-d51a-3707-ade9-c834ba880f1a,   Gray   <cit.>                         Passive ,['cui2021lookout'],['{LookOut}: Diverse Multi-Future Prediction and Planning for Self-Driving'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:c4b02e37-c6b5-396a-b3f9-f131c325da63,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:cc27fa7f-7c01-36ef-a9c8-5a66f203163a,  <cit.>         ?,['bajcsy2021analyzing'],['Analyzing Human Models that Adapt Online'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:0aa60657-dcf2-3264-a26c-0ffa0e734f49,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:004fbadb-87d4-3b9f-b961-6ab50e898031,"Recently, fully learned planning approaches have shown promising results on autonomous navigation benchmarks and settings <cit.>.","['rhinehart2020deep', 'zeng2019end', 'filos2020can']","['Deep Imitative Models for Flexible Inference, Planning, and Control', 'End-to-end interpretable neural motion planner', 'Can Autonomous Vehicles Identify, Recover From, and Adapt to Distribution Shifts?']","[None, None, None]",urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:751ec812-1354-3f01-aaba-7abe0a570e8f,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:8a8459d0-0901-317c-9f0e-191873bc0f13,"However, these methods will fail on tasks that require explicit contingency planning because they do not represent the future behavior of other agents, and therefore cannot be explicitly contingent; we demonstrate <cit.> failing in our experiments.",['rhinehart2020deep'],"['Deep Imitative Models for Flexible Inference, Planning, and Control']",[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:751ec812-1354-3f01-aaba-7abe0a570e8f,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:b84fa775-a071-3676-8011-64f46b31d20f,"In the terminology of Fig. <ref>, “robot leader” methods, commonly referred to as MPC-shooting based methods, plan action trajectories, which means that the actions will be fixed for all possible future behaviors of the other agents <cit.>.","['sadigh2016planning', 'schmerling2018multimodal', 'tang2019mfp']","['Planning for Autonomous Cars that Leverage Effects on Human Actions', 'Multimodal probabilistic model-based planning for human-robot interaction', 'Multiple futures prediction']","[None, None, None]",urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:751ec812-1354-3f01-aaba-7abe0a570e8f,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:bd179e2c-c07e-3955-a4f8-81e9016e7391,"Modular approaches such as those used in the DARPA Grand Challenge <cit.> and modern industry systems <cit.> have the potential to be contingent, but are highly dependent on imperfect perception pipelines.","['paden2016survey', 'thrun2006stanley', 'urmson2008autonomous']","['A survey of motion planning and control techniques for self-driving urban vehicles', 'Stanley: The robot that won the {DARPA Grand Challenge}', 'Autonomous driving in urban environments: Boss and the urban challenge']","[None, None, None]",urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:7ad88627-3d67-3000-84cc-a2e656d69f3c,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:bbcaa64c-2dae-3d02-846d-462708604d33,"In “human leader” approaches <cit.>, the behavior prediction of the other agents is independent of the future behavior of the robot, which means that the robot does not model how its future actions can affect decisions of the other agents, shown <ref>.","['hardy2013contingency', 'zhan2016non', 'cui2021lookout']","['{Contingency Planning Over Probabilistic Obstacle Predictions for Autonomous Road Vehicles}', 'A non-conservatively defensive strategy for urban autonomous driving', '{LookOut}: Diverse Multi-Future Prediction and Planning for Self-Driving']","[None, None, None]",urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:ab0a04ef-b643-35d5-8d94-3fd1ec34c653,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:7874ab39-a46c-3d68-8e3f-fe0559cebfcc," <cit.> and <cit.> perform co-leader contingency planning with hand-crafted models (dynamics models, behavior models, reward functions) rather than learned behavior models.","['galceran2017multipolicy', 'fisac2019hierarchical']","['Multipolicy decision-making for autonomous driving via changepoint-based behavior prediction: Theory and experiment', '{Hierarchical Game-Theoretic Planning for Autonomous Vehicles}']","[None, None]",urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:ab0a04ef-b643-35d5-8d94-3fd1ec34c653,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:ad52df45-3a3a-3b6e-82dd-ae45a9d6b511,"Both <cit.> and <cit.> (a reachability analysis-based approach) only consider single-forking contingencies, whereas our method considers contingencies at every timestep, and therefore does not require determining a `branching time'.","['cui2021lookout', 'bajcsy2021analyzing']","['{LookOut}: Diverse Multi-Future Prediction and Planning for Self-Driving', 'Analyzing Human Models that Adapt Online']","[None, None]",urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:ab0a04ef-b643-35d5-8d94-3fd1ec34c653,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:8caf95eb-de81-313e-9240-5be60ac02257,Model-free imitation learning (IL) and reinforcement learning (RL) have been used to construct policies in autonomous driving environments with multi-agent interaction  <cit.>.,"['dosovitskiy_carla_2017', 'chen2019deep', 'codevilla2019exploring', 'tang2019selfplay', 'palanisamy2019macad', 'hawke2020urban']","['{{CARLA}}: {{An Open Urban Driving Simulator}}', 'Deep imitation learning for autonomous driving in generic urban scenarios with enhanced safety', 'Exploring the limitations of behavior cloning for autonomous driving', 'Towards Learning Multi-agent Negotiations via Self-Play', 'Multi-Agent Connected Autonomous Driving using Deep Reinforcement Learning', 'Urban driving with conditional imitation learning']","[None, None, None, None, None, None]",urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:2da445fc-495a-3fde-a977-c3748a66f541,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:31c5fcfa-1da2-36ed-a92d-a8de3ff0db62,"While goal-conditioning methods can address the suboptimality of adapting model-free methods to test-time data by serving as the representation for the test-time reward function, the goal space of the agents must be specified a priori, requires goal labels, and precludes adapting the learned system to new types of test-time goal objectives <cit.>.","['codevilla2019exploring', 'hawke2020urban']","['Exploring the limitations of behavior cloning for autonomous driving', 'Urban driving with conditional imitation learning']","[None, None]",urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:2da445fc-495a-3fde-a977-c3748a66f541,usable_dataset/2104.10558/references.bib
usable_dataset/2109.08053,urn:uuid:0f0d04cb-3ccd-38cb-b3f4-f99d4d904c35,   SciSpark<cit.> extends Spark with an RDD implementation for multidimensional datasets.,['lit:scispark'],['SciSpark: Applying in-memory distributed computing to weather event detection and tracking'],[None],urn:uuid:4bd9cd6e-324c-375f-9cdd-044838ec9361,urn:uuid:80ec9c7d-257e-35b5-a268-5c9df5d05ed1,usable_dataset/2109.08053/bib-refs.bib
usable_dataset/2109.08053,urn:uuid:1f7becae-4c11-35fe-94f3-393006da0be6, ClimateSpark<cit.> is another Spark extension designed for multidimensional datasets.,['lit:climatespark'],['ClimateSpark: An in-memory distributed computing framework for big climate data analytics'],[None],urn:uuid:4bd9cd6e-324c-375f-9cdd-044838ec9361,urn:uuid:80ec9c7d-257e-35b5-a268-5c9df5d05ed1,usable_dataset/2109.08053/bib-refs.bib
usable_dataset/2104.10558,urn:uuid:60199125-574b-32c3-b1a0-7901a8a4964a,"Planning algorithms are central to robot navigation <cit.>, and planning under uncertainty is especially critical in uncontrolled environments like public roads.",['lavalle2006planning'],['Planning algorithms'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:c222f901-b370-363a-9f90-394b74759ec1,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:ca8a32c6-1382-3129-8260-285876788d50,Various choices exist for designing autonomous vehicle planning algorithms that consider other vehicles (see <cit.> for a thorough survey).,['schwarting2018planning'],['Planning and decision-making for autonomous vehicles'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:c222f901-b370-363a-9f90-394b74759ec1,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:b4ade074-3ebf-3de3-9e53-1dc713054f2a, Gray  <cit.>                         Passive ,['hardy2013contingency'],['{Contingency Planning Over Probabilistic Obstacle Predictions for Autonomous Road Vehicles}'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:0f9e6925-b936-389b-942d-8eed10ff166a,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:efbf3bb9-e757-3ec3-8e30-c3bb39fb2607,   <cit.>                         Active  ,['bandyopadhyay2013intention'],['Intention-aware motion planning'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:ef333523-ec92-32ad-8e62-ab2d6997bb11,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:cf41c548-973f-3418-a76e-9e276f89f500,    Gray  <cit.>                         None ,['xu2014motion'],['Motion planning under uncertainty for on-road autonomous driving'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:91e31e52-bb3f-3a7c-9033-30220b91d242,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:79c1e977-6242-3f8c-835c-a580dc6b90e8,   <cit.>                          Passive ,['zhan2016non'],['A non-conservatively defensive strategy for urban autonomous driving'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:de24cb71-6007-39dd-8bfe-8e2ffcdff77c,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:9460ee77-bfdd-370a-ace7-b543411c4e22,    Gray  <cit.>                          None    ,['sadigh2016planning'],['Planning for Autonomous Cars that Leverage Effects on Human Actions'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:6a978729-4caf-3417-a4f0-aa5db6d4457c,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:e1bdbd55-aa32-3e96-b4a4-86bcbe637a68,   <cit.>                         Active ,['galceran2017multipolicy'],['Multipolicy decision-making for autonomous driving via changepoint-based behavior prediction: Theory and experiment'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:3adc5e8d-3821-31ce-aa40-eba157d7c94c,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:86f95691-13a1-3b77-917a-6035ce442acd,  Gray  <cit.>                          None    ,['schmerling2018multimodal'],['Multimodal probabilistic model-based planning for human-robot interaction'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:098dd308-05c5-340c-8c78-bfe3f6e44900,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:1c066f57-05b4-358f-b32d-b2f45dc5e4e9,   <cit.>                         None ,['rhinehart2020deep'],"['Deep Imitative Models for Flexible Inference, Planning, and Control']",[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:86c6b371-6dbe-32d2-8cbd-62b2904ca92a,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:1271e00c-6732-3344-ac11-cdfffa2b2be2,    Gray  <cit.>         a                 None ,['zhou2018joint'],['Joint multi-policy behavior estimation and receding-horizon trajectory planning for automated urban driving'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:0ad9cbcb-4307-3b50-b5c0-37eb7180d39a,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:571fd5b5-6787-309d-b13c-2d0e6125b3b6,  <cit.>                          Active ,['fisac2019hierarchical'],['{Hierarchical Game-Theoretic Planning for Autonomous Vehicles}'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:3585c0d6-1873-3162-9f71-60763d512ade,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:55287bd1-f29b-3c83-97c6-4aaa0e671a07,    Gray  <cit.>                          None  ,['zeng2019end'],['End-to-end interpretable neural motion planner'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:3138e02b-07b1-3330-a8e0-89d7994ac63a,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:1fbd0514-58de-30b9-b9c2-21e9a54d0aec,   <cit.>                          None ,['tang2019mfp'],['Multiple futures prediction'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:3e430fdb-cd5c-3831-ae85-f7aa62bfadf9,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:28fae2dc-d51a-3707-ade9-c834ba880f1a,   Gray   <cit.>                         Passive ,['cui2021lookout'],['{LookOut}: Diverse Multi-Future Prediction and Planning for Self-Driving'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:c4b02e37-c6b5-396a-b3f9-f131c325da63,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:cc27fa7f-7c01-36ef-a9c8-5a66f203163a,  <cit.>         ?,['bajcsy2021analyzing'],['Analyzing Human Models that Adapt Online'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:0aa60657-dcf2-3264-a26c-0ffa0e734f49,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:004fbadb-87d4-3b9f-b961-6ab50e898031,"Recently, fully learned planning approaches have shown promising results on autonomous navigation benchmarks and settings <cit.>.","['rhinehart2020deep', 'zeng2019end', 'filos2020can']","['Deep Imitative Models for Flexible Inference, Planning, and Control', 'End-to-end interpretable neural motion planner', 'Can Autonomous Vehicles Identify, Recover From, and Adapt to Distribution Shifts?']","[None, None, None]",urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:751ec812-1354-3f01-aaba-7abe0a570e8f,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:8a8459d0-0901-317c-9f0e-191873bc0f13,"However, these methods will fail on tasks that require explicit contingency planning because they do not represent the future behavior of other agents, and therefore cannot be explicitly contingent; we demonstrate <cit.> failing in our experiments.",['rhinehart2020deep'],"['Deep Imitative Models for Flexible Inference, Planning, and Control']",[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:751ec812-1354-3f01-aaba-7abe0a570e8f,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:b84fa775-a071-3676-8011-64f46b31d20f,"In the terminology of Fig. <ref>, “robot leader” methods, commonly referred to as MPC-shooting based methods, plan action trajectories, which means that the actions will be fixed for all possible future behaviors of the other agents <cit.>.","['sadigh2016planning', 'schmerling2018multimodal', 'tang2019mfp']","['Planning for Autonomous Cars that Leverage Effects on Human Actions', 'Multimodal probabilistic model-based planning for human-robot interaction', 'Multiple futures prediction']","[None, None, None]",urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:751ec812-1354-3f01-aaba-7abe0a570e8f,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:bd179e2c-c07e-3955-a4f8-81e9016e7391,"Modular approaches such as those used in the DARPA Grand Challenge <cit.> and modern industry systems <cit.> have the potential to be contingent, but are highly dependent on imperfect perception pipelines.","['paden2016survey', 'thrun2006stanley', 'urmson2008autonomous']","['A survey of motion planning and control techniques for self-driving urban vehicles', 'Stanley: The robot that won the {DARPA Grand Challenge}', 'Autonomous driving in urban environments: Boss and the urban challenge']","[None, None, None]",urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:7ad88627-3d67-3000-84cc-a2e656d69f3c,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:bbcaa64c-2dae-3d02-846d-462708604d33,"In “human leader” approaches <cit.>, the behavior prediction of the other agents is independent of the future behavior of the robot, which means that the robot does not model how its future actions can affect decisions of the other agents, shown <ref>.","['hardy2013contingency', 'zhan2016non', 'cui2021lookout']","['{Contingency Planning Over Probabilistic Obstacle Predictions for Autonomous Road Vehicles}', 'A non-conservatively defensive strategy for urban autonomous driving', '{LookOut}: Diverse Multi-Future Prediction and Planning for Self-Driving']","[None, None, None]",urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:ab0a04ef-b643-35d5-8d94-3fd1ec34c653,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:7874ab39-a46c-3d68-8e3f-fe0559cebfcc," <cit.> and <cit.> perform co-leader contingency planning with hand-crafted models (dynamics models, behavior models, reward functions) rather than learned behavior models.","['galceran2017multipolicy', 'fisac2019hierarchical']","['Multipolicy decision-making for autonomous driving via changepoint-based behavior prediction: Theory and experiment', '{Hierarchical Game-Theoretic Planning for Autonomous Vehicles}']","[None, None]",urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:ab0a04ef-b643-35d5-8d94-3fd1ec34c653,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:ad52df45-3a3a-3b6e-82dd-ae45a9d6b511,"Both <cit.> and <cit.> (a reachability analysis-based approach) only consider single-forking contingencies, whereas our method considers contingencies at every timestep, and therefore does not require determining a `branching time'.","['cui2021lookout', 'bajcsy2021analyzing']","['{LookOut}: Diverse Multi-Future Prediction and Planning for Self-Driving', 'Analyzing Human Models that Adapt Online']","[None, None]",urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:ab0a04ef-b643-35d5-8d94-3fd1ec34c653,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:8caf95eb-de81-313e-9240-5be60ac02257,Model-free imitation learning (IL) and reinforcement learning (RL) have been used to construct policies in autonomous driving environments with multi-agent interaction  <cit.>.,"['dosovitskiy_carla_2017', 'chen2019deep', 'codevilla2019exploring', 'tang2019selfplay', 'palanisamy2019macad', 'hawke2020urban']","['{{CARLA}}: {{An Open Urban Driving Simulator}}', 'Deep imitation learning for autonomous driving in generic urban scenarios with enhanced safety', 'Exploring the limitations of behavior cloning for autonomous driving', 'Towards Learning Multi-agent Negotiations via Self-Play', 'Multi-Agent Connected Autonomous Driving using Deep Reinforcement Learning', 'Urban driving with conditional imitation learning']","[None, None, None, None, None, None]",urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:2da445fc-495a-3fde-a977-c3748a66f541,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:31c5fcfa-1da2-36ed-a92d-a8de3ff0db62,"While goal-conditioning methods can address the suboptimality of adapting model-free methods to test-time data by serving as the representation for the test-time reward function, the goal space of the agents must be specified a priori, requires goal labels, and precludes adapting the learned system to new types of test-time goal objectives <cit.>.","['codevilla2019exploring', 'hawke2020urban']","['Exploring the limitations of behavior cloning for autonomous driving', 'Urban driving with conditional imitation learning']","[None, None]",urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:2da445fc-495a-3fde-a977-c3748a66f541,usable_dataset/2104.10558/references.bib
usable_dataset/2109.08053,urn:uuid:0f0d04cb-3ccd-38cb-b3f4-f99d4d904c35,   SciSpark<cit.> extends Spark with an RDD implementation for multidimensional datasets.,['lit:scispark'],['SciSpark: Applying in-memory distributed computing to weather event detection and tracking'],[None],urn:uuid:4bd9cd6e-324c-375f-9cdd-044838ec9361,urn:uuid:80ec9c7d-257e-35b5-a268-5c9df5d05ed1,usable_dataset/2109.08053/bib-refs.bib
usable_dataset/2109.08053,urn:uuid:1f7becae-4c11-35fe-94f3-393006da0be6, ClimateSpark<cit.> is another Spark extension designed for multidimensional datasets.,['lit:climatespark'],['ClimateSpark: An in-memory distributed computing framework for big climate data analytics'],[None],urn:uuid:4bd9cd6e-324c-375f-9cdd-044838ec9361,urn:uuid:80ec9c7d-257e-35b5-a268-5c9df5d05ed1,usable_dataset/2109.08053/bib-refs.bib
usable_dataset/2104.10558,urn:uuid:60199125-574b-32c3-b1a0-7901a8a4964a,"Planning algorithms are central to robot navigation <cit.>, and planning under uncertainty is especially critical in uncontrolled environments like public roads.",['lavalle2006planning'],['Planning algorithms'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:c222f901-b370-363a-9f90-394b74759ec1,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:ca8a32c6-1382-3129-8260-285876788d50,Various choices exist for designing autonomous vehicle planning algorithms that consider other vehicles (see <cit.> for a thorough survey).,['schwarting2018planning'],['Planning and decision-making for autonomous vehicles'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:c222f901-b370-363a-9f90-394b74759ec1,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:b4ade074-3ebf-3de3-9e53-1dc713054f2a, Gray  <cit.>                         Passive ,['hardy2013contingency'],['{Contingency Planning Over Probabilistic Obstacle Predictions for Autonomous Road Vehicles}'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:0f9e6925-b936-389b-942d-8eed10ff166a,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:efbf3bb9-e757-3ec3-8e30-c3bb39fb2607,   <cit.>                         Active  ,['bandyopadhyay2013intention'],['Intention-aware motion planning'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:ef333523-ec92-32ad-8e62-ab2d6997bb11,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:cf41c548-973f-3418-a76e-9e276f89f500,    Gray  <cit.>                         None ,['xu2014motion'],['Motion planning under uncertainty for on-road autonomous driving'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:91e31e52-bb3f-3a7c-9033-30220b91d242,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:79c1e977-6242-3f8c-835c-a580dc6b90e8,   <cit.>                          Passive ,['zhan2016non'],['A non-conservatively defensive strategy for urban autonomous driving'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:de24cb71-6007-39dd-8bfe-8e2ffcdff77c,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:9460ee77-bfdd-370a-ace7-b543411c4e22,    Gray  <cit.>                          None    ,['sadigh2016planning'],['Planning for Autonomous Cars that Leverage Effects on Human Actions'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:6a978729-4caf-3417-a4f0-aa5db6d4457c,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:e1bdbd55-aa32-3e96-b4a4-86bcbe637a68,   <cit.>                         Active ,['galceran2017multipolicy'],['Multipolicy decision-making for autonomous driving via changepoint-based behavior prediction: Theory and experiment'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:3adc5e8d-3821-31ce-aa40-eba157d7c94c,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:86f95691-13a1-3b77-917a-6035ce442acd,  Gray  <cit.>                          None    ,['schmerling2018multimodal'],['Multimodal probabilistic model-based planning for human-robot interaction'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:098dd308-05c5-340c-8c78-bfe3f6e44900,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:1c066f57-05b4-358f-b32d-b2f45dc5e4e9,   <cit.>                         None ,['rhinehart2020deep'],"['Deep Imitative Models for Flexible Inference, Planning, and Control']",[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:86c6b371-6dbe-32d2-8cbd-62b2904ca92a,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:1271e00c-6732-3344-ac11-cdfffa2b2be2,    Gray  <cit.>         a                 None ,['zhou2018joint'],['Joint multi-policy behavior estimation and receding-horizon trajectory planning for automated urban driving'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:0ad9cbcb-4307-3b50-b5c0-37eb7180d39a,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:571fd5b5-6787-309d-b13c-2d0e6125b3b6,  <cit.>                          Active ,['fisac2019hierarchical'],['{Hierarchical Game-Theoretic Planning for Autonomous Vehicles}'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:3585c0d6-1873-3162-9f71-60763d512ade,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:55287bd1-f29b-3c83-97c6-4aaa0e671a07,    Gray  <cit.>                          None  ,['zeng2019end'],['End-to-end interpretable neural motion planner'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:3138e02b-07b1-3330-a8e0-89d7994ac63a,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:1fbd0514-58de-30b9-b9c2-21e9a54d0aec,   <cit.>                          None ,['tang2019mfp'],['Multiple futures prediction'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:3e430fdb-cd5c-3831-ae85-f7aa62bfadf9,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:28fae2dc-d51a-3707-ade9-c834ba880f1a,   Gray   <cit.>                         Passive ,['cui2021lookout'],['{LookOut}: Diverse Multi-Future Prediction and Planning for Self-Driving'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:c4b02e37-c6b5-396a-b3f9-f131c325da63,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:cc27fa7f-7c01-36ef-a9c8-5a66f203163a,  <cit.>         ?,['bajcsy2021analyzing'],['Analyzing Human Models that Adapt Online'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:0aa60657-dcf2-3264-a26c-0ffa0e734f49,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:004fbadb-87d4-3b9f-b961-6ab50e898031,"Recently, fully learned planning approaches have shown promising results on autonomous navigation benchmarks and settings <cit.>.","['rhinehart2020deep', 'zeng2019end', 'filos2020can']","['Deep Imitative Models for Flexible Inference, Planning, and Control', 'End-to-end interpretable neural motion planner', 'Can Autonomous Vehicles Identify, Recover From, and Adapt to Distribution Shifts?']","[None, None, None]",urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:751ec812-1354-3f01-aaba-7abe0a570e8f,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:8a8459d0-0901-317c-9f0e-191873bc0f13,"However, these methods will fail on tasks that require explicit contingency planning because they do not represent the future behavior of other agents, and therefore cannot be explicitly contingent; we demonstrate <cit.> failing in our experiments.",['rhinehart2020deep'],"['Deep Imitative Models for Flexible Inference, Planning, and Control']",[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:751ec812-1354-3f01-aaba-7abe0a570e8f,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:b84fa775-a071-3676-8011-64f46b31d20f,"In the terminology of Fig. <ref>, “robot leader” methods, commonly referred to as MPC-shooting based methods, plan action trajectories, which means that the actions will be fixed for all possible future behaviors of the other agents <cit.>.","['sadigh2016planning', 'schmerling2018multimodal', 'tang2019mfp']","['Planning for Autonomous Cars that Leverage Effects on Human Actions', 'Multimodal probabilistic model-based planning for human-robot interaction', 'Multiple futures prediction']","[None, None, None]",urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:751ec812-1354-3f01-aaba-7abe0a570e8f,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:bd179e2c-c07e-3955-a4f8-81e9016e7391,"Modular approaches such as those used in the DARPA Grand Challenge <cit.> and modern industry systems <cit.> have the potential to be contingent, but are highly dependent on imperfect perception pipelines.","['paden2016survey', 'thrun2006stanley', 'urmson2008autonomous']","['A survey of motion planning and control techniques for self-driving urban vehicles', 'Stanley: The robot that won the {DARPA Grand Challenge}', 'Autonomous driving in urban environments: Boss and the urban challenge']","[None, None, None]",urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:7ad88627-3d67-3000-84cc-a2e656d69f3c,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:bbcaa64c-2dae-3d02-846d-462708604d33,"In “human leader” approaches <cit.>, the behavior prediction of the other agents is independent of the future behavior of the robot, which means that the robot does not model how its future actions can affect decisions of the other agents, shown <ref>.","['hardy2013contingency', 'zhan2016non', 'cui2021lookout']","['{Contingency Planning Over Probabilistic Obstacle Predictions for Autonomous Road Vehicles}', 'A non-conservatively defensive strategy for urban autonomous driving', '{LookOut}: Diverse Multi-Future Prediction and Planning for Self-Driving']","[None, None, None]",urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:ab0a04ef-b643-35d5-8d94-3fd1ec34c653,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:7874ab39-a46c-3d68-8e3f-fe0559cebfcc," <cit.> and <cit.> perform co-leader contingency planning with hand-crafted models (dynamics models, behavior models, reward functions) rather than learned behavior models.","['galceran2017multipolicy', 'fisac2019hierarchical']","['Multipolicy decision-making for autonomous driving via changepoint-based behavior prediction: Theory and experiment', '{Hierarchical Game-Theoretic Planning for Autonomous Vehicles}']","[None, None]",urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:ab0a04ef-b643-35d5-8d94-3fd1ec34c653,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:ad52df45-3a3a-3b6e-82dd-ae45a9d6b511,"Both <cit.> and <cit.> (a reachability analysis-based approach) only consider single-forking contingencies, whereas our method considers contingencies at every timestep, and therefore does not require determining a `branching time'.","['cui2021lookout', 'bajcsy2021analyzing']","['{LookOut}: Diverse Multi-Future Prediction and Planning for Self-Driving', 'Analyzing Human Models that Adapt Online']","[None, None]",urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:ab0a04ef-b643-35d5-8d94-3fd1ec34c653,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:8caf95eb-de81-313e-9240-5be60ac02257,Model-free imitation learning (IL) and reinforcement learning (RL) have been used to construct policies in autonomous driving environments with multi-agent interaction  <cit.>.,"['dosovitskiy_carla_2017', 'chen2019deep', 'codevilla2019exploring', 'tang2019selfplay', 'palanisamy2019macad', 'hawke2020urban']","['{{CARLA}}: {{An Open Urban Driving Simulator}}', 'Deep imitation learning for autonomous driving in generic urban scenarios with enhanced safety', 'Exploring the limitations of behavior cloning for autonomous driving', 'Towards Learning Multi-agent Negotiations via Self-Play', 'Multi-Agent Connected Autonomous Driving using Deep Reinforcement Learning', 'Urban driving with conditional imitation learning']","[None, None, None, None, None, None]",urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:2da445fc-495a-3fde-a977-c3748a66f541,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:31c5fcfa-1da2-36ed-a92d-a8de3ff0db62,"While goal-conditioning methods can address the suboptimality of adapting model-free methods to test-time data by serving as the representation for the test-time reward function, the goal space of the agents must be specified a priori, requires goal labels, and precludes adapting the learned system to new types of test-time goal objectives <cit.>.","['codevilla2019exploring', 'hawke2020urban']","['Exploring the limitations of behavior cloning for autonomous driving', 'Urban driving with conditional imitation learning']","[None, None]",urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:2da445fc-495a-3fde-a977-c3748a66f541,usable_dataset/2104.10558/references.bib
usable_dataset/2109.08053,urn:uuid:0f0d04cb-3ccd-38cb-b3f4-f99d4d904c35,   SciSpark<cit.> extends Spark with an RDD implementation for multidimensional datasets.,['lit:scispark'],['SciSpark: Applying in-memory distributed computing to weather event detection and tracking'],[None],urn:uuid:4bd9cd6e-324c-375f-9cdd-044838ec9361,urn:uuid:80ec9c7d-257e-35b5-a268-5c9df5d05ed1,usable_dataset/2109.08053/bib-refs.bib
usable_dataset/2109.08053,urn:uuid:1f7becae-4c11-35fe-94f3-393006da0be6, ClimateSpark<cit.> is another Spark extension designed for multidimensional datasets.,['lit:climatespark'],['ClimateSpark: An in-memory distributed computing framework for big climate data analytics'],[None],urn:uuid:4bd9cd6e-324c-375f-9cdd-044838ec9361,urn:uuid:80ec9c7d-257e-35b5-a268-5c9df5d05ed1,usable_dataset/2109.08053/bib-refs.bib
usable_dataset/2104.10558,urn:uuid:60199125-574b-32c3-b1a0-7901a8a4964a,"Planning algorithms are central to robot navigation <cit.>, and planning under uncertainty is especially critical in uncontrolled environments like public roads.",['lavalle2006planning'],['Planning algorithms'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:c222f901-b370-363a-9f90-394b74759ec1,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:ca8a32c6-1382-3129-8260-285876788d50,Various choices exist for designing autonomous vehicle planning algorithms that consider other vehicles (see <cit.> for a thorough survey).,['schwarting2018planning'],['Planning and decision-making for autonomous vehicles'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:c222f901-b370-363a-9f90-394b74759ec1,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:b4ade074-3ebf-3de3-9e53-1dc713054f2a, Gray  <cit.>                         Passive ,['hardy2013contingency'],['{Contingency Planning Over Probabilistic Obstacle Predictions for Autonomous Road Vehicles}'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:0f9e6925-b936-389b-942d-8eed10ff166a,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:efbf3bb9-e757-3ec3-8e30-c3bb39fb2607,   <cit.>                         Active  ,['bandyopadhyay2013intention'],['Intention-aware motion planning'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:ef333523-ec92-32ad-8e62-ab2d6997bb11,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:cf41c548-973f-3418-a76e-9e276f89f500,    Gray  <cit.>                         None ,['xu2014motion'],['Motion planning under uncertainty for on-road autonomous driving'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:91e31e52-bb3f-3a7c-9033-30220b91d242,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:79c1e977-6242-3f8c-835c-a580dc6b90e8,   <cit.>                          Passive ,['zhan2016non'],['A non-conservatively defensive strategy for urban autonomous driving'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:de24cb71-6007-39dd-8bfe-8e2ffcdff77c,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:9460ee77-bfdd-370a-ace7-b543411c4e22,    Gray  <cit.>                          None    ,['sadigh2016planning'],['Planning for Autonomous Cars that Leverage Effects on Human Actions'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:6a978729-4caf-3417-a4f0-aa5db6d4457c,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:e1bdbd55-aa32-3e96-b4a4-86bcbe637a68,   <cit.>                         Active ,['galceran2017multipolicy'],['Multipolicy decision-making for autonomous driving via changepoint-based behavior prediction: Theory and experiment'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:3adc5e8d-3821-31ce-aa40-eba157d7c94c,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:86f95691-13a1-3b77-917a-6035ce442acd,  Gray  <cit.>                          None    ,['schmerling2018multimodal'],['Multimodal probabilistic model-based planning for human-robot interaction'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:098dd308-05c5-340c-8c78-bfe3f6e44900,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:1c066f57-05b4-358f-b32d-b2f45dc5e4e9,   <cit.>                         None ,['rhinehart2020deep'],"['Deep Imitative Models for Flexible Inference, Planning, and Control']",[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:86c6b371-6dbe-32d2-8cbd-62b2904ca92a,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:1271e00c-6732-3344-ac11-cdfffa2b2be2,    Gray  <cit.>         a                 None ,['zhou2018joint'],['Joint multi-policy behavior estimation and receding-horizon trajectory planning for automated urban driving'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:0ad9cbcb-4307-3b50-b5c0-37eb7180d39a,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:571fd5b5-6787-309d-b13c-2d0e6125b3b6,  <cit.>                          Active ,['fisac2019hierarchical'],['{Hierarchical Game-Theoretic Planning for Autonomous Vehicles}'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:3585c0d6-1873-3162-9f71-60763d512ade,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:55287bd1-f29b-3c83-97c6-4aaa0e671a07,    Gray  <cit.>                          None  ,['zeng2019end'],['End-to-end interpretable neural motion planner'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:3138e02b-07b1-3330-a8e0-89d7994ac63a,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:1fbd0514-58de-30b9-b9c2-21e9a54d0aec,   <cit.>                          None ,['tang2019mfp'],['Multiple futures prediction'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:3e430fdb-cd5c-3831-ae85-f7aa62bfadf9,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:28fae2dc-d51a-3707-ade9-c834ba880f1a,   Gray   <cit.>                         Passive ,['cui2021lookout'],['{LookOut}: Diverse Multi-Future Prediction and Planning for Self-Driving'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:c4b02e37-c6b5-396a-b3f9-f131c325da63,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:cc27fa7f-7c01-36ef-a9c8-5a66f203163a,  <cit.>         ?,['bajcsy2021analyzing'],['Analyzing Human Models that Adapt Online'],[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:0aa60657-dcf2-3264-a26c-0ffa0e734f49,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:004fbadb-87d4-3b9f-b961-6ab50e898031,"Recently, fully learned planning approaches have shown promising results on autonomous navigation benchmarks and settings <cit.>.","['rhinehart2020deep', 'zeng2019end', 'filos2020can']","['Deep Imitative Models for Flexible Inference, Planning, and Control', 'End-to-end interpretable neural motion planner', 'Can Autonomous Vehicles Identify, Recover From, and Adapt to Distribution Shifts?']","[None, None, None]",urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:751ec812-1354-3f01-aaba-7abe0a570e8f,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:8a8459d0-0901-317c-9f0e-191873bc0f13,"However, these methods will fail on tasks that require explicit contingency planning because they do not represent the future behavior of other agents, and therefore cannot be explicitly contingent; we demonstrate <cit.> failing in our experiments.",['rhinehart2020deep'],"['Deep Imitative Models for Flexible Inference, Planning, and Control']",[None],urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:751ec812-1354-3f01-aaba-7abe0a570e8f,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:b84fa775-a071-3676-8011-64f46b31d20f,"In the terminology of Fig. <ref>, “robot leader” methods, commonly referred to as MPC-shooting based methods, plan action trajectories, which means that the actions will be fixed for all possible future behaviors of the other agents <cit.>.","['sadigh2016planning', 'schmerling2018multimodal', 'tang2019mfp']","['Planning for Autonomous Cars that Leverage Effects on Human Actions', 'Multimodal probabilistic model-based planning for human-robot interaction', 'Multiple futures prediction']","[None, None, None]",urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:751ec812-1354-3f01-aaba-7abe0a570e8f,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:bd179e2c-c07e-3955-a4f8-81e9016e7391,"Modular approaches such as those used in the DARPA Grand Challenge <cit.> and modern industry systems <cit.> have the potential to be contingent, but are highly dependent on imperfect perception pipelines.","['paden2016survey', 'thrun2006stanley', 'urmson2008autonomous']","['A survey of motion planning and control techniques for self-driving urban vehicles', 'Stanley: The robot that won the {DARPA Grand Challenge}', 'Autonomous driving in urban environments: Boss and the urban challenge']","[None, None, None]",urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:7ad88627-3d67-3000-84cc-a2e656d69f3c,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:bbcaa64c-2dae-3d02-846d-462708604d33,"In “human leader” approaches <cit.>, the behavior prediction of the other agents is independent of the future behavior of the robot, which means that the robot does not model how its future actions can affect decisions of the other agents, shown <ref>.","['hardy2013contingency', 'zhan2016non', 'cui2021lookout']","['{Contingency Planning Over Probabilistic Obstacle Predictions for Autonomous Road Vehicles}', 'A non-conservatively defensive strategy for urban autonomous driving', '{LookOut}: Diverse Multi-Future Prediction and Planning for Self-Driving']","[None, None, None]",urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:ab0a04ef-b643-35d5-8d94-3fd1ec34c653,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:7874ab39-a46c-3d68-8e3f-fe0559cebfcc," <cit.> and <cit.> perform co-leader contingency planning with hand-crafted models (dynamics models, behavior models, reward functions) rather than learned behavior models.","['galceran2017multipolicy', 'fisac2019hierarchical']","['Multipolicy decision-making for autonomous driving via changepoint-based behavior prediction: Theory and experiment', '{Hierarchical Game-Theoretic Planning for Autonomous Vehicles}']","[None, None]",urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:ab0a04ef-b643-35d5-8d94-3fd1ec34c653,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:ad52df45-3a3a-3b6e-82dd-ae45a9d6b511,"Both <cit.> and <cit.> (a reachability analysis-based approach) only consider single-forking contingencies, whereas our method considers contingencies at every timestep, and therefore does not require determining a `branching time'.","['cui2021lookout', 'bajcsy2021analyzing']","['{LookOut}: Diverse Multi-Future Prediction and Planning for Self-Driving', 'Analyzing Human Models that Adapt Online']","[None, None]",urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:ab0a04ef-b643-35d5-8d94-3fd1ec34c653,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:8caf95eb-de81-313e-9240-5be60ac02257,Model-free imitation learning (IL) and reinforcement learning (RL) have been used to construct policies in autonomous driving environments with multi-agent interaction  <cit.>.,"['dosovitskiy_carla_2017', 'chen2019deep', 'codevilla2019exploring', 'tang2019selfplay', 'palanisamy2019macad', 'hawke2020urban']","['{{CARLA}}: {{An Open Urban Driving Simulator}}', 'Deep imitation learning for autonomous driving in generic urban scenarios with enhanced safety', 'Exploring the limitations of behavior cloning for autonomous driving', 'Towards Learning Multi-agent Negotiations via Self-Play', 'Multi-Agent Connected Autonomous Driving using Deep Reinforcement Learning', 'Urban driving with conditional imitation learning']","[None, None, None, None, None, None]",urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:2da445fc-495a-3fde-a977-c3748a66f541,usable_dataset/2104.10558/references.bib
usable_dataset/2104.10558,urn:uuid:31c5fcfa-1da2-36ed-a92d-a8de3ff0db62,"While goal-conditioning methods can address the suboptimality of adapting model-free methods to test-time data by serving as the representation for the test-time reward function, the goal space of the agents must be specified a priori, requires goal labels, and precludes adapting the learned system to new types of test-time goal objectives <cit.>.","['codevilla2019exploring', 'hawke2020urban']","['Exploring the limitations of behavior cloning for autonomous driving', 'Urban driving with conditional imitation learning']","[None, None]",urn:uuid:a257a117-50cd-39b6-a360-269c0bab0a74,urn:uuid:2da445fc-495a-3fde-a977-c3748a66f541,usable_dataset/2104.10558/references.bib
usable_dataset/2109.08053,urn:uuid:0f0d04cb-3ccd-38cb-b3f4-f99d4d904c35,   SciSpark<cit.> extends Spark with an RDD implementation for multidimensional datasets.,['lit:scispark'],['SciSpark: Applying in-memory distributed computing to weather event detection and tracking'],[None],urn:uuid:4bd9cd6e-324c-375f-9cdd-044838ec9361,urn:uuid:80ec9c7d-257e-35b5-a268-5c9df5d05ed1,usable_dataset/2109.08053/bib-refs.bib
usable_dataset/2109.08053,urn:uuid:1f7becae-4c11-35fe-94f3-393006da0be6, ClimateSpark<cit.> is another Spark extension designed for multidimensional datasets.,['lit:climatespark'],['ClimateSpark: An in-memory distributed computing framework for big climate data analytics'],[None],urn:uuid:4bd9cd6e-324c-375f-9cdd-044838ec9361,urn:uuid:80ec9c7d-257e-35b5-a268-5c9df5d05ed1,usable_dataset/2109.08053/bib-refs.bib
