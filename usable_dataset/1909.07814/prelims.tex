\section{Preliminaries}\label{subsec:preliminaries}

\subsection{Neural Networks} A Deep Neural Network (DNN) consists of multiple layers each performing a specific operation on the layer's input (typically a matrix) to prepare the output for the next layer. Some of these layers like Convolution and MaxPool employ stencil codes to sweep through the input using smaller stencils or filters. At a very high level, this is an iterative process where the filter moves along the input with the step value of this governed by a stride parameter. Inside an iteration, a well defined function, $\mathcal{G}$, is computed over the input cells. The result of this function yields a cell value of the output matrix. It is easy to see that such an operation would, at times, reduce the dimensions of the input. To sometimes prevent that from happening, input matrix is padded with 0s along the border. We define a few terms commonly used in the description of Convolutional Neural Network (CNN).
\begin{tiret}
\item $\relu(x)$: Defined as $\mathsf{max}(x,0)$ and its derivative, denoted by $\drelu(x)$ is $1$ if $x>0$ and $0$ otherwise.
\item \textsf{Fully Connected:} Denotes matrix multiplication between input and weights followed by the addition of a bias term.
\item \textsf{Convolution:} A stencil operation where $\mathcal{G}$ is a matrix product between stencil and the input cells beneath it. This is parameterized by the following: Input dimension of $(n\times n\times i)$ and stencil dimension being $(f\times f\times i\times o)$, where $n$ is the spatial dimension, the no. of input channels is denoted by $i$, $f$ is the filter dimension and $o$ denotes the no. of output channels.
\item \textsf{MaxPool:} A stencil operation where $\mathcal{G}$ is the max value among the input cells. Parameters are similar to that of a convolution.
\item \textsf{Batch Normalization:} A technique used in recent and popular CNNs where the output of some intermediate layers is normalized across a mini-batch of images.
\end{tiret}

\subsection{Threat Model and Security}

All security is modeled and proved using the simulation paradigm~\cite{gmw,canetti00}. At a very high level, all parties are modeled as non-uniform interactive Turing machines running in probabilistic polynomial time (PPT). The adversary $\adv$, that interacts with and acts as instructed by an environment $\env$, corrupts a subset of the parties (in our case, at most $1$ out of the parties). These corrupted parties are under the complete control of $\adv$ and $\adv$ has access to the {\em view} of the corrupted party (which includes all incoming/outgoing messages, inputs and random tape of the party). When considering {\em semi-honest security}, all parties are assumed to follow the protocol specification, while for {\em malicious security}, no such assumption is made. $\env$ receives the entire view of all adversarial parties and outputs a single bit. Security is modeled through two interactions - the {\em real} interaction where parties run a protocol $\prot$ in the presence of $\adv$ and  $\env$ and the {\em ideal} interaction where parties send their inputs to a {\em trusted functionality} $\F$ that executes the desired computation truthfully. $\simu$ (called the {\em simulator}) denotes the adversary in the ideal interaction. Let $\mathsf{REAL}_{\prot,\adv,\env}$ (resp. $\mathsf{IDEAL}_{\F,\simu,\env}$) denote the distribution describing $\env$'s output in the real (resp. ideal) interaction. A protocol {\em securely realizes} a functionality $\F$ if for all $\adv$ in the real interaction, there exists $\simu$ in the ideal interaction such that the distributions $\mathsf{REAL}_{\prot,\adv,\env}$ and  $\mathsf{IDEAL}_{\F,\simu,\env}$ are negligibly close (in a security parameter $\secparam$). Protocols can also invoke other sub-protocols and in this framework, the {\em $F-$hybrid model} is like a real interaction, except that some invocations of sub-protocols are replaced by invocations of an ideal functionality $\F$.

\subsection{Intel SGX}

A {\em Trusted Execution Environment (TEE)} is an area of the processor that promises to provide security guarantees like data privacy and code integrity to a program that is loaded inside of it, even in the presence of a malicious operating system and hypervisor. With the Skylake series of processors, Intel introduced a new set of instructions, called {\em Intel Software Guard Extensions} (SGX), which provides a way to realize TEE on Intel chipsets. This is enforced through hardware access control mechanisms for the pages belonging to an application loaded with SGX. Intel SGX aims to provide the guarantee that code and data of the secure application can neither be read nor modified by even privileged software on the machine. Naturally, providing these guarantees are very hard and reducing the assumption needed of the TEE is of paramount importance. 

Applications typically contain two parts: an {\em enclave} which contains all sensitive code and data, and the {\em standard} part, which handles all system calls related to input/output and sockets. A chunk of memory, called {\em Processor Reserved Memory} (around 128 MB) is set aside for holding the enclave data pages. There are two types of function calls in SGX - $\mathsf{ecall}$ and $\mathsf{ocall}$ with which the program control flow enters/exits an enclave - e.g., to make system calls. 

Enclave Attestation is a protocol by which an enclave proves its identity to another application or enclave. There are two types of enclave attestations: a) Local, when both enclaves reside on the same machine; and b) Remote, when the enclaves reside on different machines. In the latter case, the enclave proving its identity (say A) first proves its identity locally to a special enclave known as the Quoting Enclave (QE) which has keys provisioned by Intel. Upon successful verification, QE queries Intel's Attestation Service (IAS) for an attestation certificate (sometimes referred to as a report). This report can then be used by the second enclave (B) (or even a standard application) to verify the identity of A using IAS's public key. Once attestation is completed successfully, A can set up a private and authenticated channel with B using standard mechanisms.
