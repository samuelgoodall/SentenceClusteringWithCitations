@article{baumgartner2007manual,
  title={Manual curation is not sufficient for annotation of genomic databases},
  author={Baumgartner Jr, William A and Cohen, K Bretonnel and Fox, Lynne M and Acquaah-Mensah, George and Hunter, Lawrence},
  journal={Bioinformatics},
  volume={23},
  number={13},
  pages={i41--i48},
  year={2007},
  publisher={Oxford University Press}
}

@article{lachin2008effect,
  title={Effect of glycemic exposure on the risk of microvascular complications in the diabetes control and complications trial—revisited},
  author={Lachin, John M and Genuth, Saul and Nathan, David M and Zinman, Bernard and Rutledge, Brandy N and others},
  journal={Diabetes},
  volume={57},
  number={4},
  pages={995--1001},
  year={2008},
  publisher={Am Diabetes Assoc}
}

@article{augustin2004glycemic,
  title={Glycemic index, glycemic load and risk of gastric cancer},
  author={Augustin, LSA and Gallus, S and Negri, E and La Vecchia, C},
  journal={Annals of oncology},
  volume={15},
  number={4},
  pages={581--584},
  year={2004},
  publisher={Elsevier}
}

@inproceedings{li2016commonsense,
  title={Commonsense knowledge base completion},
  author={Li, Xiang and Taheri, Aynaz and Tu, Lifu and Gimpel, Kevin},
  booktitle={Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={1445--1455},
  year={2016}
}

@inproceedings{mausam2016open,
  title={Open information extraction systems and downstream applications},
  author={Mausam, Mausam},
  booktitle={Proceedings of the twenty-fifth international joint conference on artificial intelligence},
  pages={4074--4077},
  year={2016}
}

@article{chaudhari2021attentive,
  title={An attentive survey of attention models},
  author={Chaudhari, Sneha and Mithal, Varun and Polatkan, Gungor and Ramanath, Rohan},
  journal={ACM Transactions on Intelligent Systems and Technology (TIST)},
  volume={12},
  number={5},
  pages={1--32},
  year={2021},
  publisher={ACM New York, NY}
}

@article{wang2021distributed,
  title={Distributed Representations of Diseases based on Co-occurrence Relationship},
  author={Wang, Haoqing and Mai, Huiyu and Deng, Zhi-hong and Yang, Chao and Zhang, Luxia and Wang, Huai-yu},
  journal={Expert Systems with Applications},
  pages={115418},
  year={2021},
  publisher={Elsevier}
}

@article{dutta2021redesigning,
  title={Redesigning the Transformer Architecture with Insights from Multi-particle Dynamical Systems},
  author={Dutta, Subhabrata and Gautam, Tanya and Chakrabarti, Soumen and Chakraborty, Tanmoy},
  journal={arXiv preprint arXiv:2109.15142},
  year={2021}
}

@inproceedings{han-etal-2021-robust,
    title = "Robust Transfer Learning with Pretrained Language Models through Adapters",
    author = "Han, Wenjuan  and
      Pang, Bo  and
      Wu, Ying Nian",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-short.108",
    doi = "10.18653/v1/2021.acl-short.108",
    pages = "854--861",
    abstract = "Transfer learning with large pretrained transformer-based language models like BERT has become a dominating approach for most NLP tasks. Simply fine-tuning those large language models on downstream tasks or combining it with task-specific pretraining is often not robust. In particular, the performance considerably varies as the random seed changes or the number of pretraining and/or fine-tuning iterations varies, and the fine-tuned model is vulnerable to adversarial attack. We propose a simple yet effective adapter-based approach to mitigate these issues. Specifically, we insert small bottleneck layers (i.e., adapter) within each layer of a pretrained model, then fix the pretrained layers and train the adapter layers on the downstream task data, with (1) task-specific unsupervised pretraining and then (2) task-specific supervised training (e.g., classification, sequence labeling). Our experiments demonstrate that such a training scheme leads to improved stability and adversarial robustness in transfer learning to various downstream tasks.",
}

@article{bojanowski2017enriching,
  title={Enriching word vectors with subword information},
  author={Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},
  journal={Transactions of the Association for Computational Linguistics},
  volume={5},
  pages={135--146},
  year={2017},
  publisher={MIT Press}
}

@inproceedings{10.1145/2488388.2488420,
author = {Del Corro, Luciano and Gemulla, Rainer},
title = {ClausIE: Clause-Based Open Information Extraction},
year = {2013},
isbn = {9781450320351},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2488388.2488420},
doi = {10.1145/2488388.2488420},
abstract = {We propose ClausIE, a novel, clause-based approach to open information extraction, which extracts relations and their arguments from natural language text. ClausIE fundamentally differs from previous approaches in that it separates the detection of ``useful'' pieces of information expressed in a sentence from their representation in terms of extractions. In more detail, ClausIE exploits linguistic knowledge about the grammar of the English language to first detect clauses in an input sentence and to subsequently identify the type of each clause according to the grammatical function of its constituents. Based on this information, ClausIE is able to generate high-precision extractions; the representation of these extractions can be flexibly customized to the underlying application. ClausIE is based on dependency parsing and a small set of domain-independent lexica, operates sentence by sentence without any post-processing, and requires no training data (whether labeled or unlabeled). Our experimental study on various real-world datasets suggests that ClausIE obtains higher recall and higher precision than existing approaches, both on high-quality text as well as on noisy text as found in the web.},
booktitle = {Proceedings of the 22nd International Conference on World Wide Web},
pages = {355–366},
numpages = {12},
keywords = {open information extraction, relation extraction},
location = {Rio de Janeiro, Brazil},
series = {WWW '13}
}


@article{rinaldi2017strategies,
  title={Strategies towards digital and semi-automated curation in RegulonDB},
  author={Rinaldi, Fabio and Lithgow, Oscar and Gama-Castro, Socorro and Solano, Hilda and L{\'o}pez-Fuentes, Alejandra and Mu{\~n}iz Rascado, Luis Jos{\'e} and Ishida-Guti{\'e}rrez, Cecilia and M{\'e}ndez-Cruz, Carlos-Francisco and Collado-Vides, Julio},
  journal={Database},
  volume={2017},
  year={2017},
  publisher={Narnia}
}

@article{gottesman2019guidelines,
  title={Guidelines for reinforcement learning in healthcare},
  author={Gottesman, Omer and Johansson, Fredrik and Komorowski, Matthieu and Faisal, Aldo and Sontag, David and Doshi-Velez, Finale and Celi, Leo Anthony},
  journal={Nat Med},
  volume={25},
  number={1},
  pages={16--18},
  year={2019}
}

@article{balderas2017improving,
  title={Improving biocuration of microRNAs in diseases: a case study in idiopathic pulmonary fibrosis},
  author={Balderas-Mart{\'\i}nez, Yalbi Itzel and Rinaldi, Fabio and Contreras, Gabriela and Solano-Lira, Hilda and S{\'a}nchez-P{\'e}rez, Mishael and Collado-Vides, Julio and Selman, Mois{\'e}s and Pardo, Annie},
  journal={Database},
  volume={2017},
  year={2017},
  publisher={Narnia}
}


@article{rodriguez2007automatic,
  title={Automatic reconstruction of a bacterial regulatory network using Natural Language Processing},
  author={Rodr{\'\i}guez-Penagos, Carlos and Salgado, Heladia and Mart{\'\i}nez-Flores, Irma and Collado-Vides, Julio},
  journal={BMC bioinformatics},
  volume={8},
  number={1},
  pages={293},
  year={2007},
  publisher={BioMed Central}
}

@article{mendez2017first,
  title={First steps in automatic summarization of transcription factor properties for RegulonDB: classification of sentences about structural domains and regulated processes},
  author={M{\'e}ndez-Cruz, Carlos-Francisco and Gama-Castro, Socorro and Mej{\'\i}a-Almonte, Citlalli and Castillo-Villalba, Marco-Polo and Mu{\~n}iz-Rascado, Luis-Jos{\'e} and Collado-Vides, Julio},
  journal={Database},
  volume={2017},
  year={2017},
  publisher={Narnia}
}

@inbook{doi:10.1142/9789813279827_0011,
author = { Haohan   Wang  and  Xiang   Liu  and  Yifeng   Tao  and  Wenting   Ye  and  Qiao   Jin  and  William W.   Cohen  and  Eric P.   Xing },
title = {Automatic Human-like Mining and Constructing Reliable Genetic Association Database with Deep Reinforcement Learning},
booktitle = {Biocomputing 2019},
chapter = {},
pages = {112-123},
doi = {10.1142/9789813279827_0011},
URL = {https://www.worldscientific.com/doi/abs/10.1142/9789813279827_0011},
eprint = {https://www.worldscientific.com/doi/pdf/10.1142/9789813279827_0011},
    abstract = { The increasing amount of scientific literature in biological and biomedical science research has created a challenge in continuous and reliable curation of the latest knowledge discovered, and automatic biomedical text-mining has been one of the answers to this challenge. In this paper, we aim to further improve the reliability of biomedical text-mining by training the system to directly simulate the human behaviors such as querying the PubMed, selecting articles from queried results, and reading selected articles for knowledge. We take advantage of the efficiency of biomedical text-mining, the exibility of deep reinforcement learning, and the massive amount of knowledge collected in UMLS into an integrative artificial intelligent reader that can automatically identify the authentic articles and effectively acquire the knowledge conveyed in the articles. We construct a system, whose current primary task is to build the genetic association database between genes and complex traits of human. Our contributions in this paper are three-fold: 1) We propose to improve the reliability of text-mining by building a system that can directly simulate the behavior of a researcher, and we develop corresponding methods, such as Bi-directional LSTM for text mining and Deep Q-Network for organizing behaviors. 2) We demonstrate the effectiveness of our system with an example in constructing a genetic association database. 3) We release our implementation as a generic framework for researchers in the community to conveniently construct other databases. }
}

@inproceedings{takanobu2019hierarchical,
  title={A hierarchical framework for relation extraction with reinforcement learning},
  author={Takanobu, Ryuichi and Zhang, Tianyang and Liu, Jiexi and Huang, Minlie},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={7072--7079},
  year={2019}
}

@inproceedings{camara2015multi,
  title={A multi-agent system with reinforcement learning agents for biomedical text mining},
  author={Camara, Michael and Bonham-Carter, Oliver and Jumadinova, Janyl},
  booktitle={Proceedings of the 6th ACM Conference on Bioinformatics, Computational Biology and Health Informatics},
  pages={634--643},
  year={2015}
}

@INPROCEEDINGS{4463242,
author={I. {Rudowsky} and O. {Kulyba} and M. {Kunin} and S. {Parsons} and T. {Raphan}},
booktitle={2006 International Conference of the IEEE Engineering in Medicine and Biology Society},
title={Reinforcement Learning Interfaces for Biomedical Database Systems},
year={2006},
volume={},
number={},
pages={6269-6272},
keywords={cooperative systems;learning (artificial intelligence);medical computing;medical information systems;meta data;neurophysiology;relational databases;user interfaces;reinforcement learning interfaces;biomedical database systems;neural function;data storage;nontextual data;relational database;manageable metadata table;free formatted fields;database interface application;intelligent agent;data integrity;Learning;Database systems;Relational databases;Intelligent agent;Laboratories;Information retrieval;Memory;Data analysis;Humans;Cities and towns;Algorithms;Computational Biology;Computer Communication Networks;Computer Graphics;Computer Simulation;Database Management Systems;Databases, Factual;Humans;Learning;Medical Informatics Applications;Programming Languages;Reinforcement (Psychology);Software;Software Design;User-Computer Interface},
doi={10.1109/IEMBS.2006.260484},
ISSN={1557-170X},
month={Aug},}

@article{10.1093/bib/bbx085,
    author = {Karp, Peter D and Billington, Richard and Caspi, Ron and Fulcher, Carol A and Latendresse, Mario and Kothari, Anamika and Keseler, Ingrid M and Krummenacker, Markus and Midford, Peter E and Ong, Quang and Ong, Wai Kit and Paley, Suzanne M and Subhraveti, Pallavi},
    title = "{The BioCyc collection of microbial genomes and metabolic pathways}",
    journal = {Briefings in Bioinformatics},
    volume = {20},
    number = {4},
    pages = {1085-1093},
    year = {2017},
    month = {08},
    abstract = "{BioCyc.org is a microbial genome Web portal that combines thousands of genomes with additional information inferred by computer programs, imported from other databases and curated from the biomedical literature by biologist curators. BioCyc also provides an extensive range of query tools, visualization services and analysis software. Recent advances in BioCyc include an expansion in the content of BioCyc in terms of both the number of genomes and the types of information available for each genome; an expansion in the amount of curated content within BioCyc; and new developments in the BioCyc software tools including redesigned gene/protein pages and metabolite pages; new search tools; a new sequence-alignment tool; a new tool for visualizing groups of related metabolic pathways; and a facility called SmartTables, which enables biologists to perform analyses that previously would have required a programmer’s assistance.}",
    issn = {1477-4054},
    doi = {10.1093/bib/bbx085},
    url = {https://doi.org/10.1093/bib/bbx085},
    eprint = {https://academic.oup.com/bib/article-pdf/20/4/1085/30119563/bbx085.pdf},
}

@article{sheikhalishahi2019natural,
  title={Natural language processing of clinical notes on chronic diseases: systematic review},
  author={Sheikhalishahi, Seyedmostafa and Miotto, Riccardo and Dudley, Joel T and Lavelli, Alberto and Rinaldi, Fabio and Osmani, Venet},
  journal={JMIR medical informatics},
  volume={7},
  number={2},
  pages={e12239},
  year={2019},
  publisher={JMIR Publications Inc., Toronto, Canada}
}


@article{alexandar2015cardiogenbase,
  title={CardioGenBase: a literature based multi-omics database for major cardiovascular diseases},
  author={Alexandar, V and Nayar, Pradeep G and Murugesan, R and Mary, Beaulah and Darshana, P and Ahmed, Shiek SSJ},
  journal={PloS one},
  volume={10},
  number={12},
  year={2015},
  publisher={Public Library of Science}
}


@article{crawford2018cerebrovascular,
  title={Cerebrovascular disease knowledge portal: an open-access data resource to accelerate genomic discoveries in stroke},
  author={Crawford, Katherine M and Gallego-Fabrega, Cristina and Kourkoulis, Christina and Miyares, Laura and Marini, Sandro and Flannick, Jason and Burtt, Noel P and Von Grotthuss, Marcin and Alexander, Benjamin and Costanzo, Maria C and others},
  journal={Stroke},
  volume={49},
  number={2},
  pages={470--475},
  year={2018},
  publisher={Am Heart Assoc}
}

@article{bravo2015extraction,
  title={Extraction of relations between genes and diseases from text and large-scale data analysis: implications for translational research},
  author={Bravo, {\`A}lex and Pi{\~n}ero, Janet and Queralt-Rosinach, N{\'u}ria and Rautschka, Michael and Furlong, Laura I},
  journal={BMC bioinformatics},
  volume={16},
  number={1},
  pages={55},
  year={2015},
  publisher={Springer}
}

@article{bhasuran2018automatic,
  title={Automatic extraction of gene-disease associations from literature using joint ensemble learning},
  author={Bhasuran, Balu and Natarajan, Jeyakumar},
  journal={PloS one},
  volume={13},
  number={7},
  year={2018},
  publisher={Public Library of Science}
}

@article{yu2018automatic,
  title={Automatic extraction of protein-protein interactions using grammatical relationship graph},
  author={Yu, Kaixian and Lung, Pei-Yau and Zhao, Tingting and Zhao, Peixiang and Tseng, Yan-Yuan and Zhang, Jinfeng},
  journal={BMC medical informatics and decision making},
  volume={18},
  number={2},
  pages={42},
  year={2018},
  publisher={BioMed Central}
}

@article{miwa2009protein,
  title={Protein--protein interaction extraction by leveraging multiple kernels and parsers},
  author={Miwa, Makoto and S{\ae}tre, Rune and Miyao, Yusuke and Tsujii, Jun’ichi},
  journal={International journal of medical informatics},
  volume={78},
  number={12},
  pages={e39--e46},
  year={2009},
  publisher={Elsevier}
}


@inproceedings{blaschke1999automatic,
  title={Automatic extraction of biological information from scientific text: protein-protein interactions.},
  author={Blaschke, Christian and Andrade, Miguel A and Ouzounis, Christos A and Valencia, Alfonso},
  booktitle={Ismb},
  volume={7},
  pages={60--67},
  year={1999}
}

@inproceedings{fukuda1998toward,
  title={Toward information extraction: identifying protein names from biological papers},
  author={Fukuda, Ken-ichiro and Tsunoda, Tatsuhiko and Tamura, Ayuchi and Takagi, Toshihisa and others},
  booktitle={Pac symp biocomput},
  volume={707},
  number={18},
  pages={707--718},
  year={1998}
}


@article{hunter2013noncommunicable,
  title={Noncommunicable diseases},
  author={Hunter, David J and Reddy, K Srinath},
  journal={New England Journal of Medicine},
  volume={369},
  number={14},
  pages={1336--1343},
  year={2013},
  publisher={Mass Medical Soc}
}

@article{YOUSEFIAZAR201793,
title = "Text summarization using unsupervised deep learning",
journal = "Expert Systems with Applications",
volume = "68",
pages = "93 -- 105",
year = "2017",
issn = "0957-4174",
doi = "https://doi.org/10.1016/j.eswa.2016.10.017",
url = "http://www.sciencedirect.com/science/article/pii/S0957417416305486",
author = "Mahmood Yousefi-Azar and Len Hamey",
keywords = "Deep Learning, Query-oriented Summarization, Extractive Summarization, Ensemble Noisy Auto-Encoder",
}

@article{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

@article{gupta2019increase,
  title={Increase in Mutual Information During Interaction with the Environment Contributes to Perception},
  author={Gupta, Daya Shankar and Bahmer, Andreas},
  journal={Entropy},
  volume={21},
  number={4},
  pages={365},
  year={2019},
  publisher={Multidisciplinary Digital Publishing Institute}
}



@inproceedings{sutton2000policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
  booktitle={Advances in neural information processing systems},
  pages={1057--1063},
  year={2000}
}


@ARTICLE {oALE68a,
	AUTHOR="V. M. Aleksandrov and V. I. Sysoyev and V. V. Shemeneva",
	YEAR={1968},
	TITLE="Stochastic Optimization",
	JOURNAL={Engineering Cybernetics},
	VOLUME={5},
	PAGES={11--16}  }

@techreport{glynn1987likelihood,
  title={Likelihood ratio gradient estimation: an overview},
  author={Glynn, Peter W},
  year={1987},
  institution={STANFORD UNIV CA DEPT OF OPERATIONS RESEARCH}
}


@inproceedings{villasenor2018pulmondb,
  title={PulmonDB: A Gene Expression Lung Diseases},
  author={Villasenor-Altamirano, AB and Balderas-Martinez, YI and Moretto, M and Zayas-Del Moral, A and Maldonado, M and Munguia-Reyes, A and Garcia-Sotelo, JS and Aguilar Bautista, LA and Ramirez-Navarro, L and Santillan, O and others},
  booktitle={AMERICAN JOURNAL OF RESPIRATORY AND CRITICAL CARE MEDICINE},
  volume={197},
  year={2018},
  organization={AMER THORACIC SOC 25 BROADWAY, 18 FL, NEW YORK, NY 10004 USA}
}


@article{mendez2017first,
  title={First steps in automatic summarization of transcription factor properties for RegulonDB: classification of sentences about structural domains and regulated processes},
  author={M{\'e}ndez-Cruz, Carlos-Francisco and Gama-Castro, Socorro and Mej{\'\i}a-Almonte, Citlalli and Castillo-Villalba, Marco-Polo and Mu{\~n}iz-Rascado, Luis-Jos{\'e} and Collado-Vides, Julio},
  journal={Database},
  volume={2017},
  
  publisher={Oxford University Press}
}

@article{arroyo2019ats,
title = {Language Features in Extractive Summarization: Humans Vs. Machines},
author = {Ignacio Arroyo-Fern\'andez and Arturo Curiel and Carlos-Francisco M\'endez-Cruz},
journal = {Preprint DOI: 10.13140/RG.2.2.33259.80169},
year = {2019}
}

@article{ARROYOFERNANDEZ2019107,
title = "Unsupervised sentence representations as word information series: Revisiting TF–IDF",
journal = "Computer Speech \& Language",
volume = "56",
pages = "107 - 129",
year = "2019",
issn = "0885-2308",
doi = "https://doi.org/10.1016/j.csl.2019.01.005",
url = "http://www.sciencedirect.com/science/article/pii/S0885230817302887",
author = "Ignacio Arroyo-Fernández and Carlos-Francisco Méndez-Cruz and Gerardo Sierra and Juan-Manuel Torres-Moreno and Grigori Sidorov",
keywords = "Sentence representation, Sentence embedding, Word embedding, Information entropy, TF–IDF, Natural language processing"
}
@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{duffin1952class,
  title={A class of nonharmonic Fourier series},
  author={Duffin, Richard J and Schaeffer, Albert C},
  journal={Transactions of the American Mathematical Society},
  volume={72},
  number={2},
  pages={341--366},
  year={1952},
  publisher={JSTOR}
}

@article{lewicki2000learning,
  title={Learning overcomplete representations},
  author={Lewicki, Michael S and Sejnowski, Terrence J},
  journal={Neural computation},
  volume={12},
  number={2},
  pages={337--365},
  year={2000},
  publisher={MIT Press}
}


@article{kovavcevic2008introduction,
  title={An introduction to frames},
  author={Kova{\v{c}}evi{\'c}, Jelena and Chebira, Amina and others},
  journal={Foundations and Trends{\textregistered} in Signal Processing},
  volume={2},
  number={1},
  pages={1--94},
  year={2008},
  publisher={Now Publishers, Inc.}
}


@inproceedings{conneau2017supervised,
  title={Supervised Learning of Universal Sentence Representations from Natural Language Inference Data},
  author={Conneau, Alexis and Kiela, Douwe and Schwenk, Holger and Barrault, Lo{\"\i}c and Bordes, Antoine},
  booktitle={Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
  pages={670--680},
  year={2017}
}

@InProceedings{W18-3022,
  author = 	"Yang, Yinfei
		and Yuan, Steve
		and Cer, Daniel
		and Kong, Sheng-Yi
		and Constant, Noah
		and Pilar, Petr
		and Ge, Heming
		and Sung, Yun-hsuan
		and Strope, Brian
		and Kurzweil, Ray",
  title = 	"Learning Semantic Textual Similarity from Conversations",
  booktitle = 	"Proceedings of The Third Workshop on Representation Learning for NLP",
  year = 	"2018",
  publisher = 	"Association for Computational Linguistics",
  pages = 	"164--174",
  location = 	"Melbourne, Australia"
}

@inproceedings{bowman2015large,
  title={A large annotated corpus for learning natural language inference},
  author={Bowman, Samuel R and Angeli, Gabor and Potts, Christopher and Manning, Christopher D},
  booktitle={Conference on Empirical Methods in Natural Language Processing, EMNLP 2015},
  year={2015},
  organization={Association for Computational Linguistics (ACL)}
}


@inproceedings{rehurek_lrec,
      title = {{Software Framework for Topic Modelling with Large Corpora}},
      author = {Radim {\v R}eh{\r u}{\v r}ek and Petr Sojka},
      booktitle = {{Proceedings of the LREC 2010 Workshop on New
           Challenges for NLP Frameworks}},
      pages = {45--50},
      year = 2010,
      month = May,
      day = 22,
      publisher = {ELRA},
      address = {Valletta, Malta},
      note={\url{http://is.muni.cz/publication/884893/en}},
      language={English}
}
@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}
@inproceedings{meza2009jointly,
  title={Jointly identifying predicates, arguments and senses using Markov logic},
  author={Meza-Ruiz, Ivan and Riedel, Sebastian},
  booktitle={Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics},
  pages={155--163},
  year={2009},
  organization={Association for Computational Linguistics}
}
@article{brokos2016using,
  title={Using Centroids of Word Embeddings and Word Mover’s Distance for Biomedical Document Retrieval in Question Answering},
  author={Brokos, Georgios-Ioannis and Malakasiotis, Prodromos and Androutsopoulos, Ion},
  journal={ACL 2016},
  pages={114},
  year={2016}
}
@article{pereira2000formal,
  title={Formal grammar and information theory: together again?},
  author={Pereira, Fernando},
  journal={Philosophical Transactions of the Royal Society of London A: Mathematical, Physical and Engineering Sciences},
  volume={358},
  number={1769},
  pages={1239--1253},
  year={2000},
  publisher={The Royal Society}
}
@inproceedings{agirre2013sem,
  title={* SEM 2013 shared task: Semantic Textual Similarity},
  author={Agirre, Eneko and Cer, Daniel and Diab, Mona and Gonzalez-Agirre, Aitor and Guo, Weiwei},
  booktitle={Second Joint Conference on Lexical and Computational Semantics (* SEM), Volume 1: Proceedings of the Main Conference and the Shared Task: Semantic Textual Similarity},
  volume={1},
  pages={32--43},
  year={2013}
}

@Article{PILEHVAR201595,
  Title                    = {From senses to texts: An all-in-one graph-based approach for measuring semantic similarity},
  Author                   = {Mohammad Taher Pilehvar and Roberto Navigli},
  Journal                  = {Artificial Intelligence},
  Year                     = {2015},
  Pages                    = {95 - 128},
  Volume                   = {228},
  ISSN                     = {0004-3702},
  Keywords                 = {Semantic similarity}
}

@incollection{Osteyee1974,
author="Osteyee, David Bridston
and Good, Irving John",
title="Expected mutual information",
chapter="4",
bookTitle="Information, Weight of Evidence, the Singularity between Probability Measures and Signal Detection",
year="1974",
address="Berlin, Germany",
publisher="Springer",
pages="26--38",
isbn="978-3-540-38294-2",
doi="10.1007/BFb0064132"
}

@inproceedings{mihalcea2006corpus,
  title={Corpus-based and knowledge-based measures of text semantic similarity},
  author={Mihalcea, Rada and Corley, Courtney and Strapparava, Carlo and others},
  booktitle={AAAI},
  volume={6},
  pages={775--780},
  year={2006}
}


@inproceedings{hatzivassiloglou1999detecting,
  title={Detecting text similarity over short passages: Exploring linguistic feature combinations via Machine Learning},
  author={Hatzivassiloglou, Vasileios and Klavans, Judith L and Eskin, Eleazar},
  booktitle={Proceedings of the 1999 joint sigdat conference on empirical methods in natural language processing and very large corpora},
  pages={203--212},
  year={1999}
}

@Article{Tian2017,
author="Tian, Ran and Okazaki, Naoaki and Inui, Kentaro",
title="The mechanism of additive composition",
journal="Machine Learning",
year="2017",
month="Jul",
day="01",
volume="106",
number="7",
pages="1083--1130",
abstract="Additive composition (Foltz et al. in Discourse Process 15:285--307, 1998; Landauer and Dumais in Psychol Rev 104(2):211, 1997; Mitchell and Lapata in Cognit Sci 34(8):1388--1429, 2010) is a widely used method for computing meanings of phrases, which takes the average of vector representations of the constituent words. In this article, we prove an upper bound for the bias of additive composition, which is the first theoretical analysis on compositional frameworks from a Machine Learning point of view. The bound is written in terms of collocation strength; we prove that the more exclusively two successive words tend to occur together, the more accurate one can guarantee their additive composition as an approximation to the natural phrase vector. Our proof relies on properties of natural language data that are empirically verified, and can be theoretically derived from an assumption that the data is generated from a Hierarchical Pitman--Yor Process. The theory endorses additive composition as a reasonable operation for calculating meanings of phrases, and suggests ways to improve additive compositionality, including: transforming entries of distributional word vectors by a function that meets a specific condition, constructing a novel type of vector representations to make additive composition sensitive to word order, and utilizing singular value decomposition to train word vectors.",
issn="1573-0565"
}

@inproceedings{hinton1986distributed,
  title={Distributed representations},
  author={Hinton, GE and McClelland, JL and Rumelhart, DE},
  booktitle={Parallel distributed processing: explorations in the microstructure of cognition, vol. 1},
  pages={77--109},
  year={1986},
  organization={MIT Press}
}

@article{elman1991distributed,
  title={Distributed representations, simple recurrent networks, and grammatical structure},
  author={Elman, Jeffrey L},
  journal={Machine Learning},
  volume={7},
  number={2-3},
  pages={195--225},
  year={1991},
  publisher={Springer}
}

@book{Firth1957,
  address = {London},
  author = {Firth, John Rupert},
  publisher = {Oxford University Press},
  title = {Papers in linguistics 1934-1951},
  year = 1957
}

@article{kintsch2011construction,
  title={The construction of meaning},
  author={Kintsch, Walter and Mangalath, Praful},
  journal={Topics in Cognitive Science},
  volume={3},
  number={2},
  pages={346--370},
  year={2011},
  publisher={Wiley Online Library}
}

@incollection{martin2007mathematical,
  author      = {Martin, D. I. and Berry, M. W.},
  title       = {Mathematical foundations behind latent semantic analysis},
  editor      = {Thomas K. Landauer, Danielle S. McNamara, Simon Dennis, Walter Kintsch},
  booktitle   = {Handbook of Latent Semantic Analysis},
  publisher   = {Lawrence Erlbaum Associates Publishers},
  address     = {Mahwah, NJ, US},
  year        = 2007,
  pages       = {35--56},
  chapter     = 2
}

@article{collobert2011natural,
  title={Natural language processing (almost) from scratch},
  author={Collobert, Ronan and Weston, Jason and Bottou, L{\'e}on and Karlen, Michael and Kavukcuoglu, Koray and Kuksa, Pavel},
  journal={Journal of Machine Learning Research},
  volume={12},
  number={Aug},
  pages={2493--2537},
  year={2011}
}

@article{yazdani2013computing,
  title={Computing text semantic relatedness using the contents and links of a hypertext encyclopedia},
  author={Yazdani, Majid and Popescu-Belis, Andrei},
  journal={Artificial Intelligence},
  volume={194},
  pages={176--202},
  year={2013},
  publisher={Elsevier}
}

@article{er2016attention,
  title={Attention pooling-based convolutional neural network for sentence modelling},
  author={Er, Meng Joo and Zhang, Yong and Wang, Ning and Pratama, Mahardhika},
  journal={Information Sciences},
  volume={373},
  pages={388--403},
  year={2016},
  publisher={Elsevier}
}

@article{yu2017learning,
  title = "Learning distributed sentence representations for story segmentation",
journal = "Signal Processing",
volume = "142",
pages = "403 - 411",
year = "2018",
issn = "0165-1684",
author = "Jia Yu and Lei Xie and Xiong Xiao and Eng Siong Chng"
}


@article{chen2017improving,
  title={Improving sentiment analysis via sentence type classification using BiLSTM-CRF and CNN},
  author={Chen, Tao and Xu, Ruifeng and He, Yulan and Wang, Xuan},
  journal={Expert Systems with Applications},
  volume={72},
  pages={221--230},
  year={2017},
  publisher={Elsevier}
}

@article{onan2017hybrid,
  title={A hybrid ensemble pruning approach based on consensus clustering and multi-objective evolutionary algorithm for sentiment classification},
  author={Onan, Aytu{\u{g}} and Koruko{\u{g}}lu, Serdar and Bulut, Hasan},
  journal={Information Processing \& Management},
  volume={53},
  number={4},
  pages={814--833},
  year={2017},
  publisher={Elsevier}
}

@article{zhang2012mutual,
  title={Mutual-reinforcement document summarization using embedded graph based sentence clustering for storytelling},
  author={Zhang, Zhengchen and Ge, Shuzhi Sam and He, Hongsheng},
  journal={Information Processing \& Management},
  volume={48},
  number={4},
  pages={767--778},
  year={2012},
  publisher={Elsevier}
}

@book{charniak1996statistical,
  title={Statistical language learning},
  author={Charniak, Eugene},
  year={1996},
  publisher={MIT Press}
}

@incollection{de1999unsupervised,
  title={On the unsupervised induction of phrase-structure grammars},
  author={De Marcken, Carl},
  booktitle={Natural Language Processing Using Very Large Corpora},
  pages={191--208},
  year={1999},
  publisher={Springer}
}

@article{rennie2005regularized,
  title={Regularized logistic regression is strictly convex},
  author={Rennie, Jason DM},
  journal={Unpublished manuscript. URL people. csail.mit.edu/jrennie/writing/convexLR.pdf},
  year={2005}
}

@article{bentivogli2016sick,
  title={SICK through the SemEval glasses. Lesson learned from the evaluation of compositional distributional semantic models on full sentences through semantic relatedness and textual entailment},
  author={Bentivogli, Luisa and Bernardi, Raffaella and Marelli, Marco and Menini, Stefano and Baroni, Marco and Zamparelli, Roberto},
  journal={Language Resources and Evaluation},
  volume={50},
  number={1},
  pages={95--124},
  year={2016},
  publisher={Springer}
}

@inproceedings{nghia2015jointly,
  title={Jointly optimizing word representations for lexical and sentential tasks with the C-PHRASE model.},
  author={Nghia The Pham and Kruszewski, Germ{\'a}n and Lazaridou, Angeliki and Baroni, Marco},
  booktitle={ACL (1)},
  pages={971--981},
  year={2015}
}

@inproceedings{pgj2017unsup,
  title={Unsupervised Learning of Sentence Embeddings Using Compositional n-Gram Features},
  author={Pagliardini, Matteo and Gupta, Prakhar and Jaggi, Martin},
  booktitle={Proceedings of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL--HLT 2018)},
  volume={1},
  pages={528--540},
  year={2018}
}

@inproceedings{wieting2015towards,
  author    = {John Wieting and Mohit Bansal and Kevin Gimpel and Karen Livescu},
  title     = {Towards Universal Paraphrastic Sentence Embeddings},
  booktitle = {Proceedings of the 4th International Conference on Learning Representations (ICLR)},
  year = {2016},
}

@InProceedings{wieting-EtAl:2016:EMNLP2016,
  author    = {Wieting, John  and  Bansal, Mohit  and  Gimpel, Kevin  and  Livescu, Karen},
  title     = {Charagram: Embedding Words and Sentences via Character n-grams},
  booktitle = {Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing},
  month     = {November},
  year      = {2016},
  address   = {Austin, Texas},
  publisher = {Association for Computational Linguistics},
  pages     = {1504--1515}
}

@article{salton1988term,
  title={Term-weighting approaches in automatic text retrieval},
  author={Salton, Gerard and Buckley, Christopher},
  journal={Information Processing \& Management},
  volume={24},
  number={5},
  pages={513--523},
  year={1988},
  publisher={Elsevier}
}

@article{salton1983extended,
  title="Extended {Boolean} information retrieval",
  author={Salton, Gerard and Fox, Edward A and Wu, Harry},
  journal={Communications of the ACM},
  volume={26},
  number={11},
  pages={1022--1036},
  year={1983},
  publisher={ACM}
}

@article{badarinza2017syntactic,
  title={Syntactic Indexes for Text Retrieval},
  author={Badarinza, Ioan and Sterca, Adrian Ioan and Ionescu, Maria},
  journal={Information Technology in Industry},
  volume={5},
  pages={24--28},
  year={2017}
}

@inproceedings{mitra1997analysis,
  title={An analysis of statistical and syntactic phrases},
  author={Mitra, Mandar and Buckley, Chris and Singhal, Amit and Cardie, Claire},
  booktitle={Computer-Assisted Information Searching on Internet},
  pages={200--214},
  year={1997},
  organization={Le Centre de Hautes Etudes Internationales d'Informatique Documentaire}
}

@article{jurgens2016cross,
  title={Cross level semantic similarity: an evaluation framework for universal measures of similarity},
  author={Jurgens, David and Pilehvar, Mohammad Taher and Navigli, Roberto},
  journal={Language Resources and Evaluation},
  volume={50},
  number={1},
  pages={5--33},
  year={2016},
  publisher={Springer}
}

@article{potash2016simihawk,
  title={SimiHawk at SemEval-2016 Task 1: A Deep Ensemble System for Semantic Textual Similarity},
  author={Potash, Peter and Boag, William and Romanov, Alexey and Ramanishka, Vasili and Rumshisky, Anna},
  journal={Proceedings of SemEval},
  pages={741--748},
  year={2016}
}

@inproceedings{afzal2016mayonlp,
  title={MayoNLP at SemEval-2016 Task 1: Semantic Textual Similarity based on Lexical Semantic Net and Deep Learning Semantic Model.},
  author={Afzal, Naveed and Wang, Yanshan and Liu, Hongfang},
  booktitle={SemEval NAACL-HLT},
  pages={674--679},
  year={2016}
}

@inproceedings{huang2013learning,
  title={Learning deep structured semantic models for web search using clickthrough data},
  author={Huang, Po-Sen and He, Xiaodong and Gao, Jianfeng and Deng, Li and Acero, Alex and Heck, Larry},
  booktitle={Proceedings of the 22nd ACM international conference on Conference on information \& knowledge management},
  pages={2333--2338},
  year={2013},
  organization={ACM}
}

@inproceedings{kiros2015skip,
  title={Skip-thought vectors},
  author={Kiros, Ryan and Zhu, Yukun and Salakhutdinov, Ruslan R and Zemel, Richard and Urtasun, Raquel and Torralba, Antonio and Fidler, Sanja},
  booktitle={Advances in neural information processing systems},
  pages={3294--3302},
  year={2015}
}

@book{tesitelova1992,
title = {Quantitative linguistics}, 
author={T{\v{e}}{\v{s}}it{\v{e}}lov{\'a}, M.},
  isbn={9788020001313},
  lccn={lc93234688},
  series={Linguistics and literary studies in Eastern Europe},
  year={1992},
  publisher={Academia Publishing House of the Czechoslovak Academy of Sciences}
}

@article{newman2005power,
  title={Power laws, Pareto distributions and Zipf's law},
  author={Newman, Mark EJ},
  journal={Contemporary physics},
  volume={46},
  number={5},
  pages={323--351},
  year={2005},
  publisher={Taylor \& Francis}
}

@incollection{brychcin2016uwb,
  title={UWB at SemEval-2016 Task 1: Semantic textual similarity using lexical, syntactic, and semantic information},
  author={Brychc{\i}n, Tom{\'a}{\v{s}} and Svoboda, Luk{\'a}{\v{s}}},
  booktitle={Proceedings of SemEval},
  publisher={ACL 2016},
  pages={588--594},
  year={2016}
}


@article{sultan2014back,
  title={Back to basics for monolingual alignment: Exploiting word similarity and contextual evidence},
  author={Sultan, Md Arafat and Bethard, Steven and Sumner, Tamara},
  journal={Transactions of the Association for Computational Linguistics},
  volume={2},
  pages={219--230},
  year={2014}
}

@article{aizawa2003information,
  title={An information-theoretic perspective of tf--idf measures},
  author={Aizawa, Akiko},
  journal={Information Processing \& Management},
  volume={39},
  number={1},
  pages={45--65},
  year={2003},
  publisher={Elsevier}
}

@inproceedings{kenter2015short,
  title={Short text similarity with word embeddings},
  author={Kenter, Tom and de Rijke, Maarten},
  booktitle={Proceedings of the 24th ACM International on Conference on Information and Knowledge Management},
  pages={1411--1420},
  year={2015},
  organization={ACM}
}

@article{Desmond1977,
 ISSN = {00243892, 15309150},
 URL = {http://www.jstor.org/stable/4178003},
 author = {Desmond C. Derbyshire},
 journal = {Linguistic Inquiry},
 number = {3},
 pages = {590-599},
 publisher = {The MIT Press},
 title = {Word Order Universals and the Existence of OVS Languages},
 volume = {8},
 year = {1977}
}

@article{de2016representation,
  title={Representation learning for very short texts using weighted word embedding aggregation},
  author={De Boom, Cedric and Van Canneyt, Steven and Demeester, Thomas and Dhoedt, Bart},
  journal={Pattern Recognition Letters},
  volume={80},
  pages={150--156},
  year={2016},
  publisher={Elsevier}
}

@inproceedings{zheng2015learning,
  title={Learning to reweight terms with distributed representations},
  author={Zheng, Guoqing and Callan, Jamie},
  booktitle={Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={575--584},
  year={2015},
  organization={ACM}
}

@inproceedings{Yin2015DiscriminativePE,
title={Discriminative Phrase Embedding for Paraphrase Identification},
author={Wenpeng Yin and Hinrich Sch{\"{u}tze}},
booktitle={Proceedings of HLT-NAACL},
pages={1368--1373},
year={2015} }

@inproceedings{hill2016learning,
  title={Learning Distributed Representations of Sentences from Unlabelled Data},
  author={Hill, Felix and Cho, Kyunghyun and Korhonen, Anna},
  booktitle={Proceedings of NAACL-HLT},
  pages={1367--1377},
  year={2016}
}

@article{yin2016abcnn,
  title={ABCNN: Attention-Based Convolutional Neural Network for Modeling Sentence Pairs},
  author={Yin, Wenpeng and Sch{\"u}tze, Hinrich and Xiang, Bing and Zhou, Bowen},
  journal={Transactions of the Association for Computational Linguistics},
  volume={4},
  pages={259--272},
  year={2016}
}

@article{neculoiu2016learning,
  title={Learning Text Similarity with Siamese Recurrent Networks},
  author={Neculoiu, Paul and Versteegh, Maarten and Rotaru, Mihai and Amsterdam, Textkernel BV},
  journal={ACL 2016},
  pages={148},
  year={2016}
}

@inproceedings{mueller2016siamese,
  title={Siamese Recurrent Architectures for Learning Sentence Similarity.},
  author={Mueller, Jonas and Thyagarajan, Aditya},
  booktitle={AAAI},
  pages={2786--2792},
  year={2016}
}

@InProceedings{ferrero-EtAl:2017:SemEval,
  author    = {Ferrero, J\'{e}r\'{e}my  and  Besacier, Laurent  and  Schwab, Didier  and  Agn\`{e}s, Fr\'{e}d\'{e}ric},
  title     = {CompiLIG at SemEval-2017 Task 1: Cross-Language Plagiarism Detection Methods for Semantic Textual Similarity},
  booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
  month     = {August},
  year      = {2017},
  address   = {Vancouver, Canada},
  publisher = {Association for Computational Linguistics},
  pages     = {100--105},
  abstract  = {We present our submitted systems for Semantic Textual Similarity (STS) Track 4
	at SemEval-2017. Given a pair of Spanish-English sentences, each system must
	estimate their semantic similarity by a score between 0 and 5. In our
	submission, we use syntax-based, dictionary-based, context-based, and MT-based
	methods. We also combine these methods in unsupervised and supervised way. Our
	best run ranked 1st on track 4a with a correlation of 83.02% with human
	annotations.},
  url       = {http://www.aclweb.org/anthology/S17-2012}
}

@inproceedings{baroni2014don,
  title={Don't count, predict! A systematic comparison of context-counting vs. context-predicting semantic vectors.},
  author={Baroni, Marco and Dinu, Georgiana and Kruszewski, Germ{\'a}n},
  booktitle={ACL (1)},
  pages={238--247},
  year={2014}
}

@article{globerson2007euclidean,
  title={Euclidean embedding of co-occurrence data},
  author={Globerson, Amir and Chechik, Gal and Pereira, Fernando and Tishby, Naftali},
  journal={Journal of Machine Learning Research},
  volume={8},
  number={Oct},
  pages={2265--2295},
  year={2007}
}

@article{bengio2003neural,
  title={A neural probabilistic language model},
  author={Bengio, Yoshua and Ducharme, R{\'e}jean and Vincent, Pascal and Jauvin, Christian},
  journal={Journal of Machine Learning Research},
  volume={3},
  number={Feb},
  pages={1137--1155},
  year={2003}
}

@article{lan2009supervised,
  title={Supervised and traditional term weighting methods for automatic text categorization},
  author={Lan, Man and Tan, Chew Lim and Su, Jian and Lu, Yue},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={31},
  number={4},
  pages={721--735},
  year={2009},
  publisher={IEEE}
}

@inproceedings{levy2014dependency,
  title={Dependency-Based Word Embeddings.},
  author={Levy, Omer and Goldberg, Yoav},
  booktitle={ACL (2)},
  pages={302--308},
  year={2014}
}

@article{Rong14,    
  title={Word2vec parameter learning explained},
  author={Rong, Xin},
  journal={arXiv preprint arXiv:1411.2738},
  year={2014}
}

@inproceedings{pennington2014glove,
  author = {Jeffrey Pennington and Richard Socher and Christopher D. Manning},
  booktitle = {Empirical Methods in Natural Language Processing (EMNLP)},
  title = {GloVe: Global Vectors for Word Representation},
  year = {2014},
  pages = {1532--1543},
  url = {http://www.aclweb.org/anthology/D14-1162},
}

@article{robertson2004,
author = {Stephen Robertson},
title = {Understanding inverse document frequency: on theoretical arguments for IDF},
journal = {Journal of Documentation},
volume = {60},
number = {5},
pages = {503-520},
year = {2004},
abstract = { The term‐weighting function known as IDF was proposed in 1972, and has since been extremely widely used, usually as part of a TF*IDF function. It is often described as a heuristic, and many papers have been written (some based on Shannon's Information Theory) seeking to establish some theoretical basis for it. Some of these attempts are reviewed, and it is shown that the Information Theory approaches are problematic, but that there are good theoretical justifications of both IDF and TF*IDF in the traditional probabilistic model of information retrieval. }
}

@article{sparkJones1972,
author = {Sp\"ark Jones, Karen},
title = {A STATISTICAL INTERPRETATION OF TERM SPECIFICITY AND ITS APPLICATION IN RETRIEVAL},
journal = {Journal of Documentation},
volume = {28},
number = {1},
pages = {11-21},
year = {1972},
abstract = { The exhaustivity of document descriptions and the specificity of index terms are usually regarded as independent. It is suggested that specificity should be interpreted statistically, as a function of term use rather than of term meaning. The effects on retrieval of variations in term specificity are examined, experiments with three test collections showing in particular that frequently‐occurring terms are required for good overall performance. It is argued that terms should be weighted according to collection frequency, so that matches on less frequent, more specific, terms are of greater value than matches on frequent terms. Results for the test collections show that considerable improvements in performance are obtained with this very simple procedure. }
}
@article{arora2017simple,
  title={A simple but tough-to-beat baseline for sentence embeddings},
  author={Arora, Sanjeev and Liang, Yingyu and Ma, Tengyu},
  year={2017},
  journal={International Conference on Learning Representations (ICLR)}
}

@inproceedings{takase2016composing,
  title={Composing Distributed Representations of Relational Patterns},
  author={Takase, Sho and Okazaki, Naoaki and Inui, Kentaro},
  booktitle={Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  volume={1},
  pages={2276--2286},
  year={2016}
}

@article{LEVY20081126,
title = "Expectation-based syntactic comprehension",
journal = "Cognition",
volume = "106",
number = "3",
pages = "1126 - 1177",
year = "2008",
issn = "0010-0277",
doi = "https://doi.org/10.1016/j.cognition.2007.05.006",
url = "http://www.sciencedirect.com/science/article/pii/S0010027707001436",
author = "Roger Levy"}

@article{hale2006uncertainty,
  title={Uncertainty about the rest of the sentence},
  author={Hale, John},
  journal={Cognitive Science},
  volume={30},
  number={4},
  pages={643--672},
  year={2006},
  publisher={Wiley Online Library}
}

@article{hale2003information,
  title={The information conveyed by words in sentences},
  author={Hale, John},
  journal={Journal of Psycholinguistic Research},
  volume={32},
  number={2},
  pages={101--123},
  year={2003},
  publisher={Springer}
}

@article{frank2013uncertainty,
  title={Uncertainty reduction as a measure of cognitive load in sentence comprehension},
  author={Frank, Stefan L},
  journal={Topics in Cognitive Science},
  volume={5},
  number={3},
  pages={475--494},
  year={2013},
  publisher={Wiley Online Library}
}

@incollection{CHOMSKY1963118,
title = "The Algebraic Theory of Context-Free Languages*",
editor = "P. Braffort and D. Hirschberg",
series = "Studies in Logic and the Foundations of Mathematics",
publisher = "Elsevier",
volume = "35",
pages = "118 - 161",
year = "1963",
booktitle = "Computer Programming and Formal Systems",
issn = "0049-237X",
author = "N. Chomsky and M.P. Schützenberger"
}

@book{jurafsky2009speech,
  address = {Upper Saddle River, N.J.},
  author = {Jurafsky, Dan and Martin, James H.},
  isbn = {9780131873216 0131873210},
  publisher = {Pearson Prentice Hall},
  title = {Speech and language processing : an introduction to natural language processing, computational linguistics, and speech recognition},
  year = 2009
}

@Inbook{Baxter1998,
author="Baxter, Jonathan",
editor="Thrun, Sebastian
and Pratt, Lorien",
title="Theoretical Models of Learning to Learn",
bookTitle="Learning to Learn",
year="1998",
publisher="Springer US",
address="Boston, MA",
pages="71--94",
isbn="978-1-4615-5529-2"
}

@inproceedings{raina2007self,
  title={Self-taught learning: transfer learning from unlabeled data},
  author={Raina, Rajat and Battle, Alexis and Lee, Honglak and Packer, Benjamin and Ng, Andrew Y},
  booktitle={Proceedings of the 24th international conference on Machine learning},
  pages={759--766},
  year={2007},
  organization={ACM}
}

@inproceedings{wieting2017revisiting,
  title={Revisiting Recurrent Networks for Paraphrastic Sentence Embeddings},
  author={Wieting, John and Gimpel, Kevin},
  booktitle={Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  volume={1},
  pages={2078--2088},
  year={2017}
}


@article{YinSXZ15,
  author    = {Wenpeng Yin and
               Hinrich Sch{\"{u}}tze and Bing Xiang and
               Bowen Zhou},
  title     = {{ABCNN:} Attention-Based Convolutional Neural Network for Modeling
               Sentence Pairs},
  journal   = {CoRR},
  volume    = {abs/1512.05193},
  year      = {2015},
  url       = {http://arxiv.org/abs/1512.05193},
}

@techreport{arroyo2013protocolo,
  Title     
  = {Agrupamiento sem\'antico de definiciones en un espacio generado mediante aprendizaje de kernels},
  Author                   = {Arroyo-Fern\'andez, Ignacio},
  Institution                   = {Universidad Nacional Aut\'onoma de M\'exico},
  year                = {2013},
  type = {PhD Research project}
}

@incollection{arroyofernandez-mezaruiz2017SemEval,
  author    = {Arroyo-Fern\'{a}ndez, Ignacio  and  Meza Ruiz, Ivan Vladimir},
  title     = "{LIPN-IIMAS} at {SemEval}-2017 Task 1: Subword Embeddings, Attention Recurrent Neural Networks and Cross Word Alignment for Semantic Textual Similarity",
  booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
  month     = {August},
  year      = {2017},
  address   = {Vancouver, Canada},
  publisher = {Association for Computational Linguistics (ACL)},
  pages     = {199--203},
  abstract  = {In this paper we report our attempt to use, on the one hand, state-of-the-art
	neural approaches that are proposed to measure Semantic Textual Similarity
	(STS). On the other hand, we propose an unsupervised cross-word alignment
	approach, which is linguistically motivated. The neural approaches proposed
	herein are divided into two main stages. The first stage deals with
	constructing neural word embeddings, the components of sentence embeddings. The
	second stage deals with constructing a semantic similarity function relating
	pairs of sentence embeddings. Unfortunately our competition results were poor
	in all tracks, therefore we concentrated our research to improve them for Track
	5 (EN-EN).},
  url       = {http://www.aclweb.org/anthology/S17-2031}
}
@article{king2016unbnlp,
  title={UNBNLP at SemEval-2016 Task 1: Semantic Textual Similarity: A Unified Framework for Semantic Processing and Evaluation},
  author={King, Milton and Gharbieh, Waseem and Park, SoHyun and Cook, Paul},
  journal={Proceedings of SemEval},
  pages={732--735},
  year={2016}
}
@InProceedings{cerEtAl2017,
  author    = {Cer, Daniel  and  Diab, Mona  and  Agirre, Eneko  and  Lopez-Gazpio, Inigo  and  Specia, Lucia},
  title     = {SemEval-2017 Task 1: Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation},
  booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
  month     = {August},
  year      = {2017},
  address   = {Vancouver, Canada},
  publisher = {Association for Computational Linguistics},
  pages     = {1--14},
  abstract  = {Semantic Textual Similarity (STS) measures the meaning similarity of sentences.
	Pairwise scores are on an ordinal scale, conveying both a degree of similarity
	and a categorical interpretation. Applications include machine translation
	(MT), summarization, generation, question answering (QA), short answer grading,
	semantic search, dialog and conversational systems. While prior years
	emphasized English, the 2017 task focuses on the multilingual and cross-lingual
	setting. We find performance lags in less well studied STS languages and
	language pairings (e.g., Arabic). MT quality estimation (MTQE) data used for
	one of the tracks highlights the importance and difficultly of making fine
	grained distinctions. The task obtained strong participation from 31 teams,
	with 17 participating in {\em all  of the language tracks} for 2017. Research
	on sentence level similarity and semantic representations widely makes use of
	STS data. We introduce a new shared training and evaluation set, {\em STS
	Benchmark}, a multi-year a selection of English STS pairs (2012-2017), to
	facilitate and encourage consistent and interpretable model assessments.},
  url       = {http://www.aclweb.org/anthology/S17-2001}
}
@article{thuan2016,
 title={Open Information Extraction},
 author={Vo, Duc-Thuan and Bagheri, Ebrahim},
 organization={arXiv preprint arXiv:1607.02784},
 year={2016}
}
@inproceedings{fader2011identifying,
  title={Identifying relations for open information extraction},
  author={Fader, Anthony and Soderland, Stephen and Etzioni, Oren},
  booktitle={Proceedings of the Conference on Empirical Methods in Natural Language Processing},
  pages={1535--1545},
  year={2011},
  organization={Association for Computational Linguistics}
}
@article{angeli2015leveraging,
  title={Leveraging linguistic structure for open domain information extraction},
  author={Angeli, Gabor and Premkumar, Melvin Johnson and Manning, Christopher D},
  journal={Linguistics},
  number={1/24},
  year={2015}
}
@article{nenkova2007pyramid,
  title={The pyramid method: Incorporating human content selection variation in summarization evaluation},
  author={Nenkova, Ani and Passonneau, Rebecca and McKeown, Kathleen},
  journal={ACM Transactions on Speech and Language Processing (TSLP)},
  volume={4},
  number={2},
  pages={4},
  year={2007},
  publisher={ACM}
}
@inproceedings{nenkova:04,
  author 	= {Ani Nenkova and Rebecca J. Passonneau},
  title 	= {Evaluating Content Selection in Summarization: The Pyramid Method},
  booktitle 	= {{Conference of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL'04)}},
  month		= {May},
  year 		= {2004},
  address 	= {Boston, MA, USA},
  pages 	= {145-152}
}

@InProceedings{mikolov2014prhase,
  Title                    = {Distributed Representations of Sentences and Documents},
  Author                   = {Quoc Le and Tomas Mikolov},
  Booktitle                = {31st International Conference on Machine Learning, {ICML} 2014, Beijing, China, 21-26 June},
  Year                     = {2014},
  Pages                    = {1188--1196},
  Timestamp                = {Fri, 07 Nov 2014 20:42:30 +0100},
  Url                      = {http://jmlr.org/proceedings/papers/v32/le14.html}
}

@InProceedings{abend2014,
  Title                    = {Lexical Inference over Multi-Word Predicates: A Distributional Approach},
  Author                   = {Abend, Omri and Cohen, B. Shay and Steedman, Mark},
  Booktitle                = {52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  Year                     = {2014},
  Organization             = {ACL},
  Pages                    = {644--654},

  Location                 = {Baltimore, Maryland},
  Url                      = {http://aclweb.org/anthology/P14-1061}
}

@InCollection{Aggarwal2012,
  Title                    = {An Introduction to Text Mining},
  Author                   = {Aggarwal, Charu C. and Zhai, Cheng Xiang},
  Booktitle                = {Mining Text Data},
  Publisher                = {Springer US},
  Year                     = {2012},
  Editor                   = {Aggarwal, Charu C and Zhai, ChengXiang},
  Pages                    = {1-10},

  Doi                      = {10.1007/978-1-4614-3223-4_1},
  ISBN                     = {978-1-4614-3222-7},
  Language                 = {English},
  Url                      = {http://dx.doi.org/10.1007/978-1-4614-3223-4_1}
}

@InProceedings{aghazadeh2013properties,
  Title                    = {Properties of datasets predict the performance of classifiers},
  Author                   = {Aghazadeh, Omid and Carlsson, Stefan},
  Booktitle                = {British Machine Vision Conference},
  Year                     = {2013},
  Pages                    = {22--31}
}

@Article{aguilar1982,
  Title                    = {The process of classification and learning the meaning of linguistic descriptors of concepts},
  Author                   = {Aguilar-Martin, J and De M{\'a}ntaras, R},
  Journal                  = {Approximate Reasoning in Decision Analysis},
  Year                     = {1982},
  Pages                    = {165--175},
  Volume                   = {1982},

  Publisher                = {North-Holland, Amsterdam}
}

@Article{anandkumar2014tensor,
  Title                    = {Tensor decompositions for learning latent variable models},
  Author                   = {Anandkumar, Animashree and Ge, Rong and Hsu, Daniel and Kakade, Sham M and Telgarsky, Matus},
  Journal                  = {The Journal of Machine Learning Research},
  Year                     = {2014},
  Number                   = {1},
  Pages                    = {2773--2832},
  Volume                   = {15},

  Owner                    = {IArroyoF},
  Publisher                = {JMLR. org},
  Timestamp                = {2015.02.10}
}

@Article{andras2002,
  Title                    = {The equivalence of support vector machine and regularization neural networks},
  Author                   = {Andras, Peter},
  Journal                  = {Neural Processing Letters},
  Year                     = {2002},
  Number                   = {2},
  Pages                    = {97--104},
  Volume                   = {15},

  Publisher                = {Springer}
}

@Article{aronszajn1950,
  Title                    = {Theory of reproducing kernels},
  Author                   = {Aronszajn, Nachman},
  Journal                  = {Transactions of the American mathematical society},
  Year                     = {1950},
  Pages                    = {337--404},

  Publisher                = {JSTOR}
}

@InProceedings{arroyo2015embeddings,
  Title                    = {Learning Kernels for Distributional Semantics Embeddings},
  Author                   = {Arroyo-Fern{\'a}ndez, Ignacio},
  Booktitle                = {Consorcio de Posgrado del Encuentro Internacional del Ciencias de la Computaci\'on (ENC'2015)},
  Year                     = {2015},
  Organization             = {Sociedad Mexicana de Ciencias de la Computaci\'on (SMCC)},

  Owner                    = {iarroyof},
  Timestamp                = {2015.09.07}
}

@InProceedings{arroyo2015learning,
  Title                    = {Learning Kernels for Semantic Clustering: A Deep Approach},
  Author                   = {Arroyo-Fern{\'a}ndez, Ignacio},
  Booktitle                = {NAACL-HLT 2015 Student Research Workshop (SRW)},
  Year                     = {2015},
  Pages                    = {79--87}
}

@InCollection{bazavan2012,
  Title                    = {Fourier kernel learning},
  Author                   = {B{\u{a}}z{\u{a}}van, Eduard Gabriel and Li, Fuxin and Sminchisescu, Cristian},
  Booktitle                = {Computer Vision--ECCV 2012},
  Publisher                = {Springer},
  Year                     = {2012},
  Pages                    = {459--473},

  Owner                    = {nacho},
  Review                   = {At least for our aming, in this work we can observe one of the most advanced approaches in learning kernels field (Perhaps not too generalized since combinations of basis fuctions are exclusively linear). Given that here were joined conceptual generalizations, from the pionner approach of Lanckriet (2004) to more specific proposals (e.g. "learning sequence kernels", "learning rational kernels", "Learning nonlinear combinations of kernels" (Cortes, 2008)). Also the idea of kernel density estimation (e.g. Parzen window estimation (Jenssen, 2006; Gai, 2010), the Rademacher complexity (Cortes, 2013), Learning the Renyi's entropy kernel (from Theoretic Information Learning, Jenssen, 2006; Principe, 2010)) is highly related to the above mentioned. Such a relation connecting to all these and to the most sofisticated approaches (although possibily not so for Jain (2010) and some other metric-based approaches such as Lanckriet, 2014) is that there are optimized the coeffcients (or basis distribution parameters, called here hyperparameters for hyperkernels (Ong \& Smola et.al., 2005; Tsang et.al,2006)) of a linear combination of kernels which is indeed optimizing the coeffients of the Fourier series. Herein (Bazavan, 2012) it is treated a generalized framework of that concept and futhermore the idea of optimizing not in the original feature space (where convolution operation are expensive; Jenssen, 2006) but in the frequency domain (the Fourier domain) which is infact a RKHS. This last fact implies crucial benefits in terms of computational complexity (scaling) and precision. On one hand in RKHS, the operations between elements imply not significative modifications to the data distribution, given that they are not points in a high-dimensional space but continous and parametrized functions, so in the frequency domain operations become much more simple, convergence in a Hilbert space is ensured (the operation is closed and L2 regularization of the marging resulted with the best performance, also showed in Cortes, 2008) and few samples of these functions (conversely with the original dimensions or simple linear projections of these e.g. PCA, SVD, ICA, etc.) are needed in order to have proper representations. On the other hand, hyperparameters of a summation of predefined kernels are iterated (e.g. for the Gaussian kernel: amplitude, mean and variance; for the sinusoidal kernel: amplitude and frequency; etc.) in order to fit optimal decision boundaries via the transduction classifier (by the way, for multiclassification). The hyperparameters of the kernels however were not optimized better in L2. The election of the basis kernel set for the Fourier series was made via generating random indices from a more dense set of kernels (predefined and including its presupposed hyperparameters i.e. frequency band) by using a Monte Carlo sample drawn according to an uniform distribution. Other interesting feature of this framework is the confirmation of the usefulness of the multiple kernel schema. Different kinds of features were separately captured with corresponding different learned kernels (for images, a kernel for each well known patterns in pyramid levels of data: horizontal, vertical, diagonal and nonlinear borders), which is already proposed by Lanckried (2004) for textual data (two kernels: lexicon and concept-relations. Not thus considered in Cortes's papers on multikernel learning), showing again better performance than the monolitic kernel schema. Also the hypothesis of a regular shape through sets of different classes is questioned in this paper given that it is showed different spectral information for samples pertaining to different classes, which are in fact reliable affirmations at least for image data. Although the valuable information presented in this paper, the questioning of what predefined kernels are adequate for specific tasks is still remaining open, so in this case for images the use of square Chi (Skewed and generalized skewed intersection) and Gaussian kernels was not justified however this decision could be a bit more intuitive for images than for the case of textual data.},
  Timestamp                = {2014.12.27},
  Url                      = {http://link.springer.com/chapter/10.1007/978-3-642-33709-3_33#page-1}
}

@InProceedings{baktashmotlagh2013,
  Title                    = {Unsupervised domain adaptation by domain invariant projection},
  Author                   = {Baktashmotlagh, Mahsa and Harandi, Mehrtash T and Lovell, Brian C and Salzmann, Mathieu},
  Booktitle                = {Computer Vision (ICCV), 2013 IEEE International Conference on},
  Year                     = {2013},
  Organization             = {IEEE},
  Pages                    = {769--776}
}

@Article{baroni2010,
  Title                    = {Distributional memory: A general framework for corpus-based semantics},
  Author                   = {Baroni, Marco and Lenci, Alessandro},
  Journal                  = {Computational Linguistics},
  Year                     = {2010},
  Number                   = {4},
  Pages                    = {673--721},
  Volume                   = {36},

  Abstract                 = {Researchintocorpus-basedsemanticshasfocusedonthedevelopmentofadhocmodelsthattreat single tasks, or sets of closely related tasks, as unrelated challenges to be tackled by extracting differentkindsofdistributionalinformationfromthecorpus.Asanalternativetothis?onetask, onemodel?approach,theDistributionalMemoryframeworkextractsdistributionalinformation onceandforallfromthecorpus,intheformofasetofweightedword-link-wordtuplesarranged into a third-order tensor. Different matrices are then generated from the tensor, and their rows and columns constitute natural spaces to deal with different semantic problems. In this way, thesamedistributionalinformationcanbesharedacrosstaskssuchasmodelingwordsimilarity judgments, discovering synonyms, concept categorization, predicting selectional preferences of verbs, solving analogy problems, classifying relations between word pairs, harvesting qualia structures with patterns or example pairs, predicting the typical properties of concepts, and classifyingverbsintoalternationclasses.Extensiveempiricaltestinginallthesedomainsshows that a Distributional Memory implementation performs competitively against task-specific al- gorithms recentlyreportedin the literaturefor the same tasks, and against our implementations of several state-of-the-art methods. The Distributional Memory approach is thus shown to be tenabledespitetheconstraintsimposedbyitsmulti-purposenature.},
  Owner                    = {nacho},
  Publisher                = {MIT Press},
  Review                   = {Here we can find a generalization of Lapata 2007, where the semantic spase considering linguistic knowledge is in its childhood. Herein Baroni proposes the tensor model which although more general considering much orders of tensors as kinds of relations are in the text, is still very empirical, considering only relation between specific pairs of words instead of considering distributional relations between any pair of entities in the text. As sets of fibers of the tensors are fixed (setted latetd) the remaining one (only one) shows some desired kind of relation. Even when the approch is very general on the sense of language and kinds of meanings, the study made here led us as open problem the task of identify which kind of relations conrrespond to which kinds of words or more generally: how exactly to apply the model.},
  Timestamp                = {2014.12.27}
}

@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    year={2016}
}

@Article{ben-hur-vapnik2002,
  Title                    = {Support Vector Clustering},
  Author                   = {Ben-Hur, Asa and Horn, David and Siegelmann, Hava T and Vapnik, Vladimir},
  Journal                  = {The Journal of Machine Learning Research},
  Year                     = {2002},
  Pages                    = {125--137},
  Volume                   = {2},

  File                     = {:C\:\\Users\\Nacho\\Google Drive\\GIL\\pruebasBayes\\(2001) Support Vector Clustering [Ben-Hur - Horn - Siegelmann - Vapnik].pdf:PDF},
  Owner                    = {nacho},
  Publisher                = {JMLR. org},
  Timestamp                = {2014.12.27}
}

@InProceedings{blunsom2014deep,
  Title                    = {A deep architecture for semantic parsing},
  Author                   = {Blunsom, Phil and de Freitas, Nando and Grefenstette, Edward and Hermann, Karl Moritz and others},
  Booktitle                = {ACL 2014 Workshop on Semantic Parsing},
  Year                     = {2014},
  Organization             = {ACL}
}

@Article{tomas2014,
  Title                    = {Semantic Spaces for Improving Language Modelling},
  Author                   = {Tom\'a\u{s} Brychc\'in and Miroslav Konop\'ik},
  Journal                  = {Computer Speech and Language},
  Year                     = {2014},
  Pages                    = {192-209},
  Volume                   = {28},

  Eid                      = {Elsevier Ltd.},
  File                     = {:C\:\\Documents and Settings\\nacho\\Mis documentos\\Google Drive\\GIL\\pruebasBayes\\(2014) Semantic spaces for improving language modeling [Brychcin - Konopik].pdf:PDF},
  Owner                    = {nacho},
  Timestamp                = {2014.04.01}
}

@InProceedings{cabrera2016evaluating,
  Title                    = {Evaluating multiple summaries without human models: a first experiment with a trivergent model},
  Author                   = {Cabrera-Diego, Luis Adri\'an and Torres-Moreno, Juan-Manuel and Durette, Barth\'el\'emy},
  Booktitle                = {Proceedings of the 21st International conference on the Application of Natural Language to Information Systems},
  Organization = {NLDB},
  Year                     = {2016},
  Editor                   = {M\'etais, Elisabeth and Meziane, Farid and Saraee, Mohamed and Sugumaran, Vijay and Vadera, Sunil},
  Pages                    = {In press},

  Owner                    = {iarroyof},
  Timestamp                = {2016.05.28}
}

@InProceedings{carpuat2010task,
  Title                    = {Task-based evaluation of multiword expressions: a pilot study in statistical machine translation},
  Author                   = {Carpuat, Marine and Diab, Mona},
  Booktitle                = {Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics},
  Year                     = {2010},
  Organization             = {Association for Computational Linguistics},
  Pages                    = {242--245}
}

@InProceedings{chen2009fusing,
  Title                    = {Fusing similarities and kernels for classification},
  Author                   = {Chen, Yihua and Gupta, Maya R},
  Booktitle                = {Information Fusion, 2009. FUSION'09. 12th International Conference on},
  Year                     = {2009},
  Organization             = {IEEE},
  Pages                    = {474--481}
}

@Article{chitra2012study,
  Title                    = {A study on paraphrase recognition using radial basis function neural network},
  Author                   = {Chitra, A and Rajkumar, Anupriya},
  Journal                  = {IETE Journal of Research},
  Year                     = {2012},
  Number                   = {1},
  Pages                    = {50--56},
  Volume                   = {58},

  Publisher                = {Taylor \& Francis}
}

@Article{choi2012,
  Title                    = {Terminological paraphrase extraction from scientific literature based on predicate argument tuples},
  Author                   = {Choi, Sung-Pil and Myaeng, Sung-Hyon},
  Journal                  = {Journal of Information Science},
  Year                     = {2012},
  Pages                    = {1--19},

  Abstract                 = {Terminological paraphrases (TPs) are sentences or phrases that express the concepts of terminologies in a different form. Here we propose an effective way to identify and extract TPs from large-scale scientific literature databases. We propose a novel method for effectively retrieving sentences that contain a given terminological concept based on semantic units called predicate-argument tuples. This method enables effective textual similarity computations and minimized errors based on six TP ranking models. For evaluation, we constructed an evaluation collection for the TP recognition task by extracting TPs from a target literature database using the proposed method. Through the two experiments, we learned that scientific literature contain many TPs that could not have been identified so far. Also, the experimental results showed the potential and extensibility of our proposed methods to extract the TPs.},
  Doi                      = {10.1177/0165551512459920},
  Owner                    = {nacho},
  Publisher                = {Sage Publications},
  Review                   = {In this work we can find an interesting analysis about the paraphrses from a statistical and linguistic approach. This Linguistic phenomen (paraprahases) is present always there is ambiguity to any computing system, so likely it is precisely the principal motivation to so call our language "Natural language". In this way "terminological paraphrases" consists on diffrentet forms to conbine words in order to refer a concept. The authors designed a methodology to detect and extract terminological paraphrases from not structured text. Such a methodology consists first on determine the parse tree of sentences which in turn is the principal information source to formalize sets called PATs (Predicate Argument Tuples) that contain as arguments nouns or any other nonfunctional words whereas functional words are the names of the tuples acting as functions, not literally. Each PAT is used as feature of a bag-of-words-like vector space which is weighted via different modalities of "tfidf" according to the categories tagged by the parser onto the tuples. These (textual) vectors are compared via the cosine similarity measure and then it is empirically decided if two sets of PATs are paraphrases one from the other and viceversa.},
  Timestamp                = {2014.12.27},
  Url                      = {http://jis.sagepub.com/content/38/6/593.short}
}

@PhdThesis{cigarran2008,
  Title                    = {Organizaci\'on de resultados de b\'usqueda mediante an\'alisis formal de conceptos},
  Author                   = {Cigarr\'an Recuero, Juan Manuel},
  School                   = {Universidad Nacional de Educaci\'on a Distancia; Escuela T\'ecnica Superior de Ingenier\'ia Inform\'atica},
  Year                     = {2008},

  Owner                    = {nacho},
  Timestamp                = {2014.12.26}
}

@InProceedings{cortes2013learning,
  Title                    = {Learning Kernels Using Local Rademacher Complexity},
  Author                   = {Cortes, Corinna and Kloft, Marius and Mohri, Mehryar},
  Booktitle                = {Advances in Neural Information Processing Systems},
  Year                     = {2013},
  Pages                    = {2760--2768}
}

@InProceedings{cortes2009,
  Title                    = {L 2 regularization for learning kernels},
  Author                   = {Cortes, Corinna and Mohri, Mehryar and Rostamizadeh, Afshin},
  Booktitle                = {Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence},
  Year                     = {2009},
  Organization             = {AUAI Press},
  Pages                    = {109--116}
}

@Article{cortes1995support,
  Title                    = {Support-vector networks},
  Author                   = {Cortes, Corinna and Vapnik, Vladimir},
  Journal                  = {Machine Learning},
  Year                     = {1995},
  Number                   = {3},
  Pages                    = {273--297},
  Volume                   = {20},
  Publisher                = {Springer}
}

@Article{cybenko1989approximation,
  Title                    = {Approximation by superpositions of a sigmoidal function},
  Author                   = {Cybenko, George},
  Journal                  = {Mathematics of control, signals and systems},
  Year                     = {1989},
  Number                   = {4},
  Pages                    = {303--314},
  Volume                   = {2},

  Publisher                = {Springer}
}

@InProceedings{dai2014scalable,
  Title                    = {Scalable kernel methods via doubly stochastic gradients},
  Author                   = {Dai, Bo and Xie, Bo and He, Niao and Liang, Yingyu and Raj, Anant and Balcan, Maria-Florina F and Song, Le},
  Booktitle                = {Advances in Neural Information Processing Systems},
  Year                     = {2014},
  Pages                    = {3041--3049}
}

@InProceedings{dolan2005automatically,
  Title                    = {Automatically constructing a corpus of sentential paraphrases},
  Author                   = {Dolan, William B and Brockett, Chris},
  Booktitle                = {Proc. of IWP},
  Year                     = {2005}
}

@InProceedings{DrakeV14a,
  Title                    = {Using Spectral Features to Improve Sentiment Analysis},
  Author                   = {Adam Drake and Dan Ventura},
  Booktitle                = {13th International Conference on Machine Learning and Applications, {ICMLA} 2014, Detroit, MI, USA, December 3-6, 2014},
  Year                     = {2014},
  Pages                    = {153--158},

  Doi                      = {10.1109/ICMLA.2014.29},
  Timestamp                = {Wed, 25 Feb 2015 15:27:30 +0100}
}

@Book{duda:00,
  Title                    = {Pattern classification},
  Author                   = {Duda, Richard O and Hart, Peter E and Stork, David G},
  Publisher                = {John Wiley \& Sons},
  Year                     = {2012}
}

@Article{erk2012,
  Title                    = {Vector space models of word meaning and phrase meaning: A survey},
  Author                   = {Erk, Katrin},
  Journal                  = {Language and Linguistics Compass},
  Year                     = {2012},
  Number                   = {10},
  Pages                    = {635--653},
  Volume                   = {6},

  Publisher                = {Wiley Online Library}
}

@Article{fernandez2007,
  Title                    = {Textual energy of associative memories: Performant applications of enertex algorithm in text summarization and topic segmentation},
  Author                   = {Fernandez, Silvia and San Juan, Eric and Torres-Moreno, Juan-Manuel},
  Journal                  = {MICAI 2007: Advances in Artificial Intelligence},
  Year                     = {2007},
  Pages                    = {861--871},

  Owner                    = {nacho},
  Publisher                = {Springer Berlin/Heidelberg},
  Timestamp                = {2014.12.27}
}

@InProceedings{fernando2008semantic,
  Title                    = {A semantic similarity approach to paraphrase detection},
  Author                   = {Fernando, Samuel and Stevenson, Mark},
  Booktitle                = {Proceedings of the 11th Annual Research Colloquium of the UK Special Interest Group for Computational Linguistics},
  Year                     = {2008},
  Pages                    = {45--52}
}

@InProceedings{ferrone2014,
  Title                    = {Towards Syntax-aware Compositional Distributional Semantic Models},
  Author                   = {Ferrone, Lorenzo and Zanzotto, Fabio Massimo},
  Booktitle                = {Proceedings of COLING 2014: Technical Papers},
  Year                     = {2014},
  Pages                    = {721--730},
  Publisher                = {Dublin City University and Association for Computational Linguistics (ACL)},

  Owner                    = {nacho},
  Review                   = {In this work we can see a similar work to that of Lapata (2007) with the difference that it is used estructural kernels from kernel methods. In more detail, the componsitionality is proposed both from the syntactic level and semantic level. The former in the form of a tree given by a POS tagger and the second by the distributional word vectors (from a traditional DSM of word coocurrence, in the sense of Lapata and Baroni). These two features are combined via a structural kernel which is capable of computing low rank distributional compositional vectors (structural semantic vectors) based on a given parsed tree and distributional word vectors (Distributed Smoothed Trees, DSTs, in compounding). Semantic similarity between sentences (not only phrases as regularly is made since works of Lapata 2010 and Baroni 2014) is computed by using the Frobenius product between matrices representing two DTSs which in turn represent two sentences. Even if number of nodes in both trees (or sub-trees) is not the same the method considers matrices encoding structure and semantics, futhermore overlaping estructures between structures which is allowed by the kernel approach. Results related to keep almost the correlation with human judjements are competitive in comparison with compositional operations (mainly elementwise vector product and vector addition) introduced by Lapata (2010), however much more complex calculations (due to the estructures) but with a much more adequate theoretical justification. These methods were compared at the same proposed corpora (although different to that of Lapata (2010)).},
  Timestamp                = {2014.12.27},
  Url                      = {http://www.aclweb.org/anthology/C14-1068}
}

@Article{Figueroa2012,
  Title                    = {Contextual Language Models for Ranking Answers to Natural Language Definition Questions},
  Author                   = {Alejandro Figueroa and John Atkinson},
  Journal                  = {Computational Intelligence},
  Year                     = {2012},
  Pages                    = {528-548},

  Abstract                 = {Question?answering systems make good use of knowledge bases (KBs, e.g., Wikipedia) for responding to definition queries. Typically, systems extract relevant facts from articles regarding the question across KBs, and then they are projected into the candidate answers. However, studies have shown that the performance of this kind of method suddenly drops, whenever KBs supply narrow coverage. This work describes a new approach to deal with this problem by constructing context models for scoring candidate answers, which are, more precisely, statistical n-gram language models inferred from lexicalized dependency paths extracted from Wikipedia abstracts. Unlike state-of-the-art approaches, context models are created by capturing the semantics of candidate answers (e.g., ?novel,??singer,??coach,? and ?city?). This work is extended by investigating the impact on context models of extra linguistic knowledge such as part-of-speech tagging and named-entity recognition. Results showed the effectiveness of context models as n-gram lexicalized dependency paths and promising context indicators for the presence of definitions in natural language texts},
  Owner                    = {nacho},
  Review                   = {In this work we saw an approach which is seemed to an idea that we have proposed sometime ago. Figueroa calls this idea The contex language model which basicaly consists in vectorize different aspects of classes of langage present in a definitional answer or, more generally, a defintional sentence. Above features are obtained from a knowledge base (enterely reasonable) which is a corpus anotated by specific domain (wikipedia). Such a domain must be specified in query time; for instance: "what is a computer virus?" The idea is very simple (like in Aletras, 2014): construct a dependency-based distributional estrucuture based on the lexicon (context model), forming classes of contexts in which the most relevant terms (context indicators) can be ordered and parametrized considering sinonym (or paraphased) low rated lexical constructions as not relevant information and then discarded. It is important to be aware that the class of context is a structure that represents general information in which the lexicon is probabilisticaly disposed GIVEN a specific domain. A distributional structure is built (as mentioned above) for each new answer candidate which is paired (and rated) to each previously created context model (context patterns), so the method determines the <<link strength>> between the context model and each entering distributional structure built for candidates in order to rank them from the strongest. The output is in fact above ranked answers. The topic (called definiendum in this paper) is implicitly an input for the algorithm. This approach is very brilliant although it has still a disadvantage which is raised from the need of corpus and prior knowledge of a global finite set of categories.},
  Timestamp                = {2014.12.27},
  Url                      = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-8640.2012.00426.x/pdf}
}

@Article{Figueroa2014,
  Title                    = {Category-specific models for ranking effective paraphrases in community Question Answering},
  Author                   = {Figueroa, Alejandro and Neumann, G{\"u}nter},
  Journal                  = {Expert Systems with Applications},
  Year                     = {2014},
  Number                   = {10},
  Pages                    = {4730--4742},
  Volume                   = {41},

  Publisher                = {Elsevier}
}

@InProceedings{gu2011multitaskCluster,
  Title                    = {Learning a Kernel for Multi-Task Clustering.},
  Author                   = {Gu, Quanquan and Li, Zhenhui and Han, Jiawei},
  Booktitle                = {Proceedings of the 25th AAAI conference on artificial intelligence},
  Year                     = {2011},
  Organization             = {Association for the Advancement of Artificial Intelligence (AAAI)}
}

@MastersThesis{ximenistli2012,
  Title                    = {Quantifying Determiners from the Distributional Semantics View},
  Author                   = {Ximena Guti\'errez-Vasques},
  School                   = {Charles University in Prague},
  Year                     = {2012},

  Owner                    = {iarroyof},
  Timestamp                = {2015.08.10}
}

@Article{han2013umbc,
  Title                    = {UMBC EBIQUITY-CORE: Semantic textual similarity systems},
  Author                   = {Han, Lushan and Kashyap, Abhay and Finin, Tim and Mayfield, James and Weese, Jonathan},
  Journal                  = {Atlanta, GA, USA},
  Year                     = {2013},
  Volume                   = {44}
}

@Book{harris1968,
  Title                    = {Mathematical Structures of Language},
  Author                   = {Harris, Zellig S.},
  Publisher                = {Wiley},
  Year                     = {1968},

  Address                  = {New York, NY, USA},

  Keywords                 = {language, semantics},
  Owner                    = {IArroyoF},
  Timestamp                = {2015.01.21}
}

@InProceedings{hashimoto2011,
  Title                    = {Extracting paraphrases from definition sentences on the web},
  Author                   = {Hashimoto, Chikara and Torisawa, Kentaro and De Saeger, Stijn and Kazama, Jun'ichi and Kurohashi, Sadao},
  Booktitle                = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1},
  Year                     = {2011},
  Pages                    = {1087--1097},

  Owner                    = {nacho},
  Review                   = {In this paper is shown an interesting approach that makes a compound between contextual, syntactical and lexical features of definition sentences. Such features are computed from a corpus exclusively from a subset of the whole sentence paraphrases in order to train a binary classifier whose purpose is to predict paraphrasing onto a test set of candidate pairs. Herein is mentioned the engineered constitution of 78 features aproximately a half describing contextual aspects (mainly coming from a POS tagger and from different levels of it (Ferrone 2014; Weeds 2014)) and a half describing lexical aspects from which were selected only 17 via using "ablation" tests (which were not given details about). The ablation-selected features also have an approximated proportion of 50-50% describing the mentioned aspects. Not were vectorized the words in any usual bag-of-words way. Even when the method is largely feasible in gist, perhaps it is convenient to perform more tests over a more complex set of paraphrases (other kinds of higher order given that here is not specified the kind of paraphrases but it is noticed at least lexical (called trivial) and some interchanges (caled nontrivial)), even when some conbinations of sentences were tested (nondefintionals coming from the web) and definitional with different degree of lexical interchanges. Even results show a significative negativity in the performance tilt as complexity and amount of expressions grow up and also a stacionarity in 60% of precision as both quantities keep growing, so it is noticed taht the method is highly sensitive to de data amount (possibly as noise and variance in features increase towards not learned levels) although dimensions are low and there is classification problem. Maybe playing with some parameters (or hyperparameters such as kernels) in the training this method could be easily improved given that there was not shown more tests about it. Results were not so bad, many feature weights were not optimized and an almost manual feature selection porcess was performed ("engineered" and aware of linguistic knowledge).},
  Timestamp                = {2014.12.27}
}

@InProceedings{jain2010inductive,
  Title                    = {Inductive regularized learning of kernel functions},
  Author                   = {Jain, Prateek and Kulis, Brian and Dhillon, Inderjit S},
  Booktitle                = {Advances in Neural Information Processing Systems},
  Year                     = {2010},
  Pages                    = {946--954},

  Owner                    = {nacho},
  Review                   = {In this work the learning kernel problem is limited to find optimal parameters of the kernelized Malahanobis distance function, so the approach indeed is highly seemed to that of Lanckrinet and Cortes however herein efforts are cented in a unique kernel: the variance matrix of the Malahanobis distance which is a parametrized elliptical ball. It can be even seen as a summation of elliptical features, as in Lanckrinet and Cortes. One of the proposals to learn the Malahanobis kernel is similar to that of Lanckrinet's transduction setup. Training (optimizing) de transductor (the distance function with the variance matrix within) by iteratively comparing sets of well known dissimilar vectors and so also with well known similar vectors. The spectrum of the dissimilarities is fitted (although with unknown bounds) by the variance matrix. This approach results too interesting to our proposal, given that it is taken in account buth the spectrum of data and the spanned metric vector space via the kernelization of the Malahanobis distance, which is embedded into a KNN classifier. However, it is not treated the problem of different kinds of features although a supervised kernel feature selection algorithm is proposed (The Learned Low Rank Transformation; also based on the Malahanobis distance kernelization) and quantitatively compared outperforming to that of kernel-PCA.},
  Timestamp                = {2014.12.27},
  Url                      = {http://research.microsoft.com/pubs/157839/kernel_nips10.pdf}
}

@InProceedings{jenssen2006,
  Title                    = {Kernel maximum entropy data transformation and an enhanced spectral clustering algorithm},
  Author                   = {Jenssen, Robert and Eltoft, Torbj{\o}rn and Girolami, Mark and Erdogmus, Deniz},
  Booktitle                = {Advances in Neural Information Processing Systems},
  Year                     = {2006},
  Pages                    = {633--640},

  Abstract                 = {We propose a new kernel-based data transformation technique. It is founded on the principle of maximum entropy (MaxEnt) preservation, hence named kernel MaxEnt. The key measure is Renyis entropy estimated via Parzen windowing. We show that kernel MaxEnt is based on eigenvectors, and is in that sense similar to kernel PCA, but may produce strikingly different transformed data sets. An enhanced spectral clustering algorithm is proposed, by replacing kernel PCA by kernel MaxEnt as an intermediate step. This has a major impact on performance.},
  Owner                    = {nacho},
  Review                   = {In this work a kernel optimization method is presented to processing toy data (not for text). The importance of this is because the Renyi's entropy is considered in order to calculate the spectrum from uniquely the covariance matrix of the original data. Given this information the Parzen's window size (the variance $\sigma$) is calculated in order to calculate the eigenvectors of the Rengi's entropy (Principe, 2010) of the input data (via the convolution theorem) with respect to the Gaussian kernel defined by the calculated hyperparameter $\sigma$. This transformation yields to almost orthogonal clusters of the transformed data (Parzen estimations like in Principe (2010)). Clusters are computed via cosine distance between estimations. There is still not justificated using the Gaussian kernel and furthermore data are of regular shapes (toys) easily maintaining high spectral similarity with used kernel. In this case their method could be considered a light modification from the original kernel PCA (from Sch\"olkopf) which in fact can be easily modified in order to attain similar or even better results.},
  Timestamp                = {2014.12.27},
  Url                      = {http://machinelearning.wustl.edu/mlpapers/paper_files/NIPS2006_293.pdf}
}

@InProceedings{ji2013discriminative,
  Title                    = {Discriminative Improvements to Distributional Sentence Similarity.},
  Author                   = {Ji, Yangfeng and Eisenstein, Jacob},
  Booktitle                = {EMNLP},
  Year                     = {2013},
  Pages                    = {891--896}
}

@Article{Kalchbrenner2014,
  Title                    = {A Convolutional Neural Network for Modelling Sentences},
  Author                   = {Nal Kalchbrenner and Edward Grefenstette and Phil Blunsom},
  Journal                  = {Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics},
  Year                     = {2014},

  Month                    = {June},

  Location                 = {Baltimore, USA},
  Url                      = {http://goo.gl/EsQCuC}
}

@Article{Lanckriet2004,
  Title                    = {Learning the Kernel Matrix with Semidefinite Programming},
  Author                   = {Lanckriet, Gert R. G. and Cristianini, Nello and Bartlett, Peter and Ghaoui, Laurent El and Jordan, Michael I.},
  Journal                  = {J. Mach. Learn. Res.},
  Year                     = {2004},

  Month                    = dec,
  Pages                    = {27--72},
  Volume                   = {5},

  Acmid                    = {1005334},
  ISSN                     = {1532-4435},
  Issue_date               = {12/1/2004},
  Numpages                 = {46},
  Owner                    = {nacho},
  Publisher                = {JMLR.org},
  Review                   = {In this work the most general learning kernel algorithm is proposed, to the best of our knowledge. It is based on the setting up of the kernel machine (classifier) as objective function of a SDP (SemiDefinite Program over a transductor). This arrangement approximates a kernel function by fitting the spectrum of a non linearly separable training data by using a summation of Gaussians (as initial guesses), that is, the input set is associated to a desired output vector, then the spectrum of the implied decision boundary is detected and used as guide to learn weights of Gaussians that build a weighted linear combination that approximates mentioned boundary. The above fitting is carried out via the optimization of a performance function of the transducer setting. It is supposed that there are different vector representations of the text that contributes to the right classification: the frequency of ocurrence of words by document (bag-of-words) and the relations between concepts (previously identified) stored as nodes of a weighted graph. Therefore, results are promising when each term of the linear conbination of Gaussians is assigned to be fitted according to each one of mentioned vector representations (two in this work: K= u*K_1 + u*K_2), so the output space suggests a linear combination of different feature spaces (VSMs representing different kind of features). This combination approach is according to the Harris's hypothesis: It must be learned separately different aspects of language. Even when there is a wide theoretical justification, there is not a feasible justification of the Gaussian kernels as initial guesses and neither it is not learned a kernel K but rather is learned a set of weights for predefined kernels K_1 and K_2 wich indeed are linearly combined to build a new kernel K. However, Why a Gaussian kernel? Data has Gaussian spectra in the selected feature spaces? Other highlight of this paper is that the embedding is made for binary classification tasks so experiments also. It would be interesting to see how the algorithm behaves in multiclassification or even in clustering tasks, also using the obtained kernel in the kernel-PCA preprocessing.},
  Timestamp                = {2014.12.27},
  Url                      = {http://dl.acm.org/citation.cfm?id=1005332.1005334}
}

@Article{landauer1998,
  Title                    = {An Introduction to Latent Semantic Analysis},
  Author                   = {Landauer, Thomas K. and Foltz, Peter W. and Laham, Darrell},
  Journal                  = {Discourse Processes},
  Year                     = {1998},
  Number                   = {2-3},
  Pages                    = {259-284},
  Volume                   = {25}
}

@Book{lara2006curso,
  Title                    = {Curso de lexicolog{\'\i}a},
  Author                   = {Lara, Luis Fernando},
  Publisher                = {El Colegio de M{\'e}xico},
  Year                     = {2006}
}

@InProceedings{lau2014,
  Title                    = {Learning Word Sense Distributions, Detecting Unattested Senses and Identifying Novel Senses Using Topic Models},
  Author                   = {Jey Han Lau and Paul Cook and Diana McCarthy and Spandana Gella and Timothy Baldwin},
  Booktitle                = {Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, {ACL} 2014},
  Year                     = {2014},
  Pages                    = {259--270},
  Volume                   = {1},

  Abstract                 = {Unsupervised word sense disambiguation (WSD) methods are an attractive approach to all-words WSD due to their non-reliance on expensive annotated data. Unsuper- vised estimates of sense frequency have been shown to be very useful for WSD due to the skewed nature of word sense distri- butions. This paper presents a fully unsu- pervised topic modelling-based approach to sense frequency estimation, which is highly portable to different corpora and sense inventories, in being applicable to any part of speech, and not requiring a hi- erarchical sense inventory, parsing or par- allel text. We demonstrate the effective- ness of the method over the tasks of pre- dominant sense learning and sense distri- bution acquisition, and also the novel tasks of detecting senses which aren?t attested in the corpus, and identifying novel senses in the corpus which aren?t captured in the sense inventory},
  Bibsource                = {dblp computer science bibliography, http://dblp.org},
  Biburl                   = {http://dblp.uni-trier.de/rec/bib/conf/acl/LauCMGB14},
  Owner                    = {nacho},
  Review                   = {In this work we have find an application highly seemed to our thesis (It is also seemed in general to the WSI task estudied by Goyal \& Hovy 2014 and seemed to Figueroa 2012). The idea is to induce statistics corresponding to the senses of specific terms which is called "topic modelling". It is based on scoring predominant lexical (multinomial) lexical distributions for each detected topic for a particular term and then map each multinomial (corresponding to a topic) to a Latent Dirichlet Allocation (LDA), unlike our proposal which is intended to model topics independently from any treated term. Even when it is not the task we are looking for, it would be very useful for the task of construction of our corpus in the case of failure of the wikipedia approach that we have proposed to this end. Given that topics are frequenly associated to Dirichlet processes, it raises the question that if we sould consider this to our thesis?},
  Timestamp                = {Wed, 15 Oct 2014 02:42:14 +0200},
  Url                      = {http://aclweb.org/anthology/P/P14/P14-1025.pdf}
}

@InProceedings{angelikova2013,
  Title                    = {Compositional-ly Derived Representations of Morphologically Complex Words in Distributional Semantics},
  Author                   = {Lazaridou, Angeliki and Marelli, Marco and Zamparelli, Roberto and Baroni, Marco},
  Booktitle                = {Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  Year                     = {2013},
  Pages                    = {1517--1526},

  Url                      = {http://www.aclweb.org/anthology/P13-1149}
}

@InProceedings{lin:2004rpa,
  Title                    = {ROUGE: A Package for Automatic Evaluation of Summaries},
  Author                   = {Lin, Chin-Yew},
  Booktitle                = {Workshop Text Summarization Branches Out (ACL'04)},
  Year                     = {2004},

  Address                  = {Barcelona, Spain},
  Editor                   = {Marie-Francine Moens and Stan Szpakowicz},
  Month                    = {Jul},
  Pages                    = {74-81},
  Publisher                = {ACL},

  Owner                    = {iarroyof},
  Timestamp                = {2016.05.28}
}

@Article{louis:13,
  Title                    = {Automatically Assessing Machine Summary Content Without a Gold Standard},
  Author                   = {Louis, Annie and Nenkova, Ani},
  Journal                  = {Computational Linguistics},
  Year                     = {2013},
  Number                   = {2},
  Pages                    = {267--300},
  Volume                   = {39},

  Address                  = {Cambridge, MA, USA},
  ISSN                     = {0891-2017},
  Issue_date               = {June 2013},
  Numpages                 = {34},
  Owner                    = {iarroyof},
  Publisher                = {MIT Press},
  Timestamp                = {2016.05.28}
}

@InProceedings{louis-nenkova:2009:EMNLP,
  Title                    = {Automatically Evaluating Content Selection in Summarization without Human Models},
  Author                   = {Louis, Annie and Nenkova, Ani},
  Booktitle                = {Conference on Empirical Methods in Natural Language Processing},
  Year                     = {2009},

  Address                  = {Singapore},
  Month                    = {6-7 Aug},
  Pages                    = {306-314},
  Publisher                = {ACL},

  Owner                    = {iarroyof},
  Timestamp                = {2016.05.28}
}

@Inbook{Chen2005,
author="Chen, Hsinchun
and Fuller, Sherrilynne S.
and Friedman, Carol
and Hersh, William",
editor="Chen, Hsinchun
and Fuller, Sherrilynne S.
and Friedman, Carol
and Hersh, William",
title="Knowledge Management, Data Mining, and Text Mining in Medical Informatics",
bookTitle="Medical Informatics: Knowledge Management and Data Mining in Biomedicine",
year="2005",
publisher="Springer US",
address="Boston, MA",
pages="3--33",
abstract="In this chapter we provide a broad overview of selected knowledge management, data mining, and text mining techniques and their use in various emerging biomedical applications. It aims to set the context for subsequent chapters. We first introduce five major paradigms for machine learning and data analysis including: probabilistic and statistical models, symbolic learning and rule induction, neural networks, evolution-based algorithms, and analytic learning and fuzzy logic. We also discuss their relevance and potential for biomedical research. Example applications of relevant knowledge management, data mining, and text mining research are then reviewed in order including: ontologies; knowledge management for health care, biomedical literature, heterogeneous databases, information visualization, and multimedia databases; and data and text mining for health care, literature, and biological data. We conclude the paper with discussions of privacy and confidentiality issues of relevance to biomedical data mining.",
isbn="978-0-387-25739-6",
doi="10.1007/0-387-25739-X_1",
url="https://doi.org/10.1007/0-387-25739-X_1"
}

@article{soto2016panorama,
  title={Panorama epidemiol{\'o}gico de M{\'e}xico, principales causas de morbilidad y mortalidad},
  author={Soto-Estrada, Guadalupe and Moreno-Altamirano, Laura and Pahua D{\'\i}az, Daniel},
  journal={Revista de la Facultad de Medicina (M{\'e}xico)},
  volume={59},
  number={6},
  pages={8--22},
  year={2016},
  publisher={Universidad Nacional Aut{\'o}noma de M{\'e}xico, Facultad de Medicina}
}

@article{villasenor2020pulmondb,
  title={PulmonDB: a curated lung disease gene expression database},
  author={Villase{\~n}or-Altamirano, Ana B and Moretto, Marco and Maldonado, Mariel and Zayas-Del Moral, Alejandra and Mungu{\'\i}a-Reyes, Adri{\'a}n and Romero, Yair and Garc{\'\i}a-Sotelo, Jair S and Aguilar, Luis A and Aldana-Assad, Oscar and Engelen, Kristof and others},
  journal={Scientific Reports},
  volume={10},
  number={1},
  pages={1--9},
  year={2020},
  publisher={Nature Publishing Group}
}

@article{wang2019natural,
  title={Natural language processing for populating lung cancer clinical research data},
  author={Wang, Liwei and Luo, Lei and Wang, Yanshan and Wampfler, Jason and Yang, Ping and Liu, Hongfang},
  journal={BMC medical informatics and decision making},
  volume={19},
  number={5},
  pages={239},
  year={2019},
  publisher={Springer}
}

@article{MARIR20161256,
title = "Mining the Web and Literature to Discover New Knowledge about Diabetes",
journal = "Procedia Computer Science",
volume = "83",
pages = "1256 - 1261",
year = "2016",
note = "The 7th International Conference on Ambient Systems, Networks and Technologies (ANT 2016) / The 6th International Conference on Sustainable Energy Information Technology (SEIT-2016) / Affiliated Workshops",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2016.04.261",
url = "http://www.sciencedirect.com/science/article/pii/S1877050916302940",
author = "Farhi Marir and Huwida Said and Feras Al-Obeidat",
keywords = "Text Mining, Research papers, Diabetes, Social Networks",
abstract = "Social Networks are powerful social media for sharing information about various issues and can be used to raise awareness and collect pointers about associated risk factors and preventive measures in chronical disease like diabetes. Since the olden times, knowledge in medicine was established through recording and analysing human experiences. This paper presents the results of text mining techniques of more than five hundred thousands of texts retrieved from social networks, blogs, forums, and also research papers from MEDLINE database to discovering new knowledge related to diabetes disease covering symptoms and treatments. The text mining approach consists of two tasks, descriptive and predictive. The descriptive task was to identify explicit references to the diabetes diseases diagnosis and treatments, whereas the predictive task focused on the prediction of the diabetes disease status when the evidence was not explicitly asserted. The findings are then compared to the standard diabetes diagnosis and treatments and only those which are not listed in the standards are retained as hypothesis for further validation by clinicians and medical researchers in the domain of diabetic disease."
}

@article{Cardie_1997, title={Empirical Methods in Information Extraction}, volume={18}, url={https://www.aaai.org/ojs/index.php/aimagazine/article/view/1322}, DOI={10.1609/aimag.v18i4.1322}, abstractNote={This article surveys the use of empirical, machine-learning methods for a particular natural language-understanding task-information extraction. The author presents a generic architecture for information-extraction systems and then surveys the learning algorithms that have been developed to address the problems of accuracy, portability, and knowledge acquisition for each component of the architecture.}, number={4}, journal={AI Magazine}, author={Cardie, Claire}, year={1997}, month={Dec.}, pages={65} }

@book{manning1999foundations,
  title={Foundations of statistical natural language processing},
  author={Manning, Christopher D and Manning, Christopher D and Sch{\"u}tze, Hinrich},
  year={1999},
  publisher={MIT press}
}

@Article{luong2013better,
  Title                    = {Better word representations with recursive neural networks for morphology},
  Author                   = {Luong, Minh-Thang and Socher, Richard and Manning, Christopher D},
  Journal                  = {CoNLL-2013},
  Year                     = {2013},
  Volume                   = {104}
}

@Book{manning2009,
  Title                    = {An Introduction to Information Retrieval},
  Author                   = {Manning, Christopher D. and Raghavan, Prabhakar and Sch\"utze, Hinrich},
  Publisher                = {Cambridge University Press},
  Address					={Cambridge, United Kingdom},
  Year                     = {2009},
  Timestamp                = {2014.03.10}
}

@Book{manolakis2005statistical,
  Title                    = {Statistical and adaptive signal processing: spectral estimation, signal modeling, adaptive filtering, and array processing},
  Author                   = {Manolakis, Dimitris G and Ingle, Vinay K and Kogon, Stephen M},
  Publisher                = {Artech House Norwood},
  Year                     = {2005},
  Volume                   = {46},

  Owner                    = {iarroyof},
  Timestamp                = {2015.10.26}
}

@Article{meyer2002,
  Title                    = {Laws and theories in quantitative linguistics},
  Author                   = {Meyer, Peter},
  Journal                  = {Glottometrics},
  Year                     = {2002},
  Pages                    = {62--80},
  Volume                   = {5}
}

@Article{mikolov2013efficient,
  Title                    = {Efficient estimation of word representations in vector space},
  Author                   = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  Journal                  = {arXiv preprint arXiv:1301.3781},
  Year                     = {2013}
}

@InProceedings{mikolov2013distributed,
  Title                    = {Distributed representations of words and phrases and their compositionality},
  Author                   = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
  Booktitle                = {Advances in Neural Information Processing Systems},
  Year                     = {2013},
  Pages                    = {3111--3119},

  Abstract                 = {We propose two novel model architectures for computing continuous vector repre- sentations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previ- ously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art perfor- mance on our test set for measuring syntactic and semantic word similarities.}
}

@Article{lapata2010,
  Title                    = {Composition in Distributional Models of Semantics},
  Author                   = {Jeff Mitchell and Mirella Lapata},
  Journal                  = {Cognitive Science},
  Year                     = {2010},
  Note                     = {Cognitive Science Society, ISSN: 1551-6709},
  Number                   = {34},
  Pages                    = {1388-1429},
  Volume                   = {34},

  File                     = {:C\:\\Documents and Settings\\nacho\\Mis documentos\\Google Drive\\GIL\\pruebasBayes\\(2010) Composition in distributional models of semantics [Mitchell - Lapata].pdf:PDF},
  Owner                    = {nacho},
  Review                   = {Aqui puedo encontrar las referencias de los origenes de todo lo referente a espacios sem?nticos, semantica distribucional, composicionalidad sem?ntica latente y espacios vectoriales para representar la sem?ntica. Esplicaciones del porque un espacio sem?ntico clasico no funciona bien para establecer relaciones como "Beto ama a Mary" != "Mary ama a Beto". La necesidad de involucrar el orden sint?ctico de los elementos de una frace para detectar tal diferencia.},
  Timestamp                = {2014.03.14}
}

@Article{Molina2009,
  Title                    = {Agrupamiento sem{\'a}ntico de contextos definitorios},
  Author                   = {Molina, A},
  Journal                  = {M{\'e}moire de Master, Universidad Nacional Aut{\'o}noma de M{\'e}xico--Posgrado en Ciencia e Ingenier{\'\i}a de la Computaci{\'o}n, M{\'e}xico},
  Year                     = {2009},
  Volume                   = {108},

  Owner                    = {nacho},
  Review                   = {S?lo se usan 4 terminos cada uno con 3700 resultados de definiciones que no necesariamente son todas definiciones, de hecho asume que muchas no lo son ("cantidad importante de ruido"). La justificaci?n para esta cantidad de datos es que el objetivo es que un humano los lea y el hecho de trabajar con m?s datos dificultar?a su visualizaci?n, demanera que debe trabajarse bajo esas restricciones orientadas a dicha aplicaci?n. El espacio vectorial se contruye en base a presencia y ausencia de palabras en las definiciones, aplicando despu?s el esquema de Energ?a textual y con ello clustering jer?rquico. Seria bueno usar este esquema como baseline e incluirlo en los experimentos, no sin antes preguntar si el c?digo est? disponible. En caso contrario ver la posibilidad de que un alumno lo desarrolle.},
  Timestamp                = {2014.12.27},
  Url                      = {http://132.248.9.195/ptd2009/junio/0645439/Index.html}
}

@Article{Nenkova:07,
  Title                    = {The Pyramid Method: Incorporating human content selection variation in summarization evaluation},
  Author                   = {Nenkova, Ani and Passonneau, Rebecca and McKeown, Kathleen},
  Journal                  = {ACM Transactions on Speech Language Processing},
  Year                     = {2007},
  Number                   = {2},
  Pages                    = {1--23},
  Volume                   = {4},
  ISSN                     = {1550-4875},
  Owner                    = {iarroyof},
  Publisher                = {ACM Press, New York},
  Timestamp                = {2016.05.28}
}

@Article{nyquist1924certain,
  Title                    = {Certain Factors Affecting Telegraph Speed},
  Author                   = {Nyquist, Harry},
  Journal                  = {Bell System Technical Journal},
  Year                     = {1924},
  Number                   = {2},
  Pages                    = {324--346},
  Volume                   = {3},

  Publisher                = {Wiley Online Library}
}

@InProceedings{ong2005learning,
  Title                    = {Learning the kernel with hyperkernels},
  Author                   = {Ong, Cheng S and Williamson, Robert C and Smola, Alex J},
  Booktitle                = {Journal of Machine Learning Research},
  Year                     = {2005},
  Pages                    = {1043--1071}
}

@InProceedings{pado2009textual,
  Title                    = {Textual entailment features for machine translation evaluation},
  Author                   = {Pad{\'o}, Sebastian and Galley, Michel and Jurafsky, Dan and Manning, Christopher D},
  Booktitle                = {Proceedings of the Fourth Workshop on Statistical Machine Translation},
  Year                     = {2009},
  Organization             = {Association for Computational Linguistics},
  Pages                    = {37--41}
}

@Article{lapata2007,
  Title                    = {Dependency-based Construction of Semantic Space Models},
  Author                   = {Sebastian Pad\'{o} and Mirella Lapata},
  Journal                  = {Computational Linguistics},
  Year                     = {2007},
  Number                   = {2},
  Pages                    = {161--199},
  Volume                   = {33},

  Abstract                 = {Traditionally, vector-based semantic space models use word co-occurrence counts from large corpora to represent lexical meaning. In this article we present a novel framework for constructing semantic spaces that take syntactic relations into account. We introduce a formalization for this class of models which allows linguistic knowledge to guide the construction process. We evaluate our framework on a range of tasks relevant for cognitive science and natural language processing: semantic priming, synonymy detection and word sense disambiguation. In all cases, our framework obtains results that are comparable or superior to the state of the art.},
  Owner                    = {nacho},
  Review                   = {Here in this work is one of the most importat controbutions to semantic spaces. Lapata has proposed the use of explicit linguistic knowledge in order to weight syntactical relation between words inside a window context. Linguistic knowledge is comming from a POS tagger from which different weights are assigned to coocurrences also according to the distance between focus word and each coocurrent word, very similarly to HAL.},
  Timestamp                = {2014.12.27},
  Url                      = {http://homepages.inf.ed.ac.uk/mlap/Papers/coli.2007.33.2.161.pdf}
}

@InProceedings{gelbuk2015,
  Title                    = {How Textual Entailment Can Help Corpus-based Machine Translation},
  Author                   = {Santanu Pal and Partha Pakray and Alexander Gelbukh},
  Booktitle                = {14th Mexican International Conference on Artificial Intelligence, MICAI 2015},
  Year                     = {2015},
  Publisher                = {IEEE CS},

  Owner                    = {iarroyof},
  Timestamp                = {2015.08.10}
}

@InProceedings{passonneau2012masc,
  Title                    = {The MASC word sense sentence corpus},
  Author                   = {Passonneau, Rebecca J and Baker, Collin and Fellbaum, Christiane and Ide, Nancy},
  Booktitle                = {Proceedings of LREC},
  Year                     = {2012}
}

@Book{principe2010,
  Title                    = {Information theoretic learning: R{\'e}nyi's entropy and kernel perspectives},
  Author                   = {Principe, Jose C},
  Publisher                = {Springer},
  Year                     = {2010}
}

@InProceedings{Qin2014,
  Title                    = {Quantized Kernel Learning for Feature Matching},
  Author                   = {Qin, Danfeng and Chen, Xuanli and Guillaumin, Matthieu and Gool, Luc V},
  Booktitle                = {Advances in Neural Information Processing Systems},
  Year                     = {2014},
  Pages                    = {172--180}
}

@InProceedings{renzato2007,
  Title                    = {Unsupervised learning of invariant feature hierarchies with applications to object recognition},
  Author                   = {Ranzato, M and Huang, Fu Jie and Boureau, Y-L and LeCun, Yann},
  Booktitle                = {Computer Vision and Pattern Recognition, 2007. CVPR'07. IEEE Conference on},
  Year                     = {2007},
  Organization             = {IEEE},
  Pages                    = {1--8}
}

@InProceedings{ranzato2008semi,
  Title                    = {Semi-supervised learning of compact document representations with deep networks},
  Author                   = {Ranzato, Marc'Aurelio and Szummer, Martin},
  Booktitle                = {Proceedings of the 25th international conference on Machine Learning},
  Year                     = {2008},
  Organization             = {ACM},
  Pages                    = {792--799}
}

@Article{riesz1955,
  Title                    = {Functional analysis},
  Author                   = {Riesz, F. and Nagy, Sz-},
  Journal                  = {Dover Publications, Inc., New York. First published in},
  Year                     = {1955},
  Number                   = {6},
  Pages                    = {35},
  Volume                   = {3}
}


@inproceedings{lechelle-etal-2019-wire57,
    title = "{W}i{R}e57 : A Fine-Grained Benchmark for Open Information Extraction",
    author = "Lechelle, William  and
      Gotti, Fabrizio  and
      Langlais, Phillippe",
    booktitle = "Proceedings of the 13th Linguistic Annotation Workshop",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W19-4002",
    doi = "10.18653/v1/W19-4002",
    pages = "6--15",
    abstract = "We build a reference for the task of Open Information Extraction, on five documents. We tentatively resolve a number of issues that arise, including coreference and granularity, and we take steps toward addressing inference, a significant problem. We seek to better pinpoint the requirements for the task. We produce our annotation guidelines specifying what is correct to extract and what is not. In turn, we use this reference to score existing Open IE systems. We address the non-trivial problem of evaluating the extractions produced by systems against the reference tuples, and share our evaluation script. Among seven compared extractors, we find the MinIE system to perform best.",
}
@InProceedings{saggion:10,
  Title                    = {Multilingual summarization evaluation without human models},
  Author                   = {Saggion, Horacio and Torres-Moreno, Juan-Manuel and da Cunha, Iria and SanJuan, Eric},
  Booktitle                = {23rd International Conference on Computational Linguistics (COLING'10)},
  Year                     = {2010},

  Address                  = {Beijing, China},
  Pages                    = {1059-1067},
  Publisher                = {ACL},

  Owner                    = {iarroyof},
  Timestamp                = {2016.05.28}
}

@InCollection{scholkopf1997kernel,
  Title                    = {Kernel principal component analysis},
  Author                   = {Sch{\"o}lkopf, Bernhard and Smola, Alexander and M{\"u}ller, Klaus-Robert},
  Booktitle                = {Artificial Neural Networks--ICANN'97},
  Publisher                = {Springer},
  Year                     = {1997},
  Pages                    = {583--588}
}

@article{10.2307/411934,
 ISSN = {00978507, 15350665},
 URL = {http://www.jstor.org/stable/411934},
 author = {David G. Hays},
 journal = {Language},
 number = {4},
 pages = {511--525},
 publisher = {Linguistic Society of America},
 title = {Dependency Theory: A Formalism and Some Observations},
 volume = {40},
 year = {1964}
}

@article{shannon1948mathematical,
  title={A mathematical theory of communication},
  author={Shannon, Claude Elwood},
  journal={The Bell system technical journal},
  volume={27},
  number={3},
  pages={379--423},
  year={1948},
  publisher={Nokia Bell Labs}
}
@Article{shannon1949communication,
  Title                    = {Communication theory of secrecy systems*},
  Author                   = {Shannon, Claude E.},
  Journal                  = {Bell system technical journal},
  Year                     = {1949},
  Number                   = {4},
  Pages                    = {656--715},
  Volume                   = {28},

  Publisher                = {Wiley Online Library}
}

@Book{taylor2004,
  Title                    = {Kernel Methods for Pattern Analysis},
  Author                   = {Jhon Shawe-Taylor and Nello Cristianini},
  Publisher                = {Cambridge UP},
  Year                     = {2004},
  Note                     = {ISBN: 978-0-521-81397-6},

  File                     = {:C\:\\Users\\Nacho\\Google Drive\\GIL\\pruebasBayes\\(2004) Kernel Methods for Pattern Analysis [Taylor - Christianini].pdf:PDF},
  Owner                    = {nacho},
  Timestamp                = {2014.04.09}
}

@Article{sidorov2014soft,
  Title                    = {Soft Similarity and Soft Cosine Measure: Similarity of Features in Vector Space Model},
  Author                   = {Sidorov, Grigori and Gelbukh, Alexander and G{\'o}mez-Adorno, Helena and Pinto, David},
  Journal                  = {Computaci{\'o}n y Sistemas},
  Year                     = {2014},
  Number                   = {3},
  Volume                   = {18}
}

@Article{gsierra2009,
  Title                    = {Extracci\'on de contextos definitorios en textos de especialidad a partir del reconocimiento de patrones ling\"u\'isticos},
  Author                   = {Gerardo Sierra},
  Journal                  = {LinguaM\'ATICA},
  Year                     = {2009},

  Month                    = {Dezembro},
  Pages                    = {13-38},
  Volume                   = {2},

  File                     = {:C\:\\Documents and Settings\\nacho\\Mis documentos\\Google Drive\\GIL\\pruebasBayes\\(2009) Extraccion de contextos definitorios en textos de especialidad a partir del reconocimiento de patrones linguiticos [GSierra].pdf:PDF},
  Owner                    = {nacho},
  Timestamp                = {2014.03.21}
}

@InProceedings{smola-gretton2007,
  Title                    = {A Hilbert Space Embedding for Distributions},
  Author                   = {Alex Smola and Arthur Gretton and Le Song and Bernhard Sch\"olkopf},
  Booktitle                = {Algorithmic Learning Theory: 18th International Conference},
  Year                     = {2007},
  Pages                    = {13-31},
  Publisher                = {Springer-Verlag},

  File                     = {:C\:\\Users\\Nacho\\Google Drive\\GIL\\pruebasBayes\\(2007) A Hilbert space embadding for distributions [Smola - Gretton - LeSong - Scholkopf].pdf:PDF},
  Owner                    = {nacho},
  Timestamp                = {2014.12.27}
}

@InProceedings{Socher2011,
  Title                    = {Dynamic pooling and unfolding recursive autoencoders for paraphrase detection},
  Author                   = {Socher, Richard and Huang, Eric H and Pennin, Jeffrey and Manning, Christopher D and Ng, Andrew Y},
  Booktitle                = {Advances in Neural Information Processing Systems},
  Year                     = {2011},
  Pages                    = {801--809}
}

@InProceedings{socher2013recursive,
  Title                    = {Recursive deep models for semantic compositionality over a sentiment treebank},
  Author                   = {Socher, Richard and Perelygin, Alex and Wu, Jean Y and Chuang, Jason and Manning, Christopher D and Ng, Andrew Y and Potts, Christopher},
  Booktitle                = {Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  Year                     = {2013},
  Pages                    = {1631--1642}
}

@Article{sonnenburg2006large,
  Title                    = {Large scale multiple kernel learning},
  Author                   = {Sonnenburg, S{\"o}ren and R{\"a}tsch, Gunnar and Sch{\"a}fer, Christin and Sch{\"o}lkopf, Bernhard},
  Journal                  = {The Journal of Machine Learning Research},
  Year                     = {2006},
  Pages                    = {1531--1565},
  Volume                   = {7},
  Publisher                = {JMLR. org}
}

@InProceedings{steinbach2000,
  Title                    = {A comparison of document clustering techniques},
  Author                   = {Steinbach, Michael and Karypis, George and Kumar, Vipin and others},
  Booktitle                = {KDD workshop on text mining},
  Year                     = {2000},
  Number                   = {1},
  Organization             = {Boston},
  Pages                    = {525--526},
  Volume                   = {400}
}

@Book{sugiyama2012machine,
  Title                    = {Machine Learning in Non-stationary Environments: Introduction to Covariate Shift Adaptation},
  Author                   = {Sugiyama, Masashi and Kawanabe, Motoaki},
  Publisher                = {MIT Press},
  Address					={Cambridge, MA},
  Year                     = {2012},
  Series                   = {Adaptive computation and Machine Learning},
  ISBN                     = {9780262017091}
}

@Book{torres2014automatic,
  Title                    = {Automatic text summarization},
  Author                   = {Torres-Moreno, Juan-Manuel},
  Publisher                = {John Wiley \& Sons},
  Year                     = {2014},

  Owner                    = {iarroyof},
  Timestamp                = {2016.05.28}
}

@Article{torres_artex:12,
  Title                    = {Artex is AnotheR TEXt summarizer},
  Author                   = {Juan-Manuel Torres-Moreno},
  Journal                  = {CoRR},
  Year                     = {2012},
  Volume                   = {abs/1210.3312},

  Bibsource                = {DBLP, http://dblp.uni-trier.de},
  Ee                       = {http://arxiv.org/abs/1210.3312},
  Owner                    = {iarroyof},
  Timestamp                = {2016.05.28}
}

@Conference{torres2010,
  Title                    = {La Energ\'ia Textual Como Medida de Distancia en Agrupamiento de Definiciones},
  Author                   = {Torres-Moreno, Juan-Manuel and Molina, Alejandro and Sierra, Gerardo},
  Booktitle                = {Statistical Analysis of Textual Data},
  Year                     = {2010},
  Pages                    = {215--226},

  File                     = {EnerTex application to definitory contexts clustering:energia textual-Torres.pdf:PDF},
  Journal                  = {International Conference on Statistical Analysis of Textual Data},
  Owner                    = {nacho},
  Timestamp                = {2014.03.11}
}

@Article{torres:10poli,
  Title                    = {Summary Evaluation With and Without References},
  Author                   = {Torres-Moreno, Juan-Manuel and Saggion, Horacio and da Cunha, Iria and SanJuan, Eric},
  Journal                  = {Polibits: Research journal on Computer science and computer engineering with applications},
  Year                     = {2010},
  Pages                    = {13-19},
  Volume                   = {42},

  Owner                    = {iarroyof},
  Timestamp                = {2016.05.28}
}

@article{arroyo2019possibility,
  title={On the Possibility of Rewarding Structure Learning Agents: Mutual Information on Linguistic Random Sets},
  author={Arroyo-Fern{\'a}ndez, Ignacio and Carrasco-Ru{\'\i}z, Mauricio and Arias-Aguilar, J Anibal},
  url={https://www.sets.parts/accepted-papers},
  journal={arXiv preprint arXiv:1910.04023},
  year={2019}
}

@inproceedings{arroyo2018unam,
  title={{UNAM at SemEval}-2018 task 10: Unsupervised Semantic Discriminative Attribute Identification in Neural Word Embedding Cones},
  author={Arroyo-Fern{\'a}ndez, Ignacio and Meza, Ivan and M{\'e}ndez-Cruz, Carlos-Francisco},
  booktitle={Proceedings of The 12th International Workshop on Semantic Evaluation},
  pages={977--984},
  year={2018}
}

@Article{tsang2006efficient,
  Title                    = {Efficient hyperkernel learning using second-order cone programming},
  Author                   = {Tsang, Ivor W and Kwok, JT-Y},
  Journal                  = {Neural Networks, IEEE Transactions on},
  Year                     = {2006},
  Number                   = {1},
  Pages                    = {48--58},
  Volume                   = {17},

  Publisher                = {IEEE}
}

@InCollection{vapnik2015learning,
  Title                    = {Learning with Intelligent Teacher: Similarity Control and Knowledge Transfer},
  Author                   = {Vapnik, Vladimir and Izmailov, Rauf},
  Booktitle                = {Statistical Learning and Data Sciences},
  Publisher                = {Springer},
  Year                     = {2015},
  Pages                    = {3--32}
}

@Book{vapnik1998,
  Title                    = {Statistical Learning Theory},
  Author                   = {Vapnik, Vladimir Naumovich},
  Publisher                = {Wiley},
  Address					={New York, NY},
  Year                     = {1998},

  Abstract                 = {A comprehensive look at learning and generalization theory. The statistical theory of learning and generalization concerns the problem of choosing desired functions on the basis of empirical data. Highly applicable to a variety of computer science and robotics fields, this book offers lucid coverage of the theory as a whole. Presenting a method for determining the necessary and sufficient conditions for consistency of learning process, the author covers function estimates from small data pools, applying these estimations to real-life problems, and much more.}
}

@InCollection{wittek2011spectral,
  Title                    = {Spectral composition of semantic spaces},
  Author                   = {Wittek, Peter and Dar{\'a}nyi, S{\'a}ndor},
  Booktitle                = {Quantum Interaction},
  Publisher                = {Springer},
  Year                     = {2011},
  Pages                    = {60--70}
}

@InProceedings{Xiong2014,
  Title                    = {Zeta Hull Pursuits: Learning Nonconvex Data Hulls},
  Author                   = {Xiong, Yuanjun and Liu, Wei and Zhao, Deli and Tang, Xiaoou},
  Booktitle                = {Advances in Neural Information Processing Systems},
  Year                     = {2014},
  Pages                    = {46--54}
}

@Article{xu2014extracting,
  Title                    = {Extracting lexically divergent paraphrases from Twitter},
  Author                   = {Xu, Wei and Ritter, Alan and Callison-Burch, Chris and Dolan, William B and Ji, Yangfeng},
  Journal                  = {Transactions of the Association for Computational Linguistics},
  Year                     = {2014},
  Pages                    = {435--448},
  Volume                   = {2}
}

@InProceedings{yan2013,
  Title                    = {Minimally Supervised Method for Multilingual Paraphrase Extraction from Definition Sentences on the Web.},
  Author                   = {Yan, Yulan and Hashimoto, Chikara and Torisawa, Kentaro and Kawai, Takao and Jun'ichi Kazama and De Saeger, Stijn},
  Booktitle                = {HLT-NAACL},
  Year                     = {2013},
  Pages                    = {63--73}
}

@InProceedings{yosinski2014,
  Title                    = {How transferable are features in deep neural networks?},
  Author                   = {Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
  Booktitle                = {Advances in Neural Information Processing Systems},
  Year                     = {2014},
  Pages                    = {3320--3328}
}

@InProceedings{zhu2001kernel,
  Title                    = {Kernel logistic regression and the import vector machine},
  Author                   = {Zhu, Ji and Hastie, Trevor},
  Booktitle                = {Advances in Neural Information Processing systems},
  Year                     = {2001},
  Pages                    = {1081--1088}
}

@incollection{scholkopf1998support,
  title={Support vector regression with automatic accuracy control},
  author={Sch{\"o}lkopf, B. and Bartlett, P. and Smola, A. and Williamson, R.},
  booktitle={ICANN 98},
  pages={111--116},
  year={1998},
  publisher={Springer}
}

@article{luhn1958automatic,
  title={The automatic creation of literature abstracts},
  author={Luhn, Hans Peter},
  journal={IBM Journal of research and development},
  volume={2},
  number={2},
  pages={159--165},
  year={1958},
  publisher={IBM}
}

@inproceedings{kupiec1995trainable,
  title={A trainable document summarizer},
  author={Kupiec, Julian and Pedersen, Jan and Chen, Francine},
  booktitle={18th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={68--73},
  year={1995},
  organization={ACM}
}

@article{yeh2005text,
  title={Text summarization using a trainable summarizer and latent semantic analysis},
  author={Yeh, Jen-Yuan and Ke, Hao-Ren and Yang, Wei-Pang and Meng, I-Heng},
  journal={Information Processing \& Management},
  volume={41},
  number={1},
  pages={75--95},
  year={2005},
  publisher={Elsevier}
}

@article{divya2014eigenvector,
  title={Eigenvector Based Approach for Sentence Ranking in News Summarization},
  author={Divya, S. and Reghuraj, PC.},
  journal={IJCLNLP, April},
  year={2014}
}
@article{lee2009automatic,
  title={Automatic generic document summarization based on non-negative matrix factorization},
  author={Lee, Ju-Hong and Park, Sun and Ahn, Chan-Min and Kim, Daeho},
  journal={Information Processing \& Management},
  volume={45},
  number={1},
  pages={20--34},
  year={2009},
  publisher={Elsevier}
}

@article{sarkar2009sentence,
  title={Sentence clustering-based summarization of multiple text documents},
  author={Sarkar, Kamal},
  journal={International Journal of Computing Science and Communication Technologies},
  volume={2},
  number={1},
  pages={325--335},
  year={2009}
}

@inproceedings{wan2008multi,
  title={Multi-document summarization using cluster-based link analysis},
  author={Wan, Xiaojun and Yang, Jianwu},
  booktitle={31st annual international ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={299--306},
  year={2008},
  organization={ACM}
}

@inproceedings{li2007multi,
  title={Multi-document summarization using support vector regression},
  author={Li, Sujian and Ouyang, You and Wang, Wei and Sun, Bin},
  booktitle={Proceedings of DUC},
  year={2007}
}

@inproceedings{galanis2012extractive,
  title={Extractive Multi-Document Summarization with Integer Linear Programming and Support Vector Regression.},
  author={Galanis, Dimitrios and Lampouras, Gerasimos and Androutsopoulos, Ion},
  booktitle={COLING},
  pages={911--926},
  year={2012}
}

@inproceedings{cao2015ranking,
  title={Ranking with Recursive Neural Networks and Its Application to Multi-Document Summarization.},
  author={Cao, Ziqiang and Wei, Furu and Dong, Li and Li, Sujian and Zhou, Ming},
  booktitle={AAAI},
  pages={2153--2159},
  year={2015}
}

@inproceedings{woodsend2012multiple,
  title={Multiple aspect summarization using integer linear programming},
  author={Woodsend, Kristian and Lapata, Mirella},
  booktitle={2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning},
  pages={233--243},
  year={2012},
  organization={Association for Computational Linguistics}
}

@book{mcdonald2007study,
  title={A study of global inference algorithms in multi-document summarization},
  author={McDonald, Ryan},
  year={2007},
  publisher={Springer}
}

@inproceedings{berg2011jointly,
  title={Jointly learning to extract and compress},
  author={Berg-Kirkpatrick, Taylor and Gillick, Dan and Klein, Dan},
  booktitle={49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1},
  pages={481--490},
  year={2011},
  organization={Association for Computational Linguistics}
}

@PhdThesis{cortes1995prediction,
  Title               = {Prediction of Generalization Ability in Learning Machines},
  Author              = {Cortes, Corinna},
  School              = {University of Rochester},
  Year                = {1995}
}

@article{liang2015rosemerry,
  title={RoseMerry: A Baseline Message-level Sentiment Classification System},
  author={Liang, Huizhi and Fothergill, Richard and Baldwin, Timothy},
  journal={SemEval-2015},
  pages={551},
  year={2015}
}
@article{li2016learning,
  title={Learning Distributed Word Representation with Multi-Contextual Mixed Embedding},
  author={Li, Jianqiang and Li, Jing and Fu, Xianghua and Masud, MA and Huang, Joshua Zhexue},
  journal={Knowledge-Based Systems},
  year={2016},
  publisher={Elsevier}
}

@TechReport{gutmantext2015,
  Title                    = {Text Classification of Reddit Posts},
  Author                   = {Gutman, Jacqueline and Nam, Richard},
  Institution              = {New York University},
  Year                     = {2015},
  Month                    = {October -- December},

  Keywords                 = {Machine Learning, natural language processing},
  Owner                    = {ignacio},
  Timestamp                = {2016.06.01},
  Url                      = {http://jgutman.github.io}
}

@inproceedings{nenkova2005automatic,
  title={Automatic text summarization of newswire: Lessons learned from the document understanding conference},
  author={Nenkova, Ani},
  booktitle={AAAI},
  volume={5},
  pages={1436--1441},
  year={2005}
}

@book{van1997syntax,
  title={Syntax: Structure, meaning, and function},
  author={Van Valin, Robert D and LaPolla, Randy J},
  year={1997},
  publisher={Cambridge University Press}
}

@inproceedings{alarcon2007developing,
  title={Developing a Definitional Knowledge Extraction System},
  author={Alarc{\'o}n, Rodrigo and Sierra, Gerardo and Bach, Carme},
  booktitle={Conference Proceedings of Third Language \& Technology Conference LTC'07},
  year={2007}
}

@book{Everitt:2011,
 author = {Everitt, Brian S. and Landau, Sabine and Leese, Morven and Stahl, Daniel},
 title = {Cluster Analysis},
 year = {2011},
 isbn = {9780470749913},
 edition = {5th},
 publisher = {Wiley Publishing},
} 

@article{ward1963hierarchical,
  title={Hierarchical grouping to optimize an objective function},
  author={Ward Jr, Joe H},
  journal={Journal of the American statistical association},
  volume={58},
  number={301},
  pages={236--244},
  year={1963},
  publisher={Taylor \& Francis}
}

@inproceedings{gretton2012optimal,
  title={Optimal kernel choice for large-scale two-sample tests},
  author={Gretton, Arthur and Sejdinovic, Dino and Strathmann, Heiko and Balakrishnan, Sivaraman and Pontil, Massimiliano and Fukumizu, Kenji and Sriperumbudur, Bharath K},
  booktitle={Advances in neural information processing systems},
  pages={1205--1213},
  year={2012}
}

@book{fourier1822theorie,
  title={Theorie analytique de la chaleur},
  author={Fourier, Joseph},
  year={1822},
  publisher={Chez Firmin Didot, p{\`e}re et fils}
}

@inproceedings{agirre2012SemEval,
  title={SemEval-2012 task 6: A pilot on semantic textual similarity},
  author={Agirre, Eneko and Diab, Mona and Cer, Daniel and Gonzalez-Agirre, Aitor},
  booktitle={Proceedings of the First Joint Conference on Lexical and Computational Semantics-Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation},
  pages={385--393},
  year={2012},
  organization={Association for Computational Linguistics}
}

@incollection{rychalska2016samsung,
  title="Samsung {Poland NLP Team at SemEval-2016 Task 1}: {Necessity} for diversity; combining recursive autoencoders, {Wordnet} and ensemble methods to measure semantic similarity",
  author={Rychalska, Barbara and Pakulska, Katarzyna and Chodorowska, Krystyna and Walczak, Wojciech and Andruszkiewicz, Piotr},
  booktitle={Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval 2016), San Diego, CA, USA},
  year={2016},
  pages={602--608}
}
@article{bojanowski2016enriching,
  title={Enriching Word Vectors with Subword Information},
  author={Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},
  journal={arXiv preprint arXiv:1607.04606},
  year={2016}
}
@inproceedings{vinyals2015grammar,
  title={Grammar as a foreign language},
  author={Vinyals, Oriol and Kaiser, {\L}ukasz and Koo, Terry and Petrov, Slav and Sutskever, Ilya and Hinton, Geoffrey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2773--2781},
  year={2015}
}

@conference{arroyo-fernandez-kdir16,
author={Ignacio Arroyo-Fernández and Juan-Manuel Torres-Moreno and Gerardo Sierra and Luis Adrián Cabrera-Diego},
title={Automatic Text Summarization by Non-topic Relevance Estimation},
booktitle={Proceedings of the 8th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management - Volume 1: KDIR,},
year={2016},
pages={89-100},
doi={10.5220/0006053400890100},
isbn={978-989-758-203-5},
}
@inproceedings{le2014distributed,
  title={Distributed Representations of Sentences and Documents.},
  author={Le, Quoc V and Mikolov, Tomas},
  booktitle={ICML},
  volume={14},
  pages={1188--1196},
  year={2014}
}

@inproceedings{xu2013open,
  title={Open Information Extraction with Tree Kernels.},
  author={Xu, Ying and Kim, Mi-Young and Quinn, Kevin and Goebel, Randy and Barbosa, Denilson},
  booktitle={HLT-NAACL},
  pages={868--877},
  year={2013}
}

@article{goodfellow2013maxout,
  title={Maxout Networks.},
  author={Goodfellow, Ian J and Warde-Farley, David and Mirza, Mehdi and Courville, Aaron C and Bengio, Yoshua},
  journal={ICML (3)},
  volume={28},
  pages={1319--1327},
  year={2013}
}
@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}

@article{cho2014learning,
  title={Learning phrase representations using RNN encoder-decoder for statistical machine translation},
  author={Cho, Kyunghyun and Van Merri{\"e}nboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1406.1078},
  year={2014}
}

@inproceedings{agirre2016SemEval,
  title={SemEval-2016 task 1: Semantic textual similarity, monolingual and cross-lingual evaluation},
  author={Agirre, Eneko and Banea, Carmen and Cer, Daniel and Diab, Mona and Gonzalez-Agirre, Aitor and Mihalcea, Rada and Rigau, German and Wiebe, Janyce},
  booktitle={Proceedings of SemEval},
  pages={497--511},
  year={2016}
}
@incollection{scholkopf1997prior,
  title={Prior knowledge in support vector kernels},
  author={Sch{\"o}lkopf, Bernhard and Simard, Patrice and Smola, Alex and Vapnik, Vladimir},
  booktitle={Proceedings of the 10th International Conference on Neural Information Processing Systems},
  pages={640--646},
  year={1997},
  organization={MIT Press},
  address={Cambridge, MA}
}

@article{hunter2017knowledge, title={Knowledge-based biomedical data science}, author={Hunter, Lawrence E}, journal={Data Science}, volume={1}, number={1-2}, pages={19--25}, year={2017}, publisher={IOS Press}}

@article{davis2015commonsense, title={Commonsense reasoning and commonsense knowledge in artificial intelligence}, author={Davis, Ernest and Marcus, Gary}, journal={Communications of the ACM}, volume={58}, number={9}, pages={92--103}, year={2015}, publisher={ACM New York, NY, USA}}

@inproceedings{socher2013reasoning, title={Reasoning with neural tensor networks for knowledge base completion}, author={Socher, Richard and Chen, Danqi and Manning, Christopher D and Ng, Andrew}, booktitle={Advances in neural information processing systems}, pages={926--934}, year={2013}}

@inproceedings{xu-etal-2013-open,
    title = "Open Information Extraction with Tree Kernels",
    author = "Xu, Ying  and
      Kim, Mi-Young  and
      Quinn, Kevin  and
      Goebel, Randy  and
      Barbosa, Denilson",
    booktitle = "Proceedings of the 2013 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2013",
    address = "Atlanta, Georgia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N13-1107",
    pages = "868--877",
}

@inproceedings{cetto-etal-2018-graphene-context,
    title = "{G}raphene: a Context-Preserving Open Information Extraction System",
    author = "Cetto, Matthias  and
      Niklaus, Christina  and
      Freitas, Andr{\'e}  and
      Handschuh, Siegfried",
    booktitle = "Proceedings of the 27th International Conference on Computational Linguistics: System Demonstrations",
    month = aug,
    year = "2018",
    address = "Santa Fe, New Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/C18-2021",
    pages = "94--98",
    abstract = "We introduce Graphene, an Open IE system whose goal is to generate accurate, meaningful and complete propositions that may facilitate a variety of downstream semantic applications. For this purpose, we transform syntactically complex input sentences into clean, compact structures in the form of core facts and accompanying contexts, while identifying the rhetorical relations that hold between them in order to maintain their semantic relationship. In that way, we preserve the context of the relational tuples extracted from a source sentence, generating a novel lightweight semantic representation for Open IE that enhances the expressiveness of the extracted propositions.",
}

@inproceedings{shin2015incremental,
  title={Incremental knowledge base construction using deepdive},
  author={Shin, Jaeho and Wu, Sen and Wang, Feiran and De Sa, Christopher and Zhang, Ce and R{\'e}, Christopher},
  booktitle={Proceedings of the VLDB Endowment International Conference on Very Large Data Bases},
  volume={8},
  number={11},
  pages={1310},
  year={2015},
  organization={NIH Public Access}
}

@inproceedings{zhou2015end,
  title={End-to-end learning of semantic role labeling using recurrent neural networks},
  author={Zhou, Jie and Xu, Wei},
  booktitle={Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  pages={1127--1137},
  year={2015}
}

@article{dhingra2020differentiable,
  title={Differentiable reasoning over a virtual knowledge base},
  author={Dhingra, Bhuwan and Zaheer, Manzil and Balachandran, Vidhisha and Neubig, Graham and Salakhutdinov, Ruslan and Cohen, William W},
  journal={arXiv preprint arXiv:2002.10640},
  year={2020}
}


@article{etzioni2008open,
  title={Open information extraction from the web},
  author={Etzioni, Oren and Banko, Michele and Soderland, Stephen and Weld, Daniel S},
  journal={Communications of the ACM},
  volume={51},
  number={12},
  pages={68--74},
  year={2008},
  publisher={ACM New York, NY, USA}
}

@inproceedings{saha-etal-2017-bootstrapping,
    title = "Bootstrapping for Numerical Open {IE}",
    author = "Saha, Swarnadeep  and
      Pal, Harinder  and
      {Mausam}",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P17-2050",
    doi = "10.18653/v1/P17-2050",
    pages = "317--323",
    abstract = "We design and release BONIE, the first open numerical relation extractor, for extracting Open IE tuples where one of the arguments is a number or a quantity-unit phrase. BONIE uses bootstrapping to learn the specific dependency patterns that express numerical relations in a sentence. BONIE{'}s novelty lies in task-specific customizations, such as inferring implicit relations, which are clear due to context such as units (for e.g., {`}square kilometers{'} suggests area, even if the word {`}area{'} is missing in the sentence). BONIE obtains 1.5x yield and 15 point precision gain on numerical facts over a state-of-the-art Open IE system.",
}
@inproceedings{manning2014stanford,
  title={The Stanford CoreNLP natural language processing toolkit},
  author={Manning, Christopher D and Surdeanu, Mihai and Bauer, John and Finkel, Jenny Rose and Bethard, Steven and McClosky, David},
  booktitle={Proceedings of 52nd annual meeting of the association for computational linguistics: system demonstrations},
  pages={55--60},
  year={2014}
}

@inproceedings{bhardwaj-etal-2019-carb,
    title = "{C}a{RB}: A Crowdsourced Benchmark for Open {IE}",
    author = "Bhardwaj, Sangnie  and
      Aggarwal, Samarth  and
      Mausam, Mausam",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1651",
    doi = "10.18653/v1/D19-1651",
    pages = "6262--6267",
    abstract = "Open Information Extraction (Open IE) systems have been traditionally evaluated via manual annotation. Recently, an automated evaluator with a benchmark dataset (OIE2016) was released {--} it scores Open IE systems automatically by matching system predictions with predictions in the benchmark dataset. Unfortunately, our analysis reveals that its data is rather noisy, and the tuple matching in the evaluator has issues, making the results of automated comparisons less trustworthy. We contribute CaRB, an improved dataset and framework for testing Open IE systems. To the best of our knowledge, CaRB is the first crowdsourced Open IE dataset and it also makes substantive changes in the matching code and metrics. NLP experts annotate CaRB{'}s dataset to be more accurate than OIE2016. Moreover, we find that on one pair of Open IE systems, CaRB framework provides contradictory results to OIE2016. Human assessment verifies that CaRB{'}s ranking of the two systems is the accurate ranking. We release the CaRB framework along with its crowdsourced dataset.",
}

@article{world2018noncommunicable,
  title={Noncommunicable diseases country profiles 2018},
  author={World Health Organization and others},
  year={2018},
  publisher={World Health Organization}
}

@article{liu2004conceptnet,
  title={ConceptNet—a practical commonsense reasoning tool-kit},
  author={Liu, Hugo and Singh, Push},
  journal={BT technology journal},
  volume={22},
  number={4},
  pages={211--226},
  year={2004},
  publisher={Springer}
}

@inproceedings{bosselut2019comet,
  title={COMET: Commonsense Transformers for Automatic Knowledge Graph Construction},
  author={Bosselut, Antoine and Rashkin, Hannah and Sap, Maarten and Malaviya, Chaitanya and Celikyilmaz, Asli and Choi, Yejin},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={4762--4779},
  year={2019}
}

@inproceedings{lin2019kagnet,
  title={KagNet: Knowledge-Aware Graph Networks for Commonsense Reasoning},
  author={Lin, Bill Yuchen and Chen, Xinyue and Chen, Jamin and Ren, Xiang},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={2829--2839},
  year={2019}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017}
}

@inproceedings{kenton2019bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Kenton, Jacob Devlin Ming-Wei Chang and Toutanova, Lee Kristina},
  booktitle={Proceedings of NAACL-HLT},
  pages={4171--4186},
  year={2019}
}

@article{yang2019xlnet,
  title={Xlnet: Generalized autoregressive pretraining for language understanding},
  author={Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Russ R and Le, Quoc V},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{vinuesa2020role,
  title={The role of artificial intelligence in achieving the Sustainable Development Goals},
  author={Vinuesa, Ricardo and Azizpour, Hossein and Leite, Iolanda and Balaam, Madeline and Dignum, Virginia and Domisch, Sami and Fell{\"a}nder, Anna and Langhans, Simone Daniela and Tegmark, Max and Nerini, Francesco Fuso},
  journal={Nature communications},
  volume={11},
  number={1},
  pages={1--10},
  year={2020},
  publisher={Nature Publishing Group}
}
@inproceedings{arase2019transfer,
  title={Transfer Fine-Tuning: A BERT Case Study},
  author={Arase, Yuki and Tsujii, Jun’ichi},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={5393--5404},
  year={2019}
}

@article{mendez2020knowledge,
  title={Knowledge extraction for assisted curation of summaries of bacterial transcription factor properties},
  author={M{\'e}ndez-Cruz, Carlos-Francisco and Blanchet, Antonio and God{\'\i}nez, Alan and Arroyo-Fern{\'a}ndez, Ignacio and Gama-Castro, Socorro and Mart{\'\i}nez-Luna, Sara Berenice and Gonz{\'a}lez-Col{\'\i}n, Cristian and Collado-Vides, Julio},
  journal={Database},
  volume={2020},
  year={2020},
  publisher={Oxford Academic}
}


@inproceedings{luong-etal-2015-effective,
    title = "Effective Approaches to Attention-based Neural Machine Translation",
    author = "Luong, Thang  and
      Pham, Hieu  and
      Manning, Christopher D.",
    booktitle = "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2015",
    address = "Lisbon, Portugal",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D15-1166",
    doi = "10.18653/v1/D15-1166",
    pages = "1412--1421",
}

@inproceedings{bahdanau2015neural,
	title="Neural Machine Translation by Jointly Learning to Align and Translate",
	author="Dzmitry {Bahdanau} and Kyunghyun {Cho} and Yoshua {Bengio}",
	booktitle="ICLR 2015 : International Conference on Learning Representations 2015",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/2964308564",
	year="2015"
}
@incollection{DEVELLIS2005317,
title = {Inter-Rater Reliability},
editor = {Kimberly Kempf-Leonard},
booktitle = {Encyclopedia of Social Measurement},
publisher = {Elsevier},
address = {New York},
pages = {317-322},
year = {2005},
isbn = {978-0-12-369398-3},
doi = {https://doi.org/10.1016/B0-12-369398-5/00095-5},
url = {https://www.sciencedirect.com/science/article/pii/B0123693985000955},
author = {Robert F. DeVellis}
}

@inproceedings{arroyo2017lipn,
  title={LIPN-IIMAS at SemEval-2017 Task 1: Subword embeddings, attention recurrent neural networks and cross word alignment for semantic textual similarity},
  author={Arroyo-Fern{\'a}ndez, Ignacio and Meza-Ruiz, Ivan},
  booktitle={Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
  pages={208--212},
  year={2017}
}


@article{floridi2020gpt,
  title={GPT-3: Its nature, scope, limits, and consequences},
  author={Floridi, Luciano and Chiriatti, Massimo},
  journal={Minds and Machines},
  volume={30},
  number={4},
  pages={681--694},
  year={2020},
  publisher={Springer}
}

@inproceedings{zhang2017hcnn,
  title={HCNN: Heterogeneous convolutional neural networks for comorbid risk prediction with electronic health records},
  author={Zhang, Jinghe and Gong, Jiaqi and Barnes, Laura},
  booktitle={2017 IEEE/ACM International Conference on Connected Health: Applications, Systems and Engineering Technologies (CHASE)},
  pages={214--221},
  year={2017},
  organization={IEEE}
}

@inproceedings{10.1145/3448016.3457328,
author = {Vretinaris, Alina and Lei, Chuan and Efthymiou, Vasilis and Qin, Xiao and \"{O}zcan, Fatma},
title = {Medical Entity Disambiguation Using Graph Neural Networks},
year = {2021},
isbn = {9781450383431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3448016.3457328},
doi = {10.1145/3448016.3457328},
abstract = {Medical knowledge bases (KBs), distilled from biomedical literature and regulatory
actions, are expected to provide high-quality information to facilitate clinical decision
making. Entity disambiguation (also referred to as entity linking) is considered as
an essential task in unlocking the wealth of such medical KBs. However, existing medical
entity disambiguation methods are not adequate due to word discrepancies between the
entities in the KB and the text snippets in the source documents. Recently, graph
neural networks (GNNs) have proven to be very effective and provide state-of-the-art
results for many real-world applications with graph-structured data. In this paper,
we introduce ED-GNN based on three representative GNNs (GraphSAGE, R-GCN, and MAGNN)
for medical entity disambiguation. We develop two optimization techniques to fine-tune
and improve ED-GNN. First, we introduce a novel strategy to represent entities that
are mentioned in text snippets as a query graph. Second, we design an effective negative
sampling strategy that identifies hard negative samples to improve the model's disambiguation
capability. Compared to the best performing state-of-the-art solutions, our ED-GNN
offers an average improvement of 7.3% in terms of F1 score on five real-world datasets.},
booktitle = {Proceedings of the 2021 International Conference on Management of Data},
pages = {2310–2318},
numpages = {9},
keywords = {entity disambiguation, graph neural network, medical ontology},
location = {Virtual Event, China},
series = {SIGMOD/PODS '21}
}

@article{bizon2019robokop,
  title={ROBOKOP KG and KGB: integrated knowledge graphs from federated sources},
  author={Bizon, Chris and Cox, Steven and Balhoff, James and Kebede, Yaphet and Wang, Patrick and Morton, Kenneth and Fecho, Karamarie and Tropsha, Alexander},
  journal={Journal of chemical information and modeling},
  volume={59},
  number={12},
  pages={4968--4973},
  year={2019},
  publisher={ACS Publications}
}

@article{WANG201812,
title = {A comparison of word embeddings for the biomedical natural language processing},
journal = {Journal of Biomedical Informatics},
volume = {87},
pages = {12-20},
year = {2018},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2018.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S1532046418301825},
author = {Yanshan Wang and Sijia Liu and Naveed Afzal and Majid Rastegar-Mojarad and Liwei Wang and Feichen Shen and Paul Kingsbury and Hongfang Liu},
keywords = {Word embeddings, Natural language processing, Information extraction, Information retrieval, Machine learning},
abstract = {Background
Word embeddings have been prevalently used in biomedical Natural Language Processing (NLP) applications due to the ability of the vector representations being able to capture useful semantic properties and linguistic relationships between words. Different textual resources (e.g., Wikipedia and biomedical literature corpus) have been utilized in biomedical NLP to train word embeddings and these word embeddings have been commonly leveraged as feature input to downstream machine learning models. However, there has been little work on evaluating the word embeddings trained from different textual resources.
Methods
In this study, we empirically evaluated word embeddings trained from four different corpora, namely clinical notes, biomedical publications, Wikipedia, and news. For the former two resources, we trained word embeddings using unstructured electronic health record (EHR) data available at Mayo Clinic and articles (MedLit) from PubMed Central, respectively. For the latter two resources, we used publicly available pre-trained word embeddings, GloVe and Google News. The evaluation was done qualitatively and quantitatively. For the qualitative evaluation, we randomly selected medical terms from three categories (i.e., disorder, symptom, and drug), and manually inspected the five most similar words computed by embeddings for each term. We also analyzed the word embeddings through a 2-dimensional visualization plot of 377 medical terms. For the quantitative evaluation, we conducted both intrinsic and extrinsic evaluation. For the intrinsic evaluation, we evaluated the word embeddings’ ability to capture medical semantics by measruing the semantic similarity between medical terms using four published datasets: Pedersen’s dataset, Hliaoutakis’s dataset, MayoSRS, and UMNSRS. For the extrinsic evaluation, we applied word embeddings to multiple downstream biomedical NLP applications, including clinical information extraction (IE), biomedical information retrieval (IR), and relation extraction (RE), with data from shared tasks.
Results
The qualitative evaluation shows that the word embeddings trained from EHR and MedLit can find more similar medical terms than those trained from GloVe and Google News. The intrinsic quantitative evaluation verifies that the semantic similarity captured by the word embeddings trained from EHR is closer to human experts’ judgments on all four tested datasets. The extrinsic quantitative evaluation shows that the word embeddings trained on EHR achieved the best F1 score of 0.900 for the clinical IE task; no word embeddings improved the performance for the biomedical IR task; and the word embeddings trained on Google News had the best overall F1 score of 0.790 for the RE task.
Conclusion
Based on the evaluation results, we can draw the following conclusions. First, the word embeddings trained from EHR and MedLit can capture the semantics of medical terms better, and find semantically relevant medical terms closer to human experts’ judgments than those trained from GloVe and Google News. Second, there does not exist a consistent global ranking of word embeddings for all downstream biomedical NLP applications. However, adding word embeddings as extra features will improve results on most downstream tasks. Finally, the word embeddings trained from the biomedical domain corpora do not necessarily have better performance than those trained from the general domain corpora for any downstream biomedical NLP task.}
}
@article{zhang2019biowordvec,
  title={BioWordVec, improving biomedical word embeddings with subword information and MeSH},
  author={Zhang, Yijia and Chen, Qingyu and Yang, Zhihao and Lin, Hongfei and Lu, Zhiyong},
  journal={Scientific data},
  volume={6},
  number={1},
  pages={1--9},
  year={2019},
  publisher={Nature Publishing Group}
}

@article{RINDFLESCH2003462,
title = {The interaction of domain knowledge and linguistic structure in natural language processing: interpreting hypernymic propositions in biomedical text},
journal = {Journal of Biomedical Informatics},
volume = {36},
number = {6},
pages = {462-477},
year = {2003},
note = {Unified Medical Language System},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2003.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S1532046403001175},
author = {Thomas C Rindflesch and Marcelo Fiszman},
keywords = {Natural language processing, Semantic processing, Knowledge representation, Information extraction},
abstract = {Interpretation of semantic propositions in free-text documents such as MEDLINE citations would provide valuable support for biomedical applications, and several approaches to semantic interpretation are being pursued in the biomedical informatics community. In this paper, we describe a methodology for interpreting linguistic structures that encode hypernymic propositions, in which a more specific concept is in a taxonomic relationship with a more general concept. In order to effectively process these constructions, we exploit underspecified syntactic analysis and structured domain knowledge from the Unified Medical Language System (UMLS). After introducing the syntactic processing on which our system depends, we focus on the UMLS knowledge that supports interpretation of hypernymic propositions. We first use semantic groups from the Semantic Network to ensure that the two concepts involved are compatible; hierarchical information in the Metathesaurus then determines which concept is more general and which more specific. A preliminary evaluation of a sample based on the semantic group Chemicals and Drugs provides 83\% precision. An error analysis was conducted and potential solutions to the problems encountered are presented. The research discussed here serves as a paradigm for investigating the interaction between domain knowledge and linguistic structure in natural language processing, and could also make a contribution to research on automatic processing of discourse structure. Additional implications of the system we present include its integration in advanced semantic interpretation processors for biomedical text and its use for information extraction in specific domains. The approach has the potential to support a range of applications, including information retrieval and ontology engineering.}
}

@article{lee2020biobert,
  title={BioBERT: a pre-trained biomedical language representation model for biomedical text mining},
  author={Lee, Jinhyuk and Yoon, Wonjin and Kim, Sungdong and Kim, Donghyeon and Kim, Sunkyu and So, Chan Ho and Kang, Jaewoo},
  journal={Bioinformatics},
  volume={36},
  number={4},
  pages={1234--1240},
  year={2020},
  publisher={Oxford University Press}
}

@article{meng2021mixture,
  title={Mixture-of-Partitions: Infusing Large Biomedical Knowledge Graphs into BERT},
  author={Meng, Zaiqiao and Liu, Fangyu and Clark, Thomas Hikaru and Shareghi, Ehsan and Collier, Nigel},
  journal={arXiv preprint arXiv:2109.04810},
  year={2021}
}

@inproceedings{pfeiffer2020adapterhub,
  title={AdapterHub: A Framework for Adapting Transformers},
  author={Pfeiffer, Jonas and R{\"u}ckl{\'e}, Andreas and Poth, Clifton and Kamath, Aishwarya and Vuli{\'c}, Ivan and Ruder, Sebastian and Cho, Kyunghyun and Gurevych, Iryna},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations},
  pages={46--54},
  year={2020}
}

@ARTICLE{8682042,
  author={Fang, Youli and Wang, Hong and Wang, Lutong and Di, Ruitong and Song, Yongqiang},
  journal={IEEE Access}, 
  title={Diagnosis of COPD Based on a Knowledge Graph and Integrated Model}, 
  year={2019},
  volume={7},
  number={},
  pages={46004-46013},
  doi={10.1109/ACCESS.2019.2909069}}

@Article{info:doi/10.2196/18287,
author="Xiu, Xiaolei
and Qian, Qing
and Wu, Sizhu",
title="Construction of a Digestive System Tumor Knowledge Graph Based on Chinese Electronic Medical Records: Development and Usability Study",
journal="JMIR Med Inform",
year="2020",
month="Oct",
day="7",
volume="8",
number="10",
pages="e18287",
keywords="Chinese electronic medical records; knowledge graph; digestive system tumor; graph evaluation",
abstract="Background: With the increasing incidences and mortality of digestive system tumor diseases in China, ways to use clinical experience data in Chinese electronic medical records (CEMRs) to determine potentially effective relationships between diagnosis and treatment have become a priority. As an important part of artificial intelligence, a knowledge graph is a powerful tool for information processing and knowledge organization that provides an ideal means to solve this problem. Objective: This study aimed to construct a semantic-driven digestive system tumor knowledge graph (DSTKG) to represent the knowledge in CEMRs with fine granularity and semantics. Methods: This paper focuses on the knowledge graph schema and semantic relationships that were the main challenges for constructing a Chinese tumor knowledge graph. The DSTKG was developed through a multistep procedure. As an initial step, a complete DSTKG construction framework based on CEMRs was proposed. Then, this research built a knowledge graph schema containing 7 classes and 16 kinds of semantic relationships and accomplished the DSTKG by knowledge extraction, named entity linking, and drawing the knowledge graph. Finally, the quality of the DSTKG was evaluated from 3 aspects: data layer, schema layer, and application layer. Results: Experts agreed that the DSTKG was good overall (mean score 4.20). Especially for the aspects of ``rationality of schema structure,'' ``scalability,'' and ``readability of results,'' the DSTKG performed well, with scores of 4.72, 4.67, and 4.69, respectively, which were much higher than the average. However, the small amount of data in the DSTKG negatively affected its ``practicability'' score. Compared with other Chinese tumor knowledge graphs, the DSTKG can represent more granular entities, properties, and semantic relationships. In addition, the DSTKG was flexible, allowing personalized customization to meet the designer's focus on specific interests in the digestive system tumor. Conclusions: We constructed a granular semantic DSTKG. It could provide guidance for the construction of a tumor knowledge graph and provide a preliminary step for the intelligent application of knowledge graphs based on CEMRs. Additional data sources and stronger research on assertion classification are needed to gain insight into the DSTKG's potential. ",
issn="2291-9694",
doi="10.2196/18287",
url="http://medinform.jmir.org/2020/10/e18287/",
url="https://doi.org/10.2196/18287",
url="http://www.ncbi.nlm.nih.gov/pubmed/33026359"
}

@phdthesis{crichton2019improving,
  title={Improving automated literature-based discovery with neural networks: neural biomedical named entity recognition, link prediction and discovery},
  author={Crichton, Gamal Kashaka Omari},
  year={2019},
  school={University of Cambridge}
}

@article{Wei2013PubTatorAW,
  title={PubTator: a web-based text mining tool for assisting biocuration},
  author={Chih-Hsuan Wei and Hung-Yu Kao and Zhiyong Lu},
  journal={Nucleic Acids Research},
  year={2013},
  volume={41},
  pages={W518 - W522}
}

@Article{info:doi/10.2196/20645,
author="Li, Rui
and Yin, Changchang
and Yang, Samuel
and Qian, Buyue
and Zhang, Ping",
title="Marrying Medical Domain Knowledge With Deep Learning on Electronic Health Records: A Deep Visual Analytics Approach",
journal="J Med Internet Res",
year="2020",
month="Sep",
day="28",
volume="22",
number="9",
pages="e20645",
keywords="electronic health records; interpretable deep learning; knowledge graph; visual analytics",
abstract="Background: Deep learning models have attracted significant interest from health care researchers during the last few decades. There have been many studies that apply deep learning to medical applications and achieve promising results. However, there are three limitations to the existing models: (1) most clinicians are unable to interpret the results from the existing models, (2) existing models cannot incorporate complicated medical domain knowledge (eg, a disease causes another disease), and (3) most existing models lack visual exploration and interaction. Both the electronic health record (EHR) data set and the deep model results are complex and abstract, which impedes clinicians from exploring and communicating with the model directly. Objective: The objective of this study is to develop an interpretable and accurate risk prediction model as well as an interactive clinical prediction system to support EHR data exploration, knowledge graph demonstration, and model interpretation. Methods: A domain-knowledge--guided recurrent neural network (DG-RNN) model is proposed to predict clinical risks. The model takes medical event sequences as input and incorporates medical domain knowledge by attending to a subgraph of the whole medical knowledge graph. A global pooling operation and a fully connected layer are used to output the clinical outcomes. The middle results and the parameters of the fully connected layer are helpful in identifying which medical events cause clinical risks. DG-Viz is also designed to support EHR data exploration, knowledge graph demonstration, and model interpretation. Results: We conducted both risk prediction experiments and a case study on a real-world data set. A total of 554 patients with heart failure and 1662 control patients without heart failure were selected from the data set. The experimental results show that the proposed DG-RNN outperforms the state-of-the-art approaches by approximately 1.5{\%}. The case study demonstrates how our medical physician collaborator can effectively explore the data and interpret the prediction results using DG-Viz. Conclusions: In this study, we present DG-Viz, an interactive clinical prediction system, which brings together the power of deep learning (ie, a DG-RNN--based model) and visual analytics to predict clinical risks and visually interpret the EHR prediction results. Experimental results and a case study on heart failure risk prediction tasks demonstrate the effectiveness and usefulness of the DG-Viz system. This study will pave the way for interactive, interpretable, and accurate clinical risk predictions. ",
issn="1438-8871",
doi="10.2196/20645",
url="http://www.jmir.org/2020/9/e20645/",
url="https://doi.org/10.2196/20645",
url="http://www.ncbi.nlm.nih.gov/pubmed/32985996"
}

@article{du2020knowledge,
  title={A knowledge graph of combined drug therapies using semantic predications from biomedical literature: Algorithm development},
  author={Du, Jian and Li, Xiaoying},
  journal={JMIR medical informatics},
  volume={8},
  number={4},
  pages={e18323},
  year={2020},
  publisher={JMIR Publications Inc., Toronto, Canada}
}

@ARTICLE{8758152,
  author={Biswas, Saikat and Mitra, Pabitra and Rao, Krothapalli Sreenivasa},
  journal={IEEE/ACM Transactions on Computational Biology and Bioinformatics}, 
  title={Relation Prediction of Co-Morbid Diseases Using Knowledge Graph Completion}, 
  year={2021},
  volume={18},
  number={2},
  pages={708-717},
  doi={10.1109/TCBB.2019.2927310}}
  
@article{li2020real,
  title={Real-world data medical knowledge graph: construction and applications},
  author={Li, Linfeng and Wang, Peng and Yan, Jun and Wang, Yao and Li, Simin and Jiang, Jinpeng and Sun, Zhe and Tang, Buzhou and Chang, Tsung-Hui and Wang, Shenghui and others},
  journal={Artificial intelligence in medicine},
  volume={103},
  pages={101817},
  year={2020},
  publisher={Elsevier}
}

@inproceedings{gashteovski-etal-2017-minie,
    title = "{M}in{IE}: Minimizing Facts in Open Information Extraction",
    author = "Gashteovski, Kiril  and
      Gemulla, Rainer  and
      del Corro, Luciano",
    booktitle = "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D17-1278",
    doi = "10.18653/v1/D17-1278",
    pages = "2630--2640",
    abstract = "The goal of Open Information Extraction (OIE) is to extract surface relations and their arguments from natural-language text in an unsupervised, domain-independent manner. In this paper, we propose MinIE, an OIE system that aims to provide useful, compact extractions with high precision and recall. MinIE approaches these goals by (1) representing information about polarity, modality, attribution, and quantities with semantic annotations instead of in the actual extraction, and (2) identifying and removing parts that are considered overly specific. We conducted an experimental study with several real-world datasets and found that MinIE achieves competitive or higher precision and recall than most prior systems, while at the same time producing shorter, semantically enriched extractions.",
}

@inproceedings{stanovsky2016creating,
  title={Creating a large benchmark for open information extraction},
  author={Stanovsky, Gabriel and Dagan, Ido},
  booktitle={Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing},
  pages={2300--2305},
  year={2016}
}

@article{Yu2017KnowledgeGF,
  title={Knowledge graph for TCM health preservation: Design, construction, and applications},
  author={Tong Yu and Jinghua Li and Qi Yu and Ye Tian and Xiaofeng Shun and Lili Xu and Ling Zhu and Hongjie Gao},
  journal={Artificial intelligence in medicine},
  year={2017},
  volume={77},
  pages={
          48-52
        }
}

@article{yu2018artificial,
  title={Artificial intelligence in healthcare},
  author={Yu, Kun-Hsing and Beam, Andrew L and Kohane, Isaac S},
  journal={Nature biomedical engineering},
  volume={2},
  number={10},
  pages={719--731},
  year={2018},
  publisher={Nature Publishing Group}
}

@article{shi2017semantic,
  title={Semantic health knowledge graph: semantic integration of heterogeneous medical knowledge and services},
  author={Shi, Longxiang and Li, Shijian and Yang, Xiaoran and Qi, Jiaheng and Pan, Gang and Zhou, Binbin},
  journal={BioMed research international},
  volume={2017},
  year={2017},
  publisher={Hindawi}
}

@article{KANJIRANGAT2021103893,
title = {Enhancing Biomedical Relation Extraction with Transformer Models using Shortest Dependency Path Features and Triplet Information},
journal = {Journal of Biomedical Informatics},
volume = {122},
pages = {103893},
year = {2021},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2021.103893},
url = {https://www.sciencedirect.com/science/article/pii/S1532046421002227},
author = {Vani Kanjirangat and Fabio Rinaldi},
keywords = {Relation extraction, Shortest dependency paths, Triplets, Intra-sentential, Inter-sentential, BioBERT},

}
@article{xing2021understand,
  title={Understand me, if you refer to Aspect Knowledge: Knowledge-aware Gated Recurrent Memory Network},
  author={Xing, Bowen and Tsang, Ivor W},
  journal={arXiv preprint arXiv:2108.02352},
  year={2021}
}


@inproceedings{angeli-manning-2013-philosophers,
    title = "Philosophers are Mortal: Inferring the Truth of Unseen Facts",
    author = "Angeli, Gabor  and
      Manning, Christopher",
    booktitle = "Proceedings of the Seventeenth Conference on Computational Natural Language Learning",
    month = aug,
    year = "2013",
    address = "Sofia, Bulgaria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W13-3515",
    pages = "133--142",
}
@inproceedings{lechelle-langlais-2018-revisiting,
    title = "Revisiting the Task of Scoring Open {IE} Relations",
    author = "L{\'e}chelle, William  and
      Langlais, Philippe",
    booktitle = "Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018)",
    month = may,
    year = "2018",
    address = "Miyazaki, Japan",
    publisher = "European Language Resources Association (ELRA)"
}

@book{boyd2004convex,
  title={Convex optimization},
  author={Boyd, Stephen and Boyd, Stephen P and Vandenberghe, Lieven},
  year={2004},
  publisher={Cambridge university press}
}

@article{GODARA2020105448,
title = "Sequential pattern mining combined multi-criteria decision-making for farmers’ queries characterization",
journal = "Computers and Electronics in Agriculture",
volume = "173",
pages = "105448",
year = "2020",
issn = "0168-1699",
doi = "https://doi.org/10.1016/j.compag.2020.105448",
url = "http://www.sciencedirect.com/science/article/pii/S0168169920300120",
author = "Samarth Godara and Durga Toshniwal",
keywords = "Farmers query, Data mining in agriculture, Query characterization, Kisan call center, Association rule mining, Multi-criteria decision-making"
}

@inproceedings{ngo2018ontology,
  title={Ontology based approach for precision agriculture},
  author={Ngo, Quoc Hung and Le-Khac, Nhien-An and Kechadi, Tahar},
  booktitle={International Conference on Multi-disciplinary Trends in Artificial Intelligence},
  pages={175--186},
  year={2018},
  organization={Springer}
}

@article{SOULIGNAC20191050,
title = "GECO, the French Web-based application for knowledge management in agroecology",
journal = "Computers and Electronics in Agriculture",
volume = "162",
pages = "1050 - 1056",
year = "2019",
issn = "0168-1699",
doi = "https://doi.org/10.1016/j.compag.2017.10.028",
url = "http://www.sciencedirect.com/science/article/pii/S0168169917300492",
author = "Vincent Soulignac and François Pinet and Eva Lambert and Laurence Guichard and Luce Trouche and Sophie Aubin"}

@article{WEN200733,
title = "A knowledge-based intelligent electronic commerce system for selling agricultural products",
journal = "Computers and Electronics in Agriculture",
volume = "57",
number = "1",
pages = "33 - 46",
year = "2007",
issn = "0168-1699",
doi = "https://doi.org/10.1016/j.compag.2007.01.016",
url = "http://www.sciencedirect.com/science/article/pii/S0168169907000336",
author = "W. Wen"}

@article{canadas2017development,
  title={Development of a web tool for action threshold evaluation in table grape pest management},
  author={Ca{\~n}adas, Joaqu{\'\i}n and del {\'A}guila, Isabel M and Palma, Jos{\'e}},
  journal={Precision Agriculture},
  volume={18},
  number={6},
  pages={974--996},
  year={2017},
  publisher={Springer}
}

@article{lagos2017ontology,
  title={An ontology-based decision support system for the diagnosis of plant diseases},
  author={Lagos-Ortiz, Katty and Medina-Moreira, Jos{\'e} and Paredes-Valverde, Mario Andr{\'e}s and Espinoza-Mor{\'a}n, Winston and Valencia-Garc{\'\i}a, Rafael},
  journal={Journal of Information Technology Research (JITR)},
  volume={10},
  number={4},
  pages={42--55},
  year={2017},
  publisher={IGI Global}
}

@article{JONQUET2018126,
title = "AgroPortal: A vocabulary and ontology repository for agronomy",
journal = "Computers and Electronics in Agriculture",
volume = "144",
pages = "126 - 143",
year = "2018",
issn = "0168-1699",
doi = "https://doi.org/10.1016/j.compag.2017.10.012",
url = "http://www.sciencedirect.com/science/article/pii/S0168169916309541",
author = "Clément Jonquet and Anne Toulet and Elizabeth Arnaud and Sophie Aubin and Esther {Dzalé Yeumo} and Vincent Emonet and John Graybeal and Marie-Angélique Laporte and Mark A. Musen and Valeria Pesce and Pierre Larmande",
keywords = "Ontologies, Controlled vocabularies, Knowledge organization systems or artifacts, Ontology repository, Metadata, Mapping, Recommendation, Semantic annotation, Agronomy, Food, Plant sciences, Biodiversity"}

@article{harper2018agbiodata,
  title={AgBioData consortium recommendations for sustainable genomics and genetics databases for agriculture},
  author={Harper, Lisa and Campbell, Jacqueline and Cannon, Ethalinda KS and Jung, Sook and Poelchau, Monica and Walls, Ramona and Andorf, Carson and Arnaud, Elizabeth and Berardini, Tanya Z and Birkett, Clayton and others},
  journal={Database},
  volume={2018},
  year={2018},
  publisher={Narnia}
}

@article{doi:10.1080/10496505.2017.1378105,
author = {Maayan Zhitomirsky-Geffet and Chaim Z. Mograbi},
title = {A New Framework for Collaborative Ontology Construction for an Agricultural Domain from Heterogeneous Information Resources},
journal = {Journal of Agricultural \& Food Information},
volume = {19},
number = {3},
pages = {203-227},
year  = {2018},
publisher = {Taylor & Francis},
doi = {10.1080/10496505.2017.1378105},

URL = { 
        https://doi.org/10.1080/10496505.2017.1378105
    
},
eprint = { 
        https://doi.org/10.1080/10496505.2017.1378105
    
}

}

@article{INGRAM2019100300,
title = "Searching for meaning: Co-constructing ontologies with stakeholders for smarter search engines in agriculture",
journal = "NJAS - Wageningen Journal of Life Sciences",
volume = "90-91",
pages = "100300",
year = "2019",
issn = "1573-5214",
doi = "https://doi.org/10.1016/j.njas.2019.04.006",
url = "http://www.sciencedirect.com/science/article/pii/S1573521418302161",
author = "Julie Ingram and Pete Gaskell"}

@INPROCEEDINGS{8241212,

  author={E. {Abrahão} and A. R. {Hirakawa}},

  booktitle={2017 Second International Conference on Information Systems Engineering (ICISE)}, 

  title={Task Ontology Modeling for Technical Knowledge Representation in Agriculture Field Operations Domain}, 

  year={2017},

  volume={},

  number={},

  pages={12-16},}


@article{Sawant:240701,
      note = {The IFAMR is published quarterly my IFAMA. For more  information visit: www.ifama.org.},
      author = {Sawant, Minal and Urkude, Rajesh and Jawale, Sandip},
      url = {http://ageconsearch.umn.edu/record/240701},
      series = {Volume 19},
      journal = {International Food and Agribusiness Management Review},
      title = {Organized Data and Information for Efficacious Agriculture  Using PRIDE Model},
      number = {1030-2016-83147},
      doi = {10.22004/ag.econ.240701},
      recid = {240701},
      pages = {16},
      address = {2016-06-15},
      year = {2016},
      month = {Jun},
}

@article{saiz2020smart,
  title={From smart farming towards agriculture 5.0: a review on crop data management},
  author={Saiz-Rubio, Ver{\'o}nica and Rovira-M{\'a}s, Francisco},
  journal={Agronomy},
  volume={10},
  number={2},
  pages={207},
  year={2020},
  publisher={Multidisciplinary Digital Publishing Institute}
}

@article{tshitoyan2019unsupervised,
  title={Unsupervised word embeddings capture latent knowledge from materials science literature},
  author={Tshitoyan, Vahe and Dagdelen, John and Weston, Leigh and Dunn, Alexander and Rong, Ziqin and Kononova, Olga and Persson, Kristin A and Ceder, Gerbrand and Jain, Anubhav},
  journal={Nature},
  volume={571},
  number={7763},
  pages={95--98},
  year={2019},
  publisher={Nature Publishing Group}
}

@inproceedings{mairal2009online,
  title={Online dictionary learning for sparse coding},
  author={Mairal, Julien and Bach, Francis and Ponce, Jean and Sapiro, Guillermo},
  booktitle={Proceedings of the 26th annual international conference on machine learning},
  pages={689--696},
  year={2009}
}

@article{aharon2006k,
  title={K-SVD: An algorithm for designing overcomplete dictionaries for sparse representation},
  author={Aharon, Michal and Elad, Michael and Bruckstein, Alfred},
  journal={IEEE Transactions on signal processing},
  volume={54},
  number={11},
  pages={4311--4322},
  year={2006},
  publisher={IEEE}
}

@article{Celli2015AGRISPA,
  title={AGRIS: providing access to agricultural research data exploiting open data on the web},
  author={Fabrizio Celli and Thembani Malapela and Karna Wegner and Imma Subirats and Elena Kokoliou and Johannes Keizer},
  journal={F1000Research},
  year={2015},
  volume={4}
}

@article{salakhutdinov2009semantic,
  title={Semantic hashing},
  author={Salakhutdinov, Ruslan and Hinton, Geoffrey},
  journal={International Journal of Approximate Reasoning},
  volume={50},
  number={7},
  pages={969--978},
  year={2009},
  publisher={Elsevier}
}
@inproceedings{popescul2003statistical,
  title={Statistical relational learning for document mining},
  author={Popescul, Alexandrin and Ungar, Lyle H and Lawrence, Steve and Pennock, David M},
  booktitle={Third IEEE International Conference on Data Mining},
  pages={275--282},
  year={2003},
  organization={IEEE}
}


@inproceedings{getoor2011learning,
  title={Learning statistical models from relational data},
  author={Getoor, Lise and Mihalkova, Lilyana},
  booktitle={Proceedings of the 2011 ACM SIGMOD International Conference on Management of data},
  pages={1195--1198},
  year={2011}
}


@book{koller2007introduction,
  title={Introduction to statistical relational learning},
  author={Koller, Daphne and Friedman, Nir and D{\v{z}}eroski, Sa{\v{s}}o and Sutton, Charles and McCallum, Andrew and Pfeffer, Avi and Abbeel, Pieter and Wong, Ming-Fai and Heckerman, David and Meek, Chris and others},
  year={2007},
  publisher={MIT press}
}

@article{arroyo2019unsupervised,
  title={Unsupervised sentence representations as word information series: Revisiting TF--IDF},
  author={Arroyo-Fern{\'a}ndez, Ignacio and M{\'e}ndez-Cruz, Carlos-Francisco and Sierra, Gerardo and Torres-Moreno, Juan-Manuel and Sidorov, Grigori},
  journal={Computer Speech \& Language},
  volume={56},
  pages={107--129},
  year={2019},
  publisher={Elsevier}
}
