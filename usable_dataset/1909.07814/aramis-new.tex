\section{Aramis}\label{sec:aramis}
%\vspace{-0.1cm}

In this section, we describe Aramis, a general technique to convert
any semi-honest secure MPC
protocol into a secure MPC protocol tolerating malicious
corruptions by relying on secure hardware. The threshold of corrupted parties tolerated by the
semi-honest protocol is retained in the malicious
secure protocol by our technique. 
\\\\
\noindent\textbf{Threat Model.} We consider a strong threat model where not only does the adversary control the operating system of the corrupted parties 
(i.e., the host operating system is outside the Trusted Computing Base)
but also observes the entire state of their secure hardware.
Aramis makes a very minimal
trust assumption of {\em integrity} on
hardware, namely that of code attestation (the outputs generated by the hardware are indeed from the code that it attested to).
This implicitly requires
the hardware to possess a trusted component that can produce
signatures and this signature scheme cannot be forged
by the adversary. 
However, the adversary can see the state  (i.e., all the code and the user data) of the hardware belonging to the corrupted parties, i.e., we {\em do not} assume {\em confidentiality} of state.
Prior works~\cite{vc3, obliviousmpml, GuptaFC16, BahmaniFC17,gcsgx,ndss1,ndss2,ndss3,slalom,opaque,chiron} that combine \mpc and hardware (SGX)  make stronger trust assumption on the hardware of both confidentiality and integrity,
 and hence, provide security only in a weaker threat model where the hardware hides the data residing in it from the adversary. 
%Aramis makes a very minimal
%trust assumption of {\em integrity} on
%hardware: the code and data residing in the hardware cannot be modified by the adversary.
%This implicitly requires
%the hardware to possess a trusted component that can produce
%signatures and this signature scheme cannot be forged
%by an adversary. 
%We do not assume confidentiality, that is, the adversary can see all the code and user data that resides in  the hardware belonging to the corrupted parties. 
%This significantly weakens the trust assumption on hardware compared to prior work that combines \mpc and SGX (\cite{vc3, obliviousmpml, GuptaFC16, BahmaniFC17,gcsgx,ndss1,ndss2,ndss3,slalom}).
\\\\
\noindent\textbf{Overview.} At a very high level, Aramis
exploits the following (well-known) observation: in order for a
semi-honest protocol to be made maliciously secure, one must ensure
that all messages sent by every party $P_i$ are computed honestly
according to the specification of the semi-honest protocol consistent
with $P_i$'s input and the transcript so far.
The next observation we make is that if party $P_i$ possesses hardware
whose code can be attested by party $P_j$ (and vice-versa), then $P_j$
can obtain guarantees on the correctness of protocol messages sent by
$P_i$ as long as these messages are computed and signed by $P_i$'s
hardware.
Using these observations, we can convert a semi-honest secure protocol into one that is maliciously secure by having every protocol message of $P_i$ be computed by the trusted hardware that $P_i$ executes. 
We shall now describe our techniques in more detail. 
We first describe the ideal functionality that is assumed out of the hardware in Section \ref{subsec:sgxideal}. 
We then describe our technique in Section~\ref{sec:shtomcompiler}.
%
Finally, we provide an implementation of Aramis using Intel SGX as the underlying secure hardware. 
We explain how Intel SGX can realize the ideal functionality
in Section~\ref{sec:fattest-sgx} and challenges in porting semi-honest
\mpc protocols to SGX in Section~\ref{sec:challenges-aramis}.
%The structure of the underlying semi-honest secure MPC protocol that we use is formalized in Section \ref{subsec:nextmessagefunction} and we present our compiler in Section \ref{subsec:shtomcompiler}. Finally, we describe some of the challenges in porting secure computation protocols to SGX in Section \ref{subsec:porting}.
%\vspace{-0.23cm}

\subsection{The attestation ideal functionality $\fattest$}
\label{subsec:sgxideal}
\noindent\textbf{Description.} We formally define the ideal functionality for attested executions 
%of deterministic functions 
in Figure \ref{fig:attestideal}.
% and later describe in Section~\ref{sgxtoideal} how Intel SGX can be used to realize this functionality.
The functionality is parameterized by a signing key pair $(\vk,\sksign)$. Let 
 $\sign_{\sksign}(m)$ denote the signing algorithm on message $m$ and $\verify_{\vk}(m,\sigma)$ denote verification of signature $\sigma$ on message $m$. 
At a high level, this functionality allows users to specify a function $g$ to the ideal functionality once using the $\gcommit$ command. 
The functionality returns a token $\token_g$ generated as $\sign_\sksign(H(g))$, where $H$ is a collision resistant hash function. 
Note that this token is publicly verifiable given $g$ and $\vk$.
Let $\st_\ctr$ be an internal state that the functionality maintains,
indexed by $\ctr$ -- this state can be maintained by signing it along
with $\ctr$ and verifying the signature of the state on every input
message.
When the functionality $\fattest$ is initialized, the initial state $\st_0$ is empty (or, $\epsilon$). % where $r$ denotes all the randomness that $g$ will ever use. 
Subsequent invocations of the functionality is done on input $w_\ctr$
% and program counter $\ctr$ 
using the $\compute$ command. 
The function $g$ is a deterministic mapping from $(\ctr,w_{\ctr},r_\ctr,\st_{\ctr-1})$ to
$(y_\ctr,\st_{\ctr})$, where $r_\ctr$ is the required randomness.
% picked by $\fattest$. 
The functionality picks randomness $r_\ctr$, evaluates $g$ and provide a signature on the function output $y_\ctr$ using the signing key $\sksign$.  
Furthermore, $(y_\ctr,\st_\ctr)$ is always given to party $P$ such that $\st_\ctr$ contains $r_\ctr$ in clear and 
%$g$ is a
%deterministic function mapping $(\ctr,w_{\ctr},r,\st_{\ctr-1})$ to
%$(y_\ctr,\st_{\ctr})$. 
%
%Note, that doing so 
this ensures that there is no information hidden from $P$ and we only assume correct execution of $g$.
That is, the ideal functionality can evaluate functions and provide signed outputs and these outputs could have anyway been computed by party $P$ given
knowledge of $g, w_\ctr, r_\ctr, \ctr, \st_\ctr$, which are all known to $P$. 
Thereby, we only assume that the functionality will sign the output of $g$ on the appropriate input and not hide any  data from $P$. This significantly weakens what is assumed from the trusted hardware.


%\vspace{0.3in}

%\aseem{Figure 8, shouldn't ideal functionality store g somewhere, or it is understood?}

\begin{tffbox}
\begin{mdframed}
\begin{center}
{\bf Functionality} $\fattest^{(\vk,\sksign)}$
\end{center}
%\vspace{.1in}
{\small

$\fattest$ interacts with a party $P$.

\begin{tiret}
       \item On input message $(\gcommit,g)$ from $P$,
% sample $r$ from $\zo^*$ at random, where $r$ is all the randomness that computation of $g$ will ever need.
       \begin{enumerate}
       \item Record $(\gcommit,\st_0)$, where $\st_0 = \epsilon$;
       \item Send $( \st_0, \token_g)$ to $P$, where $\token_g = \sign_\sksign(H(g))$.
       \item Ignore further $(\gcommit,g)$ messages.
       \end{enumerate}
	\item  On input message $(\compute,w_\ctr)$ from $P$, retrieve $\st_{\ctr-1}$, pick required randomness $r_\ctr$ and compute $g(\ctr,w_\ctr,r_\ctr,\st_{\ctr-1})$ to obtain $(y_\ctr,\st_{\ctr})$ such that $\st_\ctr$ contains $(y_\ctr, r_\ctr)$. Send $(y_\ctr,\ctr, \sign_{\sksign}(y_\ctr || \ctr),\st_\ctr)$ to $P$.
	       			
\end{tiret}
%\vspace{.1in}
} %SMALL
\end{mdframed}
\caption{\sl The Authentication functionality $\fattest^{(\vk,\sksign)}$.}
\label{fig:attestideal}
	%\vspace{-0.2cm}
\end{tffbox}


\subsection{Semi-honest security to malicious security}
\label{subsec:nextmessagefunction}

Our technique takes any semi-honest secure MPC protocol and converts
it into a malicious secure MPC protocol in the
$\fattest^{(\vk,\sksign)}-$hybrid model. The idea is to have messages
sent by every party $P_i$ to every other party $P_j$ in the
semi-honest protocol be computed by the corresponding
$\fattest^{(\vk_i,\sksign_i)}$ functionality interacting with $P_i$,
where $(\vk_i,\sksign_i)$ are keys used by the functionality.
These messages can be verified by functionality $\fattest^{(\vk_j,\sksign_j)}$ interacting with $P_j$. 
We assume that every $\fattest^{(\vk_i,\sksign_i)}$ knows the verification key $\vk_j$ used by functionalities of all other parties $P_j$ in a reliable manner. 
Later, we show how to achieve this through the use of remote attestation in the context of Intel SGX. We now set notation and describe the next message function of any semi-honest secure MPC protocol and how we modify it for our use.
\\\\
\noindent\textbf{Next message function.} Let $\pi(\cdot)$ be the next message function of any semi-honest secure MPC protocol. $\pi(\cdot)$ takes the following values as input - two party ids $i$ and $j$, input $x_i$, a round number $\ctr$, randomness $r_{i,j,\ctr}$ and $\transcript_i$, which includes the transcript of all messages sent and received by the party $P_i$ so far. 
Given these, $\pi(\cdot)$ outputs $y_{\ctr}^{i,j}$, which is the message that $P_i$ must send to $P_j$ in round $\ctr$ and also updates $\transcript_i$ appropriately. Additionally, $\pi(\cdot)$ takes message $y_{\ctr}^{j,i}$ sent by $P_j$ to $P_i$ at round $\ctr$ and update $\transcript_i$ with this message. We now describe how to modify $\pi(\cdot)$ to $\pi^*(\cdot)$ to incorporate checks to detect malicious behavior.
\\\\
\noindent\textbf{Modified next message function.} $\pi^*(\cdot)$, is the modified function that builds upon $\pi(\cdot)$ and we describe it for $P_i$.
%We will assume that every $\fattest^{g,(\vk_i,\sksign_i)}(P_i)$ knows and agrees upon $\pi(\cdot)$; we will show how to achieve this as well through attestation. 
%The modifications made to the next message function are now described:

\begin{enumerate}

\item For $\ctr = 1$, 
%$\pi^*(\cdot)$, picks an execution identity $\sid$. 
Let $x_i$ be the input of $P_i$ in $\pi(\cdot)$. Then,
%let $y^i_0$ denote $x_i$, and the randomness $r_i$ that will be used by $P_i$ in $\pi(\cdot)$. 
$(\ctr, x_i)$ is stored as $\st_1$ (also called as $\transcript^1_i$) and sent to $P_i$.
% after signing it with $\sksign_i$. 

\item When $\pi^*(\cdot)$ receives a message $M =
  (y_{\ctr}^{j,i},\ctr,\sigma)$ from party $P_j$, it runs
  $\verify_{\vk_j}((y_{\ctr}^{j,i},\ctr),\sigma)$. If verification
  succeeds, it appends $M$ to $\transcript_i$. Else, $P_i$ aborts.

\item $\pi^*(\cdot)$ on input $(\ctr, \st_{\ctr-1}, j)$ computes the
  next message from $P_i$ to $P_j$ as follows: It checks that
  $\st_{\ctr-1}$ contains a valid transcript of all messages computed
  so far. If it verifies, it picks randomness $r_{i,j,\ctr}$ and runs $\pi(\ctr, \st_{\ctr-1}, j, r_{i,j,\ctr})$ to compute next message $y^{i,j}_\ctr$ and updated state $\st_\ctr$ (containing $r_{i,j,\ctr}$). 
  Else it outputs $\bot$. 
Note that $\st_{\ctr-1}$ already contains
  input $x_i$, the input of party $P_i$.
\end{enumerate}~\\
\noindent\textbf{Malicious MPC in the $\fattest-$hybrid model.}
\label{sec:shtomcompiler}
The malicious \mpc protocol works as follows: Each party $P_i$ invokes $\fattest^{(\vk_i,\sksign_i)}$ with the command $\gcommit$ using function $\pi^*(\cdot)$ described above and sends the received token $\token^{(i)}_{\pi^*}$ to other parties $P_j$. It  receives similar tokens $\token^{(j)}_{\pi^*}$ from party $P_j$ and verifies it under $\vk_j$. Party $P_i$ aborts if any of these verifications fail. If all verifications succeed, it proceeds with running $\pi^*(\cdot)$ inside $\fattest^{(\vk_i,\sksign_i)}$ as described formally in Figure~\ref{fig:shtomprotocol}.

%whenever party $P_i$ must send a message according to $\pi(\cdot)$ to party $P_j$ in the underlying semi-honest secure protocol in round $\ctr$, $P_i$ invokes $\fattest^{\pi^*(\cdot)}$ along with the appropriate messages needed to compute the message $y_{\ctr}^{i,j}$. The functionality will check the validity of all messages and transcript and if correct, will produce $y_{\ctr}^{i,j}$ along with a signature on it (along with $\ctr,\sid$). This signed message is then passed on by $P_i$ to $P_j$ as the message in that round. 
%The complete protocol is in Figure \ref{fig:shtomprotocol}.

%\vspace{0.3in}

%%\aseem{(a) What is sid in Figure 9, is it just i? (b) In the fifth
%  step, it invokes F sub attest on (sid, Compute, j), is the last
%  argument j? Shouldn't it be the output of pi star? (c) The order
%  of ctr, sigma, y sub i,j is inconsistent, it won't typecheck :).}

\begin{tffbox}
\begin{mdframed}
\begin{center}
{\bf Protocol} $\protshtom$
\end{center}
%\vspace{.1in}
{\small

Party $P_i$ with input $x_i$ interacts with $\{P_j\}_{j\ne i}$ and $\fattest^{(\vk_i,\sksign_i)}$ and does the following:
\begin{tiret}
\item Invokes $\fattest^{(\vk_i,\sksign_i)}$ on $(\gcommit,\pi^*)$ to receive $( \st^{(i)}_0, \token^{(i)}_{\pi^*})$ and sends $\token^{(i)}_{\pi^*}$ to all parties $P_j$, $j \ne i$.

\item Receives $\token^{(j)}_{\pi^*}$ from $P_j$ and runs $\verify_{\vk_j}(H(\pi^*), \token^{(j)}_{\pi^*} )$ for all $j \in [n]\setminus i$. Aborts if one of these checks fail.

\item Invokes $\fattest^{(\vk_i,\sksign_i)}$ on $(\compute, x_i)$ to get $\transcript_i^1$ containing input $x_i$. %randomness $r_i$ that would be used to generate future messages from $P_i$.

\item When $P_i$ receives a message $M = (y_{\ctr}^{j,i},\ctr,\sigma)$ from party $P_j$, it invokes $\fattest^{(\vk_i,\sksign_i)}$ on  $( \compute, (y_{\ctr}^{j,i},\ctr,\sigma))$ and receives updated transcript or $\bot$ (and aborts).

\item When $P_i$ needs to send next message to $P_j$ it invokes $\fattest^{(\vk_i,\sksign_i)}$ on $( \compute, j)$ and receives $(y_{\ctr}^{i,j},\ctr, \sigma)$ along with updated transcript and randomness used. Here, $\sigma$ is a signature on $(y_{\ctr}^{i,j},\ctr)$ under $\sksign_i$. It sends $(y_{\ctr}^{i,j},\ctr, \sigma)$ to $P_j$.
   
   \item When $P_i$ has no more messages to send in $\pi(\cdot)$, it computes the output of the function from 
%transcript messages 
$\transcript_i$.
	       			
\end{tiret}
%\vspace{.1in}
} %SMALL
\end{mdframed}
\caption{\sl Malicious secure MPC $\protshtom$.}
\label{fig:shtomprotocol}
\end{tffbox}


%\vspace{0.3in}
\begin{tffbox}
\begin{mdframed}
\begin{center}
{\bf Functionality} $\fmpc^f(P_1,\cdots,P_n)$
\end{center}
%\vspace{.1in}
{\small

$\fmpc^f$ interacts with parties $\{P_1,\cdots,P_n\}$ and the adversary $\simu$.

\begin{tiret}
       \item On input message $x_i$ from $P_i$ record $x_i$ and ignore further $x_i$ from $P_i$
       \item Upon receiving $x_i$ from all $P_i, i\in [n]$, compute $y = f(x_1,\cdots,x_n)$ and send to $\simu$.
       \item Upon receiving $(i,\mathsf{Send})$ or $(i,\bot)$ from $\simu$, send $y$ or $\bot$ to $P_i$.
	       			

	       			\end{tiret}
%\vspace{.1in}
} %SMALL
\end{mdframed}
\caption{\sl The MPC functionality $\fmpc^f$.}
\label{fig:fideal}
%	\vspace{-0.5cm}
\end{tffbox}
%\vspace{-1cm}

\noindent\textbf{Malicious Security.} Next, we prove that if $\pi$ is secure against semi-honest adversaries, then the protocol described in Figure~\ref{fig:shtomprotocol} is an \mpc protocol secure against malicious adversaries with the same corruption threshold.  We prove the following result using the standard simulation paradigm in Appendix~\ref{app:proof}.

\begin{theorem}
\label{theorem:maliciousmpc}
Let $\pi(\cdot)$ be a semi-honest secure MPC protocol securely realizing $\fmpc^f$. Then, protocol $\protshtom$ described in Figure \ref{fig:shtomprotocol} securely realizes $\fmpc^f$ in the $\fattest^{(\vk_i,\sksign_i)}-$hybrid model (with $i \in [n]$) against malicious adversaries.
\end{theorem}

\subsection{Realizing $\fattest$}
\label{sec:fattest-sgx}
We note that the ideal functionality assumed out of the hardware can potentially be realized using various hardware platforms that provide code attestation and secure signing, e.g., STM32H7, MediaTek MT3620, CEC1702, ARMTrustZone, Intel SGX, etc. In this work, we provide an implementation of Aramis based on Intel SGX. 

SGX allows a host to create a protected region known as an enclave. Intel gives integrity guarantees, that is, the code and the data residing in the enclave, once attested, cannot be modified by the host or the operating system. 
When SGX receives a $\gcommit$ command (Figure~\ref{fig:attestideal}) for a function $g$, then it creates an enclave with code $g$.
Randomness $r_\ctr$ of Figure~\ref{fig:attestideal} can be sampled in SGX using {\tt sgx\_read\_rand} command. 
The attestation token $\token_g$ is generated by SGX communicating with Intel's Attestation Service (IAS) and this token is publicly verifiable given $g$ and  public verification key corresponding to Intel's Report Signing Key.
The key-pair $(\vk,\sksign)$ for ECDSA signature scheme is also generated inside the enclave and the verification key $\vk$ is sent as payload to IAS during the generation of the attestation token. 
The token $\token_g$ contains the verification key $\vk$ in the clear and this $\vk$ can be used to verify the signed outputs $y_\ctr$.
Now, on receiving the $\compute$ command, the enclave starts executing the code of $g$ and produces outputs signed under $\sksign$.

While running \mpc in the $\fattest$-hybrid, we require the enclave to reliably have verification keys used by enclaves of all other parties. This can be done by attaching the following prelude to $\pi^*$ (the code running inside SGX): Read the tokens of all parties, parse them to obtain the verification keys, and verify the signature on the tokens using verification key of Intel's Report Signing key. Note that since all the parties are running the same function $\pi^*$ (appended with this prelude), they can compute the hash of $\pi^*$ locally and compare it with the hash in the tokens (which has been signed by Intel's IAS) of all the other parties, proceeding only if they all match perfectly.

\subsection{Implementation challenges with Intel SGX}
\label{sec:challenges-aramis}

%\dg{SGX memory issues - [ReLU chunking, liveness ], ecall-ocall message passing payload optimizing, MAC}

We outline some of the key challenges in implementing \mpc between multiple SGX enclaves that involve multiple rounds of interaction and operate over large volumes of data.

 
\subsubsection{Memory constraints in SGX}
In SGX, all the enclave content, including code, and related data is stored in a special region of memory known as the Enclave Page Cache (EPC). The size of EPC is fixed in BIOS and can have a maximum size of 128MB. Typically, paging facilitates the execution of enclaves which cannot fit in EPC and any page that is evicted out is encrypted before storing it on unprotected memory \cite{intelsgxperf}. This additional overhead  has  detrimental effects on the overall performance of the enclave application. 
We reduce the working set of secure inference tasks to limit these overheads.
%To overcome this, we make changes to our code in the following way:
\begin{itemize}
	\item \textit{ReLU and MaxPool functions:} 
  % We split the computation of memory intensive non-linear functions into chunks  that fit  in EPC to avoid paging. For example, a secure ReLU computation that requires 120MB memory is split into 3 chunks  of 40MB each. Note that chunking increases the number of \mpc rounds and very small chunks are actually detrimental to performance.
  We split the computation of memory-intensive non-linear functions into chunks that fit in the EPC to avoid paging. However, lower chunk sizes  increase  the number of rounds, and so, the chunk sizes must be carefully selected. For \resnet, we  set the chunk sizes for ReLU and MaxPool layers to be 40 MB and 10 MB respectively. For our network configurations, the increase in rounds is justified by the elimination of paging costs and reduction in end-to-end runtimes.
	\item \textit{Convolution and Matrix Multiplication functions:} For the linear functions, we block the matrices into smaller ones, process the blocks, and aggregate them. We ensure that individual blocks fit in EPC. 
	\item \textit{Liveness Analysis:} Athos implements liveness analysis (Section~\ref{sec:athosopt}) which reduces the memory footprint of the compiled DNNs.  For example, the memory footprint of \resnet reduces from 1100 MB to 397 MB due to liveness analysis. When chunking and liveness analysis are done together, the memory footprint of \resnet comes down to 297MB.

\end{itemize}

%For the case of \resnet, we chose a chunksize of 40, 10 and 40 MiB for ReLU, MaxPool and Convolution, respectively. The number of rounds of a function increases linearly with the number of chunks needed to complete the function evaluation. For example, in \resnet, the ReLU with the maximum elements requires 5 chunks for 40 MiB each, making the rounds grow from 10 to 50. The values of chunksizes were chosen empirically to find a sweet-spot between increased number of rounds and decreased working set memory. In isolation to this chunking optimization, with liveness analysis, we observed that the memory footprint of \resnet comes down from 1100 MB to a mere 397 MB. Both these optimizations played a major role in drastically improving the performance of Aramis for our benchmarks.

\subsubsection{Porting Interactive Protocols to SGX}
To the best of our knowledge, we are the first work to implement highly interactive protocols in SGX and this comes with unique challenges. For example, whenever data is passed across the enclave's protected memory region, it has to be {\em marshalled} in/out of the region.
%\footnote{When pointers to memory are passed as parameters into the enclave via an $\mathsf{ecall}$, the referenced data block is {\em marshalled} into the enclave, specifically into the protected memory region that an enclave uses. Similarly, when a pointer to enclave data, residing in protected memory region, is passed outside an enclave via an $\mathsf{ocall}$, the referenced data block is marshalled out of the protected memory region.}. 
The performance of marshalling depends on the size of the parameters crossing the bridge. Larger parameters imply slower marshalling~\cite{intelsgxperf}, while smaller parameters increase the total numbers of cross-bridge calls (which have an overhead of their own). 
%For example, we observed that in order to send 1MB data in/out of the enclave, if 1048576 calls (OCALL-ECALL pair) are done with each carrying a payload of 1B, then it takes about 3.1 s for the calls alone, 16 calls with payload of 65KB each only take about 0.5 ms and 2 calls of 512KB each take 0.8 ms. Since we make calls of the order of 100000, 
Thus, we tune the payload size carefully. 
We also implement the techniques in~\cite{sealedglass}  for optimizing communication involving enclaves. 
%Apart from this, for efficiency purposes, we also employ other common optimizations for establishing symmetric key authenticated communication channels between enclaves as has already been suggested in \cite{sealedglass}.



\begin{comment}

\subsection{Porting crypto protocols to SGX}\label{subsec:porting}

In this section we describe how keys and code are exchanged and attested by the enclaves during the setup phase and also discuss other technical issues when porting crypto protocols to SGX. %Before doing so, we set some notation and provide some background on Intel SGX.
%\\\\
%\noindent\textbf{Background on Intel SGX.} %We present a very high level overview over here and defer a more detailed discussion to Appendix \ref{appendix:sgx}. 
%A {\em Trusted Execution Environment (TEE)} is an area of the processor that promises to provide security guarantees like data privacy and code integrity to a program that is loaded inside of it, even in the presence of a malicious operating system and hypervisor. With the Skylake series of processors, Intel introduced a new set of instructions, called {\em Intel Software Guard Extensions} (SGX), which provides a way to realize TEE on Intel chipsets. This is enforced through hardware access control mechanisms for the pages belonging to an application loaded with SGX. Intel SGX aims to provide the guarantee that code and data of the secure application can neither be read nor modified by even privileged software on the machine. Naturally, providing these guarantees are very hard and reducing the assumption needed of the TEE is of paramount importance. 

%Applications typically contain two parts: an {\em enclave} which contains all sensitive code and data, and the {\em standard} part, which handles all system calls related to input/output and sockets. A chunk of memory, called {\em Processor Reserved Memory} (around 128 MB) is set aside for holding the enclave data pages. There are two types of function calls in SGX - $\mathsf{ecall}$ and $\mathsf{ocall}$ with which the program control flow enters/exits an enclave - e.g., to make system calls. 

%Enclave Attestation is a protocol by which an enclave proves its identity to another application or enclave. There are two types of enclave attestations: a) Local, when both enclaves reside on the same machine; and b) Remote, when the enclaves reside on different machines. In the latter case, the enclave proving its identity (say A) first proves its identity locally to a special enclave known as the Quoting Enclave (QE) which has keys provisioned by Intel. Upon successful verification, QE queries Intel's Attestation Service (IAS) for an attestation certificate (sometimes referred to as a report). This report can then be used by the second enclave (B) to verify the identity of A using IAS's public key. Once attestation is completed successfully, A can set up a private and authenticated channel with B using standard mechanisms.

%\mayank{Changes made here.}
\noindent\textbf{Eastablishing Keys between SGX Enclaves.} Protocol setup involves the following steps:
\begin{itemize}
	\item To begin with, every enclave in the system already
          reliably possesses a public verification key
          $\vk_{\textrm{\tiny{irs}}}$ of the Intel Attestation Server
          (IAS), corresponding to a private key known as Intel's
          Report Signing Key~\cite{intel_sign}. Along with this, each
          enclave also has the MPC code that computes a function $f$
          (\aseem{Should we just call it pi (if it is same as pi in
            the formalization above)?}), which is the function
          that all the enclaves want to compute over their private
          inputs.
	\item Now, each enclave prepares a report which includes its
          identity $i$, a hash measurement (MRENCLAVE) (\aseem{What is
            MRENCLAVE? Can we briefly say?}) of the MPC
          code, a public key for encryption ($\pk_i$), and a
          verification key ($\vk_i$) for a signature scheme in it --
          these keys will be used for authenticated and encrypted
          communication with other enclaves (\aseem{Where does
            encryption come in? So far we have told the reader that we
          don't need encryption. Should we write a short note here
          that the encryption is to hide from a network attacker (not
          MPC attacker)? Or actually how about just let the host deal
          with the network attacker? I.e. have a TLS connection
          between parties that terminates at the host, if I understand
          correctly this is basically assumed by all MPC papers.}). The enclave sends this
          report to the TruCE server \cite{ibmsgx} which relays them
          to the Intel Attestation Server (IAS). The IAS replies back
          with an Attestation Verification Report that has been signed
          using the Report Signing Key. The TruCE server saves this
          report in a key value store that has been indexed by a
          unique ID (specific to each enclave), called TruCE ID.
	\item Every pair of enclaves share their TruCE IDs with each other. Using the TruCE ID of other enclaves, every enclave now queries the key value store on the TruCE server for the signed Attestation Verification Report of all other enclaves.
	\item Each enclave $i$ now verifies this report using
          $\vk_{\textrm{\tiny{irs}}}$ and checks that the MRENCLAVE
          value in the report is indeed correct by comparing it with
          the expected MRENCLAVE value which can be calculated locally
          given the MPC code (this guarantees that each enclave is
          running the unaltered and correct MPC code which computes
          the intended function $f$), and finally extracts the public
          key for encryption and authentication $(\pk_j, \vk_j)$, of
          other participating enclaves, from it. An important note to
          be made here is that this verification must be done inside
          the enclave (and not by the host party of the enclave) in
          order to prevent a man-in-the-middle attack. 
	\item At the end of this phase, every enclave will have a
          secure and authenticated communication channel with every
          other enclave. For efficiency reasons, we will use this
          secure and authenticated communication channel to set up a
          shared symmetric key between every pair of parties for
          secure authenticated communication. We do this using
          standard techniques -- for each $(i,j)$ pairs of enclaves,
          one of the enclaves (say $i$) samples a random MAC key
          $k_{ij}$ (AES GCM key in our case) and sends it to the other
          enclave via the newly established secure channel. This is
          done by encrypting $k_{ij}$ using $\pk_j$ (this is an RSA
          encryption key in our case) and then signing the ciphertext
          using $\sksign_i$ (which is an ECDSA signature key in our
          case). Enclave $j$ will verify the signature on the
          ciphertext received using $\vk_i$ and then decrypt the
          ciphertext using $\sk_j$ to get $k_{ij}$. This key will be
          used to authenticate any further communication between this
          pair of enclaves. \nc{Technically, shouldnt we be encrypting
            messages also between $i$ and $j$ so that an adversarial
            party $w$ cannot see the message? If so, why do we
            exchange only a MAC key?} \aseem{Please see my comment
            above.}
	\item During the main MPC protocol execution, every message
          sent by $i$ to $j$ is MACed using the key $k_{ij}$. $j$,
          upon receiving a message, will first check its MAC using
          $k_{ij}$. It proceeds with the execution of the MPC only if
          the MAC verifies. If it doesn't, the receiver
          aborts. \nc{So, we get security with abort? We dont discuss
            these issues - I dont know how much to go into it. Also,
            what about the attested copy of the code? We need to
            exchange that also in the beginning of the protocol to
            make sure everyone is running the same code, right?} 
\end{itemize}

%\noindent\textbf{SGX Verification Keys.} In order for participants to know the identities of various $\fattest^{g,(\vk_i,\sksign_i)}(P_i)$ functionalities in the protocol, the corresponding verification keys must be signed by a key registration authority (or reliably known to all other participants in the protocol). We implement this through the remote enclave attestation protocol to obtain verified verification keys $\vk_i$ as well as an attested copy of the hash of $\pi^*(\cdot)$ to ensure that all functionalities run the same semi-honest protocol. %The modified next message functionality $\pi(\cdot)$ will additionally also check that every $\vk_i$ has been properly attested when it is invoked with $\ctr = 0$ (and hence this message also contains these certificates). %For this purpose, every $\fattest^{g,(\vk_i,\sksign_i)}(P_i)$ contacts the Intel server once in order to verify the certificate provided.

%\noindent\textbf{Implementing Remote Attestation.} For the purpose of remote attestation, we used IBM's SGX Trust Management Framework~\cite{ibmsgx}. IBM's framework however supports only a setting where a non-SGX client  can verify that it is communicating with a genuine Intel SGX application on a cloud server and then set up a private communication channel with the enclave running on the cloud server. We modified this framework to support a setting where multiple SGX enclaves can verify the identity of other SGX enclaves and then set up a private MAC key with them, which can then be used for authenticating any messages. One important change that had to be done was to now run the report verification and public key extraction inside the enclave. If enclave A has to make sure that it is talking to enclave B, then, it first receives the attestation report, verifies it, makes sure that the hash of public keys in the report (signed by Intel's key) is consistent with the public keys sent along with it. It is crucial that the report is verified inside the enclave because the party whose report is being verified has to be sure that it is talking to the enclave and not an untrusted application -- otherwise, this would lead to a standard man-in-the-middle attack. %In case $P_0$ wants to make sure that it is talking to enclave of $P_1$. Suppose the report verification on $P_1$ was done by the application, then the application of $P_1$ can launch a man-in-the-middle attack with the enclave of $P_1$ and forge messages. 

\noindent\textbf{Assigning Protected Memory.} We observed that assigning more protected memory to the enclave than what it actually requires affects the performance of enclave code. Intel's SGX SDK provides a tool called \textsf{sgx\_emmt} (Enclave Memory Management Tool)~\cite{intelsgxdevref} which can be used to measure the peak protected memory required by an enclave at runtime. We use this tool to make sure that we tune the max heap and stack size in enclave configuration file to match what is reported by \textsf{sgx\_emmt}. This helps us to optimize the runtime of enclave code by making sure that the memory reserved for the enclave is no more than what it requires.

\noindent\textbf{Porting interactive protocols to SGX.} We are the first work to port heavily interactive protocols to SGX enclaves and this comes with unique challenges. For example, whenever data is passed across the enclave's protected memory region, it has to be {\em marshalled} in/out of the region\footnote{When pointers to memory are passed as parameters into the enclave via an $\mathsf{ecall}$, the referenced data block is {\em marshalled} into the enclave, specifically into the protected memory region that an enclave uses. Similarly, when a pointer to enclave data, residing in protected memory region, is passed outside an enclave via an $\mathsf{ocall}$, the referenced data block is marshalled out of the protected memory region.}. The performance of  marshalling mainly depends on the size of the parameters crossing the bridge. Larger parameters imply slower marshalling~\cite{intelsgxperf}, while smaller parameters would increase the total numbers of cross-bridge calls (which have an overhead of their own). When we port highly interactive protocols to SGX, calls in and out of the enclave become a major factor that affects the performance of the application. This calls for the careful tuning of parameter sizes in cross-bridge calls. %We also had to add some common functionalities to the SGX SDK - e.g., routines to get input from user at runtime, sockets, routines to read cleartext data from files, routines to print output coming from enclave, spawn and join threads, and so on. \nc{Last line a bit informal.}
%\paragraph{New functionalities added to SGX SDK} Since we run highly interactive protocols completely inside enclave, there are some common functionalities that had to be implemented to make sure the porting works. Some of them include -- routines to get input from user at runtime, sockets, routines to read cleartext data from files, routines to print output coming from enclave, spawn and join threads, and so on. For all of these functionalities, we make an \textsf{ocall} to run the functionality and then come back to the enclave execution with appropriate data.
\end{comment}
