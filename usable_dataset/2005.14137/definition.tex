% \section{Background}


\section{Problem Definition}
Consider a $k$-way image classification model $f({\bf x})$ where ${\bf x}\in\mathbb{R}^m$ denotes the input image with dimension $m$, and $f({\bf x})\in\mathbb{R}^k$ represents the vector of confidence scores of the image belonging to each classes. 
In boundary-based black-box attacks, the attacker can only inquire the model with queries $\{ {\bf x}_i \}$ (a series of updated images) and get the predicted labels % $\tilde{y}=F({\bf x}) = \argmax_j [f({\bf x})]_j$
$\tilde{y}_i=F({\bf x_i}) = \argmax_j [f({\bf x_i})]_j,$
where $[f]_j$ represents the score of the $j$-th class. The parameters in the model $f$ and the score vector $\bf s$ are not accessible.

There is a \targetimage ${\bf x}_{tgt}$ with a \emph{benign label} $y_{ben}$. Based on the \emph{malicious label} $y_{mal}$ of their choice, the adversary will start from a \sourceimage ${\bf x}_{src}$ selected from the category with label $y_{mal}$, and move ${\bf x}_{src}$ towards ${\bf x}_{tgt}$ on the pixel space while keeping $y_{mal}$ to guarantee the attack. 
An image that is on the decision boundary between the two classes (e.g. $y_{ben}$ and $y_{mal}$) and is classified as $y_{mal}$ is called \boundaryimage. 

The adversary's goal is to find an \emph{adversarial image}(\advimage) ${\bf x}_{adv}$ such that $F({\bf x}_{adv}) = y_{mal}$ and $D({\bf x}_{tgt}, {\bf x}_{adv})$ is as small as possible, where $D$ is the distance metric (usually $L_2$-norm or $L_\infty$-norm distance). By definition, \advimage is a \boundaryimage with an optimized (minimal) distance from the \targetimage. 
In the paper we focus on targeted attack and the approaches can extend to untargeted scenario naturally. 



% \paragraph{Boundary-based Attacks}


% Boundary attack (BA)\Xiaojun{cite} is an iterative algorithm for decision-based attack. In BA, the adversary initializes its \advimage with \sourceimage $\xadv{0} = {\bf x}_s$ so that $F(\xadv{0}) = y_{mal}$. At each iterative step $t$, a random small perturbation $\Delta_t \in \mathbb{R}^m$ will be sampled from a chosen distribution to modify 

% HopSkipJumpAttack~\cite{chen2019hopskipjumpattack} improves upon the basic random walk idea in the original Boundary Attack paper. It proposes an unbiased estimate of the gradient of the model on the decision boundary via a Monte-Carlo algorithm. The queries are generated by adding the \boundaryimage with a set of noise vectors that are randomly sampled from the whole image space. Using the estimated gradient, the paper is able to perform more efficient update to get to a \boundaryimage that is closer to the \targetimage by taking a step towards the gradient direction and then performing binary search back to the decision boundary iteratively. This method reduces the query number compared with BA, but since it is sampling from an extremely high-dimensional space(for example, ImageNet data samples lie in $224\times 224\times 3$ dimensional space), the number of queries required to get a fair estimation for updating is still large.

% Boundary attack (BA)\Xiaojun{cite} is an iterative algorithm for decision-based attack. In BA, the adversary initializes its \advimage with \sourceimage $\xadv{0} = {\bf x}_{src}$ so that $F(\xadv{0}) = y_{mal}$. At each iterative step $t$, a small random perturbation $\Delta_t \in \mathbb{R}^m$ is sampled such that:
% \begin{align}
%     D(\xadv{t}+\Delta_t, {\bf x}_{tgt}) < D(\xadv{t}, {\bf x}_{tgt}).
% \end{align}
% and a rejective sampling procedure is used to update the \advimage:
% \begin{align}
%     \xadv{t+1} = \begin{cases}
%     \xadv{t}+\Delta_t, & \text{if } F(\xadv{t}+\Delta_t) = y_{mal}\\
%     \xadv{t}, & \text{otherwise}
%     \end{cases}
% \end{align}

% Experiment results show that BA can generate adversarial examples comparable with that generated by white-box or score-based attack.
% \Xiaojun{may add more explanation if we have space}
% \subsection{HopSkipJumpAttack}
% The disadvantage in applying BA in practice is that it requires a large number of queries. 
% Many follow-up works have been proposed to reduce the required number of queries. We focus on one of the most effective approaches named `HopSkipJumpAttack'(HSJA)\cite{chen2019hopskipjumpattack}. In HSJA, the random sampling process is replaced with a smarter way to update the \advimage. 
% The core idea is that the adversary can use multiple queries to estimate the gradient of \advimage if it lies on the decision boundary. Thus, each update breaks down into two sub-steps: first, move the \advimage towards the estimated gradient direction so that its score of recognized as the malicious class increases; second, project the \advimage back to the decision boundary to reduce its distance with the \targetimage.

% HopSkipJumpAttack (HSJA)~\cite{chen2019hopskipjumpattack} reduces the query number in this process by estimating gradient directions at the decision boundary to assist updates. Define the attack loss and the indicator function:
% \begin{align}
%     S_{{\bf x}_{tgt}}({\bf x}) &= [f({\bf x})]_{y_{mal}} - \max_{y \neq y_{mal}} [f({\bf x})]_y\\
%     \phi_{{\bf x}_{tgt}}({\bf x}) &= \text{sign}(S_{{\bf x}_{tgt}}({\bf x})) =
%     \begin{cases}
%     1 & \text{if } S_{{\bf x}_{tgt}}({\bf x})\geq 0\\
%     -1 & \text{otherwise}
%     \end{cases}
% \end{align}
% \begin{align}
%     \phi({\bf x}) &=
%     \begin{cases}
%     1 & \text{if } F(x) \text{ equals } y_{mal} \\
%     -1 & \text{otherwise}.
%     \end{cases}
% \end{align}
% We abbreviate the two functions as $S({\bf x})$ and $\phi({\bf x})$ if it does not cause confusion. 
% % Then $\bf x$ is adversarial if and only if $S({\bf x})\geq 0$, and the adversary can know the value of $\phi$ in the decision-based black-box setting. Thus, 
% Then the gradient of $S$ w.r.t. an \advimage which lies on the decision boundary can be estimated via Monte Carlo method:
% \begin{align}
%     \widetilde{\nabla S} = \frac1B \sum_{i=1}^B \phi({\bf x}+\delta {\bf u}_b) {\bf u}_b
%     \label{eq:MC_gradient_estimation}
% \end{align}
% where $\{{\bf u}_b\}$ are $B$ random perturbations uniformly sampled from the unit sphere in $\mathbb{R}^m$ and $\delta$ is a small weighting constant.

% Each iterative step $t$ starts with an adv-image $\xadv{t}$ on the decision boundary. The update breaks down into two steps:
% \begin{enumerate}
%     \item Move the \advimage towards the gradient direction:
%     \begin{align}
%         \label{eqn:grad-est}
%         \hat{\bf x}_{t+1} = \xadv{t} + \xi_t \cdot \frac{\widetilde{\nabla S}}{||\widetilde{\nabla S}||_2}
%     \end{align}
%     \item Project the new image back to the decision boundary:
%     \begin{align}
%         \label{eqn:binary}
%         \xadv{t+1} = \alpha_t {\bf x}_{tgt} + (1-\alpha_t) \hat{\bf x}_{t+1}
%     \end{align}
%     where the projection is achieved by a binary search over $\alpha_t$.
% \end{enumerate}
% Note that the \sourceimage does not lie on the boundary, so we need to first project it onto boundary using Eqn.\ref{eqn:binary} to get $\xadv{0}$.


% In \cite{chen2019hopskipjumpattack}, the authors show that with appropriate choice of $B$, $\xi$ and $\delta$, the pipeline can achieve good attack performance both theoretically and empirically. 








% stale part for problem definition

% In traditional adversarial attacks, the adversary starts at ${\bf x}^*$ and gradually perturbs it to make it misclassified by the model. In contrast, in a decision-based attack the adversary usually starts with an image ${\bf x}_s$ where $F({\bf x}_s) = y_{mal}$, and gradually perturb it to minimize its distance with ${\bf x}^*$. Therefore, we call ${\bf x}^*$ the \emph{\targetimage} and ${\bf x}_s$ the \emph{\sourceimage}.

% Consider in the image classification scenario, the attacker only has access to the final predicted label of the system (the \decisionlabel) by inquiring it with a image of their choice (the \queryimage). 
% % The output label of the system is called \decisionlabel and the image for inquiring is denoted as \queryimage. 
% The label given by an human expert(thus used as ground truth for the true label) for the same image is called \expertlabel. 

% The attacker has two images: the \sourceimage with \expertlabel of \maliciousclass, and the \targetimage with \expertlabel of \benignclass.
% An image that is very close to the decision boundary of the classifier with the \decisionlabel of \maliciousclass, is called \boundaryimage.

% The attacker would like to find an \advimage that has an \expertlabel of \benignclass but the system would give a \decisionlabel of \maliciousclass. In other words, the \advimage fools the system.

% \subsection{Boundary Attack}
% Boundary attack (BA)\Xiaojun{cite} is an iterative algorithm for decision-based attack. In BA, the adversary initializes its \advimage with \sourceimage $\xadv{0} = {\bf x}_s$ so that $F(\xadv{0}) = y_{mal}$. At each iterative step $t$, a random small perturbation $\Delta_t \in \mathbb{R}^m$ will be sampled from a chosen distribution such that:
% \begin{align}
%     D(\xadv{t}+\Delta_t, {\bf x}^*) < D(\xadv{t}, {\bf x}^*)
% \end{align}
% And the \advimage is updated by:
% \begin{align}
%     \xadv{t+1} = \begin{cases}
%     \xadv{t}+\Delta_t, & \text{if } F(\xadv{t}+\Delta_t) = y_{mal}\\
%     \xadv{t}, & \text{otherwise}
%     \end{cases}
% \end{align}
% Experiment results show that BA can generate adversarial examples comparable with that generated by white-box or score-based attack.
% \Xiaojun{may add more explanation if we have space}

% \subsection{HopSkipJumpAttack}
% The disadvantage in applying BA in practice is that it requires a large number of queries. Many follow-up works have been proposed to reduce the required number of queries. We focus on one of the most effective approaches named `HopSkipJumpAttack'(HSJA)\cite{chen2019hopskipjumpattack}. In HSJA, the random sampling process is replaced with a smarter way to update the \advimage. The core idea is that the adversary can use multiple queries to estimate the gradient of \advimage if it lies on the decision boundary. Thus, each update breaks down into two sub-steps: first, move the \advimage towards the estimated gradient direction so that its score of recognized as the malicious class increases; second, project the \advimage back to the decision boundary to reduce its distance with the \targetimage.

% Formally speaking, we define the following functions:
% \begin{align}
%     S_{{\bf x}^*}({\bf x}) &= [f({\bf x})]_{y_{mal}} - \max_{y \neq y_{mal}} [f({\bf x})]_y\\
%     \phi_{{\bf x}^*}({\bf x}) &= \text{sign}(S_{{\bf x}^*}({\bf x})) =
%     \begin{cases}
%     1 & \text{if } S_{{\bf x}^*}({\bf x})\geq 0\\
%     -1 & \text{otherwise}
%     \end{cases}
% \end{align}
% We abbreviate the two functions as $S({\bf x})$ and $\phi({\bf x})$ if it does not cause confucsion. Then $\bf x$ is adversarial if and only if $S({\bf x})\geq 0$, and the adversary can know the value of $\phi$ in the decision-based black-box setting. Thus, given an \advimage which lies on the decision boundary (i.e. $S({\bf x})=0$), the gradient of $S$ w.r.t. the input can be estimated via Monte Carlo:
% \begin{align}
%     \widetilde{\nabla S} = \frac1B \sum_{i=1}^B \phi({\bf x}+\delta {\bf u}_b) {\bf u}_b
% \end{align}
% where $\{{\bf u}_b\}$ are random perturbations uniformly sampled from the unit sphere in $\mathbb{R}^m$.

% \Xiaojun{Fig. or Alg.} In iterative step $t$, suppose the adv-image $\xadv{t}$ is already on the decision boundary. Then the update breaks down into two steps:
% \begin{enumerate}
%     \item Move the \advimage towards the gradient direction:
%     \begin{align}
%         \label{eqn:grad-est}
%         \hat{\bf x}_{t+1} = \xadv{t} + \xi_t \cdot \frac{\widetilde{\nabla S}}{||\widetilde{\nabla S}||_2}
%     \end{align}
%     \item Project the new image back to the decision boundary:
%     \begin{align}
%         \label{eqn:binary}
%         \xadv{t+1} = \alpha_t x^* + (1-\alpha_t) \hat{\bf x}_{t+1}
%     \end{align}
%     where the projection is achieved by a binary search over $\alpha_t$.
% \end{enumerate}
% Note that the \sourceimage does not lie on the boundary, so we need to first project it onto boundary using Eqn.\ref{eqn:binary} to get $\xadv{0}$.
% In \cite{chen2019hopskipjumpattack}, the authors show that with appropriate choice of $B$, $\xi$ and $\delta$, the pipeline can achieve good attack performance both theoretically and empirically. 

